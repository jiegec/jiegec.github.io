
<!DOCTYPE html>

<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="杰哥的{运维,编程,调板子}小笔记" name="description"/>
<link href="https://jia.je/page/9/" rel="canonical"/>
<link href="../../about/" rel="next"/>
<link href="../../feed_rss_created.xml" rel="alternate" title="RSS 订阅" type="application/rss+xml"/>
<link href="../../feed_rss_updated.xml" rel="alternate" title="已更新内容的 RSS 订阅" type="application/rss+xml"/>
<link href="../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.3, mkdocs-material-9.2.0-b0" name="generator"/>
<title>博客 - 杰哥的{运维,编程,调板子}小笔记</title>
<link href="../../assets/stylesheets/main.0c456da8.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#_1">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="杰哥的{运维,编程,调板子}小笔记" class="md-header__button md-logo" data-md-component="logo" href="../.." title="杰哥的{运维,编程,调板子}小笔记">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            杰哥的{运维,编程,调板子}小笔记
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              博客
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
</nav>
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../..">
        
  
    
  
  博客

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../about/">
        
  
    
  
  关于

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../open-source-contributions/">
        
  
    
  
  开源

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tags/">
        
  
    
  
  标签

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="/kb/">
        
  
    
  
  知识库

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../series/">
        
  
    
  
  系列

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../projects/">
        
  
    
  
  项目

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tools/">
        
  
    
  
  工具

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="/feed.xml">
        
  
    
  
  订阅

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../archive/2023/">
          
  
  归档

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../category/crypto/">
          
  
  分类

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="杰哥的{运维,编程,调板子}小笔记" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="杰哥的{运维,编程,调板子}小笔记">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    杰哥的{运维,编程,调板子}小笔记
  </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    博客
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../about/">
<span class="md-ellipsis">
    关于
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../open-source-contributions/">
<span class="md-ellipsis">
    开源
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tags/">
<span class="md-ellipsis">
    标签
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="/kb/">
<span class="md-ellipsis">
    知识库
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../series/">
<span class="md-ellipsis">
    系列
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../projects/">
<span class="md-ellipsis">
    项目
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tools/">
<span class="md-ellipsis">
    工具
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="/feed.xml">
<span class="md-ellipsis">
    订阅
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_10" type="checkbox"/>
<label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
<span class="md-ellipsis">
    归档
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_10_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_10">
<span class="md-nav__icon md-icon"></span>
            归档
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2023/">
<span class="md-ellipsis">
    2023
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2022/">
<span class="md-ellipsis">
    2022
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2021/">
<span class="md-ellipsis">
    2021
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2020/">
<span class="md-ellipsis">
    2020
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2019/">
<span class="md-ellipsis">
    2019
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2018/">
<span class="md-ellipsis">
    2018
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2017/">
<span class="md-ellipsis">
    2017
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2016/">
<span class="md-ellipsis">
    2016
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../archive/2014/">
<span class="md-ellipsis">
    2014
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
<span class="md-ellipsis">
    分类
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
            分类
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/crypto/">
<span class="md-ellipsis">
    crypto
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/csdn/">
<span class="md-ellipsis">
    csdn
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/ctf/">
<span class="md-ellipsis">
    ctf
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/devops/">
<span class="md-ellipsis">
    devops
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/hardware/">
<span class="md-ellipsis">
    hardware
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/life/">
<span class="md-ellipsis">
    life
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/logo/">
<span class="md-ellipsis">
    logo
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/meta/">
<span class="md-ellipsis">
    meta
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/misc/">
<span class="md-ellipsis">
    misc
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/networking/">
<span class="md-ellipsis">
    networking
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/news/">
<span class="md-ellipsis">
    news
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/os/">
<span class="md-ellipsis">
    os
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/others/">
<span class="md-ellipsis">
    others
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/programming/">
<span class="md-ellipsis">
    programming
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/software/">
<span class="md-ellipsis">
    software
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/speech/">
<span class="md-ellipsis">
    speech
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/system/">
<span class="md-ellipsis">
    system
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../category/unboxing/">
<span class="md-ellipsis">
    unboxing
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<div class="md-content__inner">
<header class="md-typeset">
<h1 id="_1"><a class="toclink" href="#_1">博客</a></h1>
</header>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-29 00:00:00">2021年12月29日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/software/">software</a></li>
<li class="md-meta__item">
            
              需要 1 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="xrdp-nvidia"><a class="toclink" href="../../software/2021/12/29/xrdp-nvidia/">XRDP 和 NVIDIA 显卡兼容性问题</a></h2>
<h3 id="_1"><a class="toclink" href="../../software/2021/12/29/xrdp-nvidia/#_1">背景</a></h3>
<p>最近在尝试配置 XRDP，发现它在有 NVIDIA 的机器上启动远程桌面后会黑屏，查看错误信息可以看到：</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a href="../../software/2021/12/29/xrdp-nvidia/#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a>xf86OpenConsole: Cannot open virtual console 1 (Permission denied)
</span></code></pre></div>
<h3 id="_2"><a class="toclink" href="../../software/2021/12/29/xrdp-nvidia/#_2">解决方法</a></h3>
<p>XRDP 作者在 <a href="https://github.com/neutrinolabs/xrdp/issues/2010#issuecomment-942561105">issue #2010</a> 中提到了解决方法：</p>
<p>修改 /etc/xrdp/sesman.ini，在 <code>[Xorg]</code> 部分里加上下面的配置：</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a href="../../software/2021/12/29/xrdp-nvidia/#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a>param=-configdir
</span><span id="__span-1-2"><a href="../../software/2021/12/29/xrdp-nvidia/#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>param=/
</span></code></pre></div>
<p>实际上就是不让 Xorg 加载 nvidia xorg 驱动，这样就绕过了问题。</p>
<nav class="md-post__action">
<a href="../../software/2021/12/29/xrdp-nvidia/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-26 00:00:00">2021年12月26日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/software/">software</a></li>
<li class="md-meta__item">
            
              需要 3 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="nvidia-cuda"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/">NVIDIA 驱动和 CUDA 版本信息速查</a></h2>
<h3 id="_1"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#_1">背景</a></h3>
<p>之前和 NVIDIA 驱动和 CUDA 搏斗比较多，因此记录一下一些常用信息，方便查询。</p>
<h3 id="_2"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#_2">常用地址</a></h3>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux">CUDA Toolkit Downloads</a></li>
<li><a href="https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html">NVIDIA Driver Installation Quickstart Guide</a></li>
<li><a href="https://www.nvidia.com/Download/index.aspx">NVIDIA Driver Downloads</a></li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html">NVIDIA Docker Installation Guide</a></li>
</ul>
<h3 id="cuda-nvidia"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#cuda-nvidia">CUDA 版本与 NVIDIA 驱动兼容性</a></h3>
<p>可以通过 apt show cuda-runtime-x-x 找到：</p>
<ul>
<li>cuda 12.1 &gt;= 530</li>
<li>cuda 12.0 &gt;= 525</li>
<li>cuda 11.7 &gt;= 515</li>
<li>cuda 11.6 &gt;= 510</li>
<li>cuda 11.5 &gt;= 495</li>
<li>cuda 11.4 &gt;= 470</li>
<li>cuda 11.3 &gt;= 465</li>
<li>cuda 11.2 &gt;= 460</li>
<li>cuda 11.1 &gt;= 455</li>
<li>cuda 11.0 &gt;= 450</li>
<li>cuda 10.2 &gt;= 440</li>
<li>cuda 10.1 &gt;= 418</li>
<li>cuda 10.0 &gt;= 410</li>
<li>cuda 9.2 &gt;= 396</li>
<li>cuda 9.1 &gt;= 387</li>
<li>cuda 9.0 &gt;= 384</li>
</ul>
<p>使用 nvidia-smi 看到的 CUDA 版本，通常就是这个驱动在上表里对应的 CUDA 版本，例如内核驱动版本是 470 的话，看到的 CUDA 版本就是 11.4。</p>
<p>不过，实际上兼容的版本会更多一些：<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">官方文档</a> 里面写了 CUDA 11.x 可以兼容 NVIDIA &gt;= 450。</p>
<h3 id="cuda-gccclang"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#cuda-gccclang">CUDA 版本和 GCC/Clang 版本兼容性</a></h3>
<p>可以在 cuda/include/crt/host_config.h 文件里找到：</p>
<ul>
<li>cuda 12.1: gcc &lt;= 12, 3.2 &lt; clang &lt; 16</li>
<li>cuda 12.0: gcc &lt;= 12, 3.2 &lt; clang &lt; 15</li>
<li>cuda 11.5: gcc &lt;= 11</li>
<li>cuda 11.4: gcc &lt;= 10</li>
<li>cuda 11.3: gcc &lt;= 10, 3.2 &lt; clang &lt; 12</li>
<li>cuda 11.1: gcc &lt;= 10, 3.2 &lt; clang &lt; 11</li>
<li>cuda 11.0: gcc &lt;= 9, 3.2 &lt; clang &lt; 10</li>
<li>cuda 10.2: gcc &lt;= 8, 3.2 &lt; clang &lt; 9</li>
<li>cuda 10.1: gcc &lt;= 8, 3.2 &lt; clang &lt; 9</li>
<li>cuda 10.0: gcc &lt;= 7</li>
<li>cuda 9.1: gcc &lt;= 6</li>
</ul>
<h3 id="cuda"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#cuda">CUDA 版本与显卡兼容性</a></h3>
<p>编译选项与显卡对应关系 https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/</p>
<p>可以在 <code>nvcc --help</code> 搜索 gpu-architecture 找到：</p>
<ul>
<li>cuda 12.0 sm_50 to sm_90a</li>
<li>cuda 11.4 sm_35 to sm_87</li>
<li>cuda 11.3 sm_35 to sm_86</li>
<li>cuda 11.1 sm_35 to sm_86</li>
<li>cuda 11.0 sm_35 to sm_80</li>
<li>cuda 10.2 sm_30 to sm_75</li>
<li>cuda 10.0 sm_30 to sm_75</li>
<li>cuda 9.1 sm_30 to sm_72</li>
<li>cuda 9.0 sm_30 to sm_70</li>
</ul>
<p>显卡的 Compute Capability 可以在 https://developer.nvidia.com/cuda-gpus 找到：</p>
<ul>
<li>H100: 90</li>
<li>A100: 80</li>
<li>V100: 70</li>
<li>P100: 60</li>
</ul>
<h3 id="nvidia"><a class="toclink" href="../../software/2021/12/26/nvidia-cuda/#nvidia">升级 NVIDIA 驱动</a></h3>
<p>升级后，需要 rmmod 已有的，再 modprobe 新的：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a href="../../software/2021/12/26/nvidia-cuda/#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a>sudo<span class="w"> </span>rmmod<span class="w"> </span>nvidia_uvm<span class="w"> </span>nvidia_drm<span class="w"> </span>nvidia_modeset<span class="w"> </span>nvidia<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>sudo<span class="w"> </span>modprobe<span class="w"> </span>nvidia
</span></code></pre></div>
<p>如果发现 rmmod 失败，可以 <code>lsof /dev/nvidiactl</code> 查看谁在占用。DGX 上需要停止：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a href="../../software/2021/12/26/nvidia-cuda/#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a>sudo<span class="w"> </span>systemctl<span class="w"> </span>stop<span class="w"> </span>nvsm.service
</span><span id="__span-1-2"><a href="../../software/2021/12/26/nvidia-cuda/#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>sudo<span class="w"> </span>systemctl<span class="w"> </span>stop<span class="w"> </span>nvidia-dcgm.service<span class="w"> </span>
</span></code></pre></div>
<nav class="md-post__action">
<a href="../../software/2021/12/26/nvidia-cuda/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-17 00:00:00">2021年12月17日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 15 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="_1"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/">「教学」缓存一致性协议分析</a></h2>
<p>本文的内容已经整合到<a href="/kb/hardware/cache_coherence_protocol.html">知识库</a>中。</p>
<h3 id="_2"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#_2">背景</a></h3>
<p>最近在《高等计算机系统结构》课程中学习缓存一致性协议算法，这里用自己的语言来组织一下相关知识的讲解。</p>
<h3 id="write-invalidate-write-update"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#write-invalidate-write-update">Write-invalidate 和 Write-update</a></h3>
<p>最基础的缓存一致性思想有两种：</p>
<ol>
<li>Write-invalidate：写入数据的时候，将其他 Cache 中这条 Cache Line 设为 Invalid</li>
<li>Write-update：写入数据的时候，把新的结果写入到有这条 Cache Line 的其他 Cache</li>
</ol>
<h3 id="write-once"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#write-once">Write-once 协议</a></h3>
<p>Write-once 协议定义了四个状态：</p>
<ol>
<li>Invalid：表示这个块不合法</li>
<li>Valid：表示这个块合法，并可能是共享的，同时数据没有修改</li>
<li>Reserved：表示这个块合法，不是共享的，同时数据没有更改</li>
<li>Dirty：表示这个块合法，不是共享的，数据做了修改，和内存不同。</li>
</ol>
<p>可见，当一个缓存状态在 R 或者 D，其他缓存只能是 I；而缓存状态是 V 的时候，可以有多个缓存在 V 状态。</p>
<p>Write-once 协议的特点是，第一次写的时候，会写入到内存（类似 Write-through），连续写入则只写到缓存中，类似 Write-back。</p>
<p>当 Read hit 的时候，状态不变。</p>
<div class="language-text highlight"><pre><span></span><code>Read hit: The information is supplied by the current cache. No state change.
</code></pre></div>
<p>当 Read miss 的时候，会查看所有缓存，如果有其他缓存处于 Valid/Reserved/Dirty 状态，就从其他缓存处读取数据，然后设为 Valid，其他缓存也设为 Valid。如果其他缓存处于 Dirty 状态，还要把数据写入内存。</p>
<div class="language-text highlight"><pre><span></span><code>Read miss: The data is read from main memory. The read is snooped by other caches; if any of them have the line in the Dirty state, the read is interrupted long enough to write the data back to memory before it is allowed to continue. Any copies in the Dirty or Reserved states are set to the Valid state.
</code></pre></div>
<p>当 Write hit 的时候，如果是 Valid 状态，首先写入内存，把其他 Cache 都设为 Invalid，进入 Reserved 状态，这意味着第一次写是 Write-through。如果是 Reserved/Dirty 状态，则不修改内存，进入 Dirty 状态，这表示后续的写入都是 Write-back。</p>
<div class="language-text highlight"><pre><span></span><code>Write hit: If the information in the cache is in Dirty or Reserved state, the cache line is updated in place and its state is set to Dirty without updating memory. If the information is in Valid state, a write-through operation is executed updating the block and the memory and the block state is changed to Reserved. Other caches snoop the write and set their copies to Invalid.
</code></pre></div>
<p>当 Write miss 的时候，这个行为 Wikipedia 上和上课讲的不一样。按照 Wikipedia 的说法，首先按照 Read miss 处理，再按照 Write hit 处理，类似于 Write Allocate 的思路。如果是这样的话，那么首先从其他缓存或者内存读取数据，然后把其他缓存都设为 Invalid，把更新后的数据写入内存，进入 Reserved 状态。相当于 Write miss 的时候，也是按照 Write-through 实现。</p>
<div class="language-text highlight"><pre><span></span><code>Write miss: A partial cache line write is handled as a read miss (if necessary to fetch the unwritten portion of the cache line) followed by a write hit. This leaves all other caches in the Invalid state, and the current cache in the Reserved state.
</code></pre></div>
<p>教材上则是 Write miss 的时候按照 Write-back 处理。如果其他缓存都是 Invalid 时，从内存里读取数据，然后写入到缓存中，进入 Dirty 状态。如果其他缓存是 Valid/Reserved/Dirty 状态，就从其他缓存里读取数据，让其他缓存都进入 Invalid 状态，然后更新自己的数据，进入 Dirty 状态。</p>
<h3 id="msi"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#msi">MSI 协议</a></h3>
<p>MSI 协议比较简单，它定义了三个状态：</p>
<ol>
<li>Modified：表示数据已经修改，和内存里不一致</li>
<li>Shared：数据和内存一致，可以有一到多个缓存同时处在 Shared 状态</li>
<li>Invalid：不在缓存中</li>
</ol>
<p>当 Read hit 的时候，状态不变。</p>
<p>当 Read miss 的时候，检查其他缓存的状态，如果都是 Invalid，就从内存里读取，然后进入 Shared 状态。如果有 Shared，就从其他缓存处读取。如果有 Dirty，那就要把其他缓存的数据写入内存和本地缓存，然后进入 Shared 状态。</p>
<p>当 Write hit 的时候，如果现在是 Shared 状态，则要让其他的 Shared 缓存进入 Invalid 状态，然后更新数据，进入 Modified 状态。如果是 Modified 状态，那就修改数据，状态保持不变。</p>
<p>当 Write miss 的时候，如果有其他缓存处于 Modified/Shared 状态，那就从其他缓存处读取数据，并让其他缓存进入 Invalid 状态，然后修改本地数据，进入 Modified 状态。如果所有缓存都是 Invalid 状态，那就从内存读入，然后修改缓存数据，进入 Modified 状态。</p>
<h3 id="mesi"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#mesi">MESI 协议</a></h3>
<p>MESI 协议定义了四种状态：</p>
<ol>
<li>Modified：数据与内存不一致，并且只有一个缓存有数据</li>
<li>Exclusive：数据与内存一致，并且只有一个缓存有数据</li>
<li>Shared：数据与内存一致，可以有多个缓存同时有数据</li>
<li>Invalid：不在缓存中</li>
</ol>
<p>当 Read hit 的时候，状态不变。</p>
<p>当 Read miss 的时候，首先会检查其他缓存的状态，如果有数据，就从其他缓存读取数据，并且都进入 Shared 状态，如果其他缓存处于 Modified 状态，还需要把数据写入内存；如果其他缓存都没有数据，就从内存里读取，然后进入 Exclusive 状态。</p>
<p>当 Write hit 的时候，进入 Modified 状态，同时让其他缓存进入 Invalid 状态。</p>
<p>当 Write miss 的时候，检查其他缓存的状态，如果有数据，就从其他缓存读取，否则从内存读取。然后，其他缓存都进入 Invalid 状态，本地缓存更新数据，进入 Modified 状态。</p>
<p>值得一提的是，Shared 状态不一定表示只有一个缓存有数据：比如本来有两个缓存都是 Shared 状态，然后其中一个因为缓存替换变成了 Invalid，那么另一个是不会受到通知变成 Exclusive 的。Exclusive 的设置是为了减少一些总线请求，比如当数据只有一个核心访问的时候，只有第一次 Read miss 会发送总线请求，之后一直在 Exclusive/Modified 状态中，不需要发送总线请求。</p>
<h3 id="moesi"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#moesi">MOESI 协议</a></h3>
<p>MOESI 定义了五个状态：</p>
<ol>
<li>Modified：数据经过修改，并且只有一个缓存有这个数据</li>
<li>Owned：同时有多个缓存有这个数据，但是只有这个缓存可以修改数据</li>
<li>Exclusive：数据没有修改，并且只有一个缓存有这个数据</li>
<li>Shared：同时有多个缓存有这个数据，但是不能修改数据</li>
<li>Invalid：不在缓存中</li>
</ol>
<p>状态中，M 和 E 是独占的，所有缓存里只能有一个。此外，可以同时有多个 S，或者多个 S 加一个 O，但是不能同时有多个 O。</p>
<p>它的状态转移与 MESI 类似，区别在于：当核心写入 Owned 状态的缓存时，有两种方式：1）通知其他 Shared 的缓存更新数据；2）把其他 Shared 缓存设为 Invalid，然后本地缓存进入 Modified 状态。在 Read miss 的时候，则可以从 Owned 缓存读取数据，进入 Shared 状态，而不用写入内存。它相比 MESI 的好处是，减少了写回内存的次数。</p>
<p>AMD64 文档里采用的就是 MOESI 协议。AMBA ACE 协议其实也是 MOESI 协议，只不过换了一些名称，表示可以兼容 MEI/MESI/MOESI 中的一个协议。ACE 对应关系如下：</p>
<ol>
<li>UniqueDirty: Modified</li>
<li>SharedDirty: Owned</li>
<li>UniqueClean: Exclusive</li>
<li>SharedClean: Shared</li>
<li>Invalid: Invalid</li>
</ol>
<p>需要注意的是，SharedClean 并不代表它的数据和内存一致，比如说和 SharedDirty 缓存一致，它只是说缓存替换的时候，不需要写回内存。</p>
<h3 id="dragon"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#dragon">Dragon 协议</a></h3>
<p>Dragon 协议是一个基于更新的协议，意味着写入缓存的时候，会把更新的数据同步到拥有这个缓存行的其他核心。它定义了四个状态：</p>
<ol>
<li>Exclusive clean(E)：独占，并且数据和内存一致</li>
<li>Shared clean(Sc)：数据同时存在多个缓存中，并且自己不是最后一个写入该缓存数据的</li>
<li>Shared modified(Sm)：数据同时存在多个缓存中，并且自己设最后一个写入该缓存数据的，类似于前面 MOESI 协议的 Owner 状态</li>
<li>Modify(M)：独占，并且数据和内存不一致</li>
</ol>
<p>可以看到，E 和 M 都是独占的，如果出现了多个缓存有同一个缓存行，那就是若干个 Sc 和一个 Sm。</p>
<p>当 Read miss 的时候，在总线上检查是否有缓存已经有这个缓存行的数据，如果没有，则从内存读取并转到 Exclusive clean 状态；如果已经在其他缓存中，则从其他缓存读取，将其他缓存转移到 Shared clean/Shared modified 状态，然后该缓存转移到 Shared clean 状态。</p>
<p>当 Write miss 的时候，同样检查其他缓存的状态，如果是第一个访问的，就从内存读取，更新数据，然后转到 Modify 状态；如果不是第一个访问的，就进入 Shared modified 状态，并且让原来 Shared modified 的缓存进入 Shared clean 状态。</p>
<p>当 Write hit 的时候，如果状态是 Shared modified，这时候需要通知其他缓存更新数据；如果状态是 Shared clean，则要通知其他缓存更新数据的同时，让原来 Shared modified 的缓存进入 Shared clean 状态；如果状态是 Exclusive clean，则进入 Modify 状态。</p>
<p>在这里，Shared modified 的缓存负责在换出的时候，写入数据到内存中。</p>
<h3 id="ace"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#ace">ACE 协议</a></h3>
<p>ACE 协议在 AXI 的基础上，添加了三个 channel：</p>
<ol>
<li>AC: Coherent address channel, Input to master: ACADDR, ACSNOOP, ACPROT</li>
<li>CR: Coherent response channel, Output from master: CRRESP</li>
<li>CD: Coherent data channel, Output from master: CDDATA, CDLAST</li>
</ol>
<p>此外，已有的 Channel 也添加了信号：</p>
<ol>
<li>ARSNOOP[3:0]/ARBAR[1:0]/ARDOMAIN[1:0]</li>
<li>AWSNOOP[3:0]/AWBAR[1:0]/AWDOMAIN[1:0]/AWUNIQUE</li>
<li>RRESP[3:2]</li>
<li>RACK/WACK</li>
</ol>
<p>ACE-lite 只在已有 Channel 上添加了新信号，没有添加新的 Channel。因此它内部不能有 Cache，但是可以访问一致的缓存内容。</p>
<p>当 Read miss 的时候，首先 AXI master 发送 read transaction 给 Interconnect，Interconnect 向保存了这个缓存行的缓存发送 AC 请求，如果有其他 master 提供了数据，就向请求的 master 返回数据；如果没有其他 master 提供数据，则向内存发起读请求，并把结果返回给 master，最后 master 提供 RACK 信号。</p>
<p>当 Write miss 的时候，也是类似地，AXI master 发送 MakeUnique 请求给 Interconnect，Interconnect 向保存了该缓存行的缓存发送请求，要求其他 master 状态改为 Invalid；当所有 master 都已经 invalidate 成功，就向原 AXI master 返回结果。</p>
<h3 id="_3"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#_3">基于目录的缓存一致性</a></h3>
<p>上面的缓存一致性协议中，经常有这么一个操作：向所有有这个缓存行的缓存发送/接受消息。简单的方法是直接广播，然后接受端自己判断是否处理。但是这个方法在核心很多的时候会导致广播流量太大，因此需要先保存下来哪些缓存会有这个缓存的信息，然后对这些缓存点对点地发送。这样就可以节省一些网络流量。</p>
<p>那么，怎么记录这个信息呢？一个简单的办法（Full bit vector format）是，有一个全局的表，对每个缓存行，都记录一个大小为 N（N 为核心数）的位向量，1 表示对应的核心中有这个缓存行。但这个方法保存数据量太大：缓存行数正比于 N，还要再乘以一次 N，总容量是 O(N^2) 的。</p>
<p>一个稍微好一些的方法（Coarse bit vector format）是，我把核心分组，比如按照 NUMA 节点进行划分，此时每个缓存行都保存一个大小为 M（M 为 NUMA 数量）的位向量，只要这个 NUMA 节点里有这个缓存行，对应位就取 1。这样相当于是以牺牲一部分流量为代价（NUMA 节点内部广播），来节省一些目录的存储空间。</p>
<p>但实际上，通常情况下，一个缓存行通常只会在很少的核心中保存，所以这里有很大的优化空间。比如说，可以设置一个缓存行同时出现的缓存数量上限 (Limited pointer format)，然后保存核心的下标而不是位向量，这样的存储空间就是 O(Nlog2N)。但是呢，这样限制了缓存行同时出现的次数，如果超过了上限，需要替换掉已有的缓存，可能在一些场景下性能会降低。</p>
<p>还有一种方式，就是链表 (Chained directory format)。目录中保存最后一次访问的核心编号，然后每个核心的缓存里，保存了下一个保存了这个缓存行的核心编号，或者表示链表终止。这样存储空间也是 O(Nlog2N)，不过发送消息的延迟更长，因为要串行遍历一遍，而不能同时发送。类似地，可以用二叉树 (Number-balanced binary tree format) 来组织：每个缓存保存两个指针，指向左子树和右子树，然后分别遍历，目的还是加快遍历的速度，可以同时发送消息给多个核心。</p>
<h3 id="_4"><a class="toclink" href="../../hardware/2021/12/17/cache-coherency-protocol/#_4">参考文档</a></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Cache_coherence">Cache coherence</a></li>
<li><a href="https://en.wikipedia.org/wiki/MSI_protocol">MSI protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/Write-once_(cache_coherence)">Write-once (cache coherence)</a></li>
<li><a href="https://en.wikipedia.org/wiki/MESI_protocol">MESI protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/MOESI_protocol">MOESI protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/Dragon_protocol">Dragon protocol</a></li>
<li><a href="https://blogs.synopsys.com/vip-central/2014/12/23/a-strategy-to-verify-an-axi-ace-compliant-interconnect-part-2-of-4/">A Strategy to Verify an AXI/ACE Compliant Interconnect (2 of 4)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Directory-based_cache_coherence">Directory-based cache coherence</a></li>
</ul>
<nav class="md-post__action">
<a href="../../hardware/2021/12/17/cache-coherency-protocol/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-13 00:00:00">2021年12月13日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 3 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="dram-kintex-7-fpga-vref"><a class="toclink" href="../../hardware/2021/12/13/dram-fpga-vref-problem/">DRAM 在 Kintex 7 FPGA 上内部 Vref 的性能问题</a></h2>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/12/13/dram-fpga-vref-problem/#_1">背景</a></h3>
<p>最近我们设计的 Kintex 7 FPGA 开发板在测试 DDR SDRAM 的时候遇到了一个问题，因为采用了 Internel VREF，MIG 在配置的时候限制了频率只能是 400 MHz，对应 800 MT/s，这样无法达到 DDR 的最好性能。</p>
<h3 id="_2"><a class="toclink" href="../../hardware/2021/12/13/dram-fpga-vref-problem/#_2">原理</a></h3>
<p>首先，VREF 在 DDR 中是用来区分低电平和高电平的。在 JESD79-4B 标准中，可以看到，对于直流信号，电压不小于 VREF+0.075V 时表示高电平，而电压不高于 VREF-0.075V 时表示低电平。VREF 本身应该介于 VDD 的 0.49 倍到 0.51 倍之间。</p>
<p>在连接 FPGA 的时候，有两种选择：</p>
<ul>
<li>Internal VREF: 从 FPGA 输出 VREF 信号到 DRAM</li>
<li>External VREF：接入 FPGA 以外的 VREF</li>
</ul>
<p>对于 7 Series 的 FPGA，Xilinx 要求如下：</p>
<div class="language-text highlight"><pre><span></span><code>For DDR3 SDRAM interfaces running at or below 800 Mb/s (400 MHz),
users have the option of selecting Internal VREF to save two I/O
pins or using external VREF. VREF is required for banks containing
DDR3 interface input pins (DQ/DQS).
</code></pre></div>
<p>进一步，Xilinx 在 UltraScale 文档下解释了背后的原因：</p>
<div class="language-text highlight"><pre><span></span><code>The UltraScale internal VREF circuit includes enhancements compared
to the 7 Series internal VREF circuit. Whereas 7 Series MIG had datarate
limitations on internal VREF usage (see (Xilinx Answer 42036)), internal
VREF is recommended in UltraScale. The VREF for 7 Series had coarse steps
of VREF value that were based on VCCAUX. This saved pins but limited the
performance because VCCAUX did not track with VCCO as voltage went up and
down. Not being able to track with VCCO enforced the performance
limitations of internal VREF in MIG 7 Series. UltraScale includes several
changes to internal VREF including a much finer resolution of VREF for DDR4
read VREF training. Additionally, internal VREF is based on the VCCO supply
enabling it to track with VCCO. Internal VREF is not subject to PCB and
Package inductance and capacitance. These changes in design now give internal
VREF the highest performance.
</code></pre></div>
<p>用中文简单来说：</p>
<ol>
<li>7 Series FPGA 中，Internal VREF 可以节省引脚，代价是 VREF 不会随着 VCCO 变化而变化（而是随着 VCCAUX 变化而变化），当 DRAM 频率提高的时候，可能无法满足 VREF 约等于 VDD 一半的要求</li>
<li>UltraScale FPGA 中，Internal VREF 是随着 VCCO 变化而变化的，并且会比 External VREF 性能更好；因此 UltraScale FPGA 的 DDR4 只支持 Internal VREF。</li>
</ol>
<p>以 MA703FA-35T 开发板为例，它使用的 FPGA 是 Artix7 35T，内存是 DDR3，采用的是 External VREF。它采用了 <a href="https://www.ti.com/lit/ds/symlink/tps51200.pdf">TPS51200 Sink and Source DDR Termination Regulator</a> 芯片，将芯片的 REFOUT 芯片接到 DRAM 的 VREFDQ 和 VREFCA 引脚上。</p>
<h3 id="_3"><a class="toclink" href="../../hardware/2021/12/13/dram-fpga-vref-problem/#_3">参考文档</a></h3>
<ul>
<li><a href="https://support.xilinx.com/s/article/42036?language=en_US">MIG 7 Series - Internal/External VREF Guidelines</a></li>
<li><a href="https://support.xilinx.com/s/article/64410?language=en_US">UltraScale/UltraScale+ Memory IP - Can either external or internal VREF be used?</a></li>
</ul>
<nav class="md-post__action">
<a href="../../hardware/2021/12/13/dram-fpga-vref-problem/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-12 00:00:00">2021年12月12日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 12 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="dram"><a class="toclink" href="../../hardware/2021/12/12/dram/">「教学」DRAM 结构和特性</a></h2>
<p>本文的内容已经整合到<a href="/kb/hardware/sdram.html">知识库</a>中。</p>
<h3 id="dram_1"><a class="toclink" href="../../hardware/2021/12/12/dram/#dram_1">DRAM 是如何组织的</a></h3>
<p>DRAM 分成很多层次：Bank Group，Bank，Row，Column，从大到小，容量也是各级别的乘积。</p>
<p>举例子：</p>
<ul>
<li>4 Bank Group</li>
<li>4 Bank per Bank Group</li>
<li>32,768 Row per Bank</li>
<li>1024 Column per Row</li>
<li>4 Bits per Column</li>
</ul>
<p>那么总大小就是 <code>4*4*32768*1024*4=2 Gb</code>。</p>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/12/12/dram/#_1">访问模式</a></h3>
<p>DRAM 的访问模式决定了访问内存的实际带宽。对于每次访问，需要这样的操作：</p>
<ol>
<li>用 ACT(Bank Activate) 命令打开某个 Bank Group 下面的某个 Bank 的某个 Row，此时整个 Row 的数据都会复制到 Sense Amplifier 中。这一步叫做 RAS（Row Address Strobe）</li>
<li>用 RD(Read)/WR(Write) 命令按照 Column 访问数据。这一步叫做 CAS（Column Address Strobe）。</li>
<li>在访问其他 Row 之前，需要用 PRE(Single Bank Precharge) 命令将 Sense Amplifier 中整个 Row 的数据写回 Row 中。</li>
</ol>
<p>可以看到，如果访问连续的地址，就可以省下 ACT 命令的时间，可以连续的进行 RD/WR 命令操作。</p>
<p>除了显式 PRE 以外，还可以在某次读写之后自动进行 PRE：WRA(Write with Auto-Precharge) 和 RDA(Read with Auto-Precharge)。</p>
<p>总结一下上面提到的六种命令：</p>
<ol>
<li>ACT: Bank Activate，激活一个 Row，用于接下来的访问</li>
<li>PRE: Single Bank Precharge，与 ACT 是逆操作，解除 Row 的激活状态</li>
<li>RD: Read，读取当前 Row 的某个 Column 数据</li>
<li>RDA: Read with Auto-Precharge，读取后执行 Precharge</li>
<li>WR: Write，写入当前 Row 的某个 Column 数据</li>
<li>WRA: Write with Auto-Precharge，写入后执行 Precharge</li>
</ol>
<p>除此之外，还有一些常用命令：</p>
<ol>
<li>REF: Refresh，需要定期执行，保证 DRAM 数据不会丢失。</li>
</ol>
<h3 id="_2"><a class="toclink" href="../../hardware/2021/12/12/dram/#_2">参数</a></h3>
<p>DRAM 有很多参数，以服务器上的内存 <a href="https://in.micron.com/products/dram-modules/rdimm/part-catalog/mta36asf2g72pz-2g3">MTA36ASF2G72PZ-2G3A3</a> 为例子：</p>
<ul>
<li>16GB 容量，DDR4 SDRAM RDIMM</li>
<li>PC4-2400</li>
<li>Row address: 64K A[15:0]</li>
<li>Column address: 1K A[9:0]</li>
<li>Device bank group address: 4 BG[1:0]</li>
<li>Device bank address per group: 4 BA[1:0]</li>
<li>Device configuration: 4Gb (1Gig x 4), 16 banks</li>
<li>Module rank address: 2 CS_n[1:0]</li>
<li>Configuration: 2Gig x 72</li>
<li>Module Bandwidth: 19.2 GB/s=2400 MT/s * 8B/T</li>
<li>Memory Clock: 0.83ns(1200 MHz)</li>
<li>Data Rate: 2400 MT/s</li>
<li>Clock Cycles: CL-nRCD-nRP = 17-17-17</li>
</ul>
<p>容量：每个 DRAM 颗粒 <code>64K*1K*4*4*4=4Gb</code>，不考虑 ECC，一共有 <code>16*2=32</code> 个这样的颗粒，实际容量是 16 GB。32 个颗粒分为两组，每组 16 个颗粒，两组之间通过 CS_n 片选信号区分。每组 16 个颗粒，每个颗粒 4 位 DQ 数据信号，合并起来就是 64 位，如果考虑 ECC 就是 72 位。</p>
<p>再举一个 FPGA 开发板上内存的例子：<a href="https://www.micron.com/products/dram/ddr4-sdram/part-catalog/mt40a512m16ly-075">MT40A512M16LY-075E</a>，参数如下：</p>
<ol>
<li>Data Rate: 2666 MT/s, Clock Frequency: 1333 MHz, tCK=0.750ns=750ps</li>
<li>Target CL-nRCD-nRP: 18-18-18</li>
<li>tAA(Internal READ command to first data)=<code>13.50ns(=18*0.750)</code></li>
<li>tRCD(ACTIVATE to internal READ or WRITE delay time)=<code>13.50ns(=18*0.750)</code></li>
<li>tRP(PRECHARGE command period)=<code>13.50ns(=18*0.750)</code></li>
<li>tRAS(ACTIVATE-to-PRECHARGE command period)=32ns</li>
<li>512 Meg x 16</li>
<li>Number of bank groups: 2</li>
<li>Bank count per group: 4</li>
<li>Row addressing: 64K</li>
<li>Column addressing: 1K</li>
<li>Page size: 2KB=2K*16b</li>
</ol>
<p>总大小：<code>2*4*64K*1K*16=1GB</code>。这个开发板用了 5 个 DRAM 芯片，只采用了其中的 4.5 个芯片：最后一个芯片只用了 8 位数据，这样就是 <code>4.5*16=72</code> 位的数据线，对应 64 位+ECC。</p>
<h3 id="_3"><a class="toclink" href="../../hardware/2021/12/12/dram/#_3">时序</a></h3>
<p>可以看到，上面的 DRAM Datasheet 里提到了三个时序参数：</p>
<ol>
<li>CL=17: CAS Latency，从发送读请求到第一个数据的延迟周期数</li>
<li>RCD=17: ACT to internal read or write delay time，表示从 ACT 到读/写需要的延迟周期数</li>
<li>RP=17: Row Precharge Time，表示 Precharge 后需要延迟周期数</li>
</ol>
<p>如果第一次访问一个 Row 中的数据，并且之前没有已经打开的 Row，那么要执行 ACT 和 RD 命令，需要的周期数是 RCD+CL；如果之前已经有打开了的 Row，那么要执行 PRE，ACT 和 RD 命令，需要的周期数是 RP+RCD+CL。但如果是连续访问，虽然还需要 CL 的延迟，但是可以流水线起来，充分利用 DDR 的带宽。</p>
<p>如果把这个换算到 CPU 角度的内存访问延迟的话，如果每次访问都是最坏情况，那么需要 17+17+17=51 个 DRAM 时钟周期，考虑 DRAM 时钟是 1200MHz，那就是 42.5ns，这个相当于是 DRAM 内部的延迟，实际上测得的是 100ns 左右。</p>
<p>更严格来说，读延迟 READ Latency = AL + CL + PL，其中 AL 和 PL 是可以配置的，CL 是固有的，所以简单可以认为 READ Latency = CL。同理 WRITE Latency = AL + CWL + PL，可以简单认为 WRITE Latency = CWL。CWL 也是可以配置的，不同的 DDR 速率对应不同的 CWL，范围从 1600 MT/s 的 CWL=9 到 3200 MT/s 的 CWL=20，具体见 JESD79-4B 标准的 Table 7 CWL (CAS Write Latency)。</p>
<h3 id="_4"><a class="toclink" href="../../hardware/2021/12/12/dram/#_4">波形</a></h3>
<p>用 Micron 提供的 <a href="https://media-www.micron.com/-/media/client/global/documents/products/sim-model/dram/ddr4/ddr4_verilog_models.zip?rev=caf27a5eaf6b4a9f81eb894a874a4492">Verilog Model</a> 进行仿真，可以看到如下的波形图：</p>
<p><img alt="" src="/images/ddr4_waveform.png"/></p>
<p>首先看第一个命令，ACT_n=0, ADDR=0x009C, CAS_n_A15=0, CKE=1-&gt;1, CS_n=0, RAS_n_A16=0, WE_n_A14=1，查阅标准可知这是 ACT(Bank Activate) 命令。接着第二个命令，ACT_n=1, ADDR=0x0400, CAS_n_A15=0, CKE=1-&gt;1, CS_n=0, RAS_n_A16=1, WE_n_A14=1, A10=1, 这是 RDA(Read with Auto Precharge) 命令。若干个周期后，读取的数据从 DQ 上输出，一共 8 个字节的数据。</p>
<h3 id="_5"><a class="toclink" href="../../hardware/2021/12/12/dram/#_5">刷新</a></h3>
<p>DRAM 的一个特点是需要定期刷新。有一个参数 tREFI，表示刷新的时间周期，这个值通常是 7.8us，在温度大于 85 摄氏度时是 3.9 us（见 JESD79-4B Table 131）。在刷新之前，所有的 bank 都需要 Precharge 完成并等待 RP 的时间，这时候所有的 Bank 都是空闲的，再执行 REF(Refresh) 命令。等待 tRFC(Refresh Cycle) 时间后，可以继续正常使用。</p>
<p>为了更好的性能，DDR4 标准允许推迟一定次数的刷新，但是要在之后补充，保证平均下来依然满足每过 tREFI 时间至少一次刷新。</p>
<h3 id="_6"><a class="toclink" href="../../hardware/2021/12/12/dram/#_6">地址映射</a></h3>
<p>如果研究 DRAM 内存控制器，比如 <a href="https://www.xilinx.com/support/documentation/ip_documentation/ultrascale_memory_ip/v1_4/pg150-ultrascale-memory-ip.pdf">FPGA 上的 MIG</a>，可以发现它可以配置不同的地址映射方式，例如：</p>
<ul>
<li>ROW_COLUMN_BANK</li>
<li>ROW_BANK_COLUMN</li>
<li>BANK_ROW_COLUMN</li>
<li>ROW_COLUMN_LRANK_BANK</li>
<li>ROW_LRANK_COLUMN_BANK</li>
<li>ROW_COLUMN_BANK_INTLV</li>
</ul>
<p>就是将地址的不同部分映射到 DRAM 的几个地址：Row，Column，Bank。可以想象，不同的地址映射方式针对不同的访存模式会有不同的性能。对于连续的内存访问，ROW_COLUMN_BANK 方式是比较适合的，因为连续的访问会分布到不同的 Bank 上，这样性能就会更好。</p>
<p>此外，如果访问会连续命中同一个 Page，那么直接读写即可；反之如果每次读写几乎都不会命中同一个 Page，那么可以设置 Auto Precharge，即读写以后自动 Precharge，减少了下一次访问前因为 Row 不同导致的 PRE 命令。一个思路是在对每个 Page 的最后一次访问采用 Auto Precharge。</p>
<h3 id="_7"><a class="toclink" href="../../hardware/2021/12/12/dram/#_7">传输速率</a></h3>
<p>DDR SDRAM 的传输速率计算方式如下：</p>
<div class="language-text highlight"><pre><span></span><code>Memory Speed (MT/s) * 64 (bits/transfer)
</code></pre></div>
<p>例如一个 DDR4-3200 的内存，带宽就是 <code>3200 * 64 = 204.8 Gb/s = 25.6 GB/s</code>。但前面已经看到，除了传输数据，还需要进行很多命令，实际上很难达到 100% 的带宽。然后 CPU 可以连接多个 channel 的 DRAM，再考虑多个 CPU Socket，系统的总带宽就是</p>
<div class="language-text highlight"><pre><span></span><code>Memory Speed (MT/s) * 64 (bits/transfer) * Channels * Sockets
</code></pre></div>
<p>使用 MLC 等工具进行测试，计算实际与理论的比值，我测试得到的大概在 70%-90% 之间。</p>
<h3 id="hbm"><a class="toclink" href="../../hardware/2021/12/12/dram/#hbm">HBM</a></h3>
<p>HBM 相比前面的 DDR SDRAM，它堆叠了多个 DRAM，提供多个 channel 并且提高了位宽。例如 <a href="https://media-www.micron.com/-/media/client/global/documents/products/data-sheet/dram/hbm2e/8gb_and_16gb_hbm2e_dram.pdf">Micron HBM with ECC</a>，堆叠了 4/8 层 DRAM，提供 8 个 channel，每个 channel 的数据宽度是 128 位，以 3200 MT/s 计算，一个 HBM 芯片的传输速率最大是：</p>
<div class="language-text highlight"><pre><span></span><code>3200 (MT/s) * 128 (bits/transfer) * 8 (Channels) = 3276.8 Gb/s = 409.6 GB/s
</code></pre></div>
<p>所以一片 HBM 的传输速率就相当于 16 个传统的 DDR SDRAM：8 个 Channel 加双倍的位宽。128 位实际上就是把两片 64-bit DDR SDRAM 并起来了，可以当成一个 128 位的用，也可以在 Pseudo Channel 模式下，当成共享地址和命令信号的两个 DDR SDRAM 用。</p>
<p>Xilinx 的 Virtex Ultrascale Plus HBM FPGA 提供了 <code>1800 (MT/s) * 128 (bits/transfer) * 8 (Channels) = 230.4 GB/s</code> 的带宽，如果用了两片 HBM 就是 460.8 GB/s。暴露给 FPGA 逻辑的是 16 个 256 位的 AXI3 端口，AXI 频率 450 MHz，内存频率 900 MHz。可以看到，每个 AXI3 就对应了一个 HBM 的 pseudo channel。每个 pseudo channel 是 64 位，但是 AXI 端口是 256 位：在速率不变的情况下，从 450MHz 到 900MHz，再加上 DDR，相当于频率翻了四倍，所以位宽要从 64 位翻四倍到 256 位。</p>
<p>当然了，HBM 的高带宽的代价就是引脚数量很多。根据 <a href="https://www.jedec.org/system/files/docs/JESD238A.pdf">HBM3 JESD238A</a>，每个 Channel 要 120 个 pin，一共 16 个 channel（HBM2 是 8 channel，每个 channel 128 位；HBM3 是 16 channel，每个 channel 64 位），然后还有其他的 52 个 pin，这些加起来就 1972 个 pin 了。所以一般在 Silicon Interposer 上连接，而不是传统的在 PCB 上走线（图源 <a href="https://picture.iczhiku.com/resource/ieee/WYifSuFTZuHLFcMV.pdf">A 1.2V 20nm 307GB/s HBM DRAM with At-Speed Wafer-Level I/O Test Scheme and Adaptive Refresh Considering Temperature Distribution</a>）：</p>
<p><img alt="" src="/images/hbm_stack.png"/></p>
<p>所以在 HBM3 标准里，用 Microbump 来描述 HBM 的 pin。</p>
<p>可以理解为把原来插在主板上的内存条，通过堆叠，变成一个 HBM Die，然后紧密地连接到 CPU 中。但是另一方面，密度上去了，价格也更贵了。</p>
<p>A100 显卡 40GB PCIe 版本提供了 1555 GB/s 的内存带宽。根据倍数关系，可以猜测是 5 个 8GB 的 HBM，每个提供 <code>1555 / 5 = 311 GB/s</code> 的带宽，那么时钟频率就是 <code>311 (GB/s) * 8 (bits/byte) / 128 (bits/transfer) / 8 (channels) / 2 (DDR) = 1215 MHz</code>，这与 <code>nvidia-smi -q</code> 看到的结果是一致的。</p>
<p>进一步，A100 80GB PCIe 版本提供了 1935 GB/s 的带宽，按照同样的方法计算，可得时钟频率是 <code>1935 (GB/s) / 5 * 8 (bits/byte) / 128 (bits/transfer) / 8 (channels) / 2(DDR) = 1512 MHz</code>，与 <a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/PB-10577-001_v02.pdf">Product Brief</a> 一致。频率的提高是因为从 HBM2 升级到了 HBM2e。</p>
<p>A100 文档中的 Memory bus width 5120 的计算方式也就清楚了：<code>128 (bits/transfer) * 8 (channels) * 5 (stacks) = 5120 (bits)</code>。</p>
<p>H100 SXM5 升级到了 HBM3，内存容量依然是 80GB，但是时钟频率提高，内存带宽是 <code>2619 (MHz) * 2 (DDR) * 128 (bits/transfer) * 8 (channels) * 5 (stacks) / 8 (bits/byte) = 3352 GB/s</code>。</p>
<h3 id="_8"><a class="toclink" href="../../hardware/2021/12/12/dram/#_8">参考文档</a></h3>
<ul>
<li>Memory systems: Cache, DRAM &amp; Disk</li>
<li><a href="https://zhuanlan.zhihu.com/p/262052220">译文：DDR4 SDRAM - Understanding the Basics（上）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/263080272">译文：DDR4 SDRAM - Understanding the Basics（下）</a></li>
<li><a href="https://github.com/RAMGuide/TheRamGuide-WIP-/raw/main/DDR5%20Spec%20JESD79-5.pdf">JEDEC STANDARD DDR5 SDRAM JESD79-5</a></li>
<li><a href="http://www.softnology.biz/pdf/JESD79-4B.pdf">JEDEC STANDARD DDR4 SDRAM JESD79-4B</a></li>
<li><a href="https://documents.pub/document/jesd79-3e-ddr3-sdram-specification.html">JEDEC STANDARD DDR3 SDRAM JESD79-3E</a></li>
</ul>
<nav class="md-post__action">
<a href="../../hardware/2021/12/12/dram/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-12 00:00:00">2021年12月12日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 14 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="risc-v-debug"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/">「教学」RISC-V Debug 协议</a></h2>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#_1">背景</a></h3>
<p>之前用过一些 RISC-V 核心，但是遇到调试相关的内容的时候就两眼一抹黑，不知道原理，出了问题也不知道如何排查，趁此机会研究一下工作原理。</p>
<h3 id="_2"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#_2">架构</a></h3>
<p>为了调试 RISC-V 核心，需要很多部件一起工作。按 RISC-V Debug Spec 所述，有这么几部分：</p>
<ol>
<li>Debugger: GDB，连接到 OpenOCD 启动的 GDB Server</li>
<li>Debug Translator: OpenOCD，向 GDB 提供 Server 实现，同时会通过 FTDI 等芯片控制 JTAG</li>
<li>Debug Transport Hardware: 比如 FTDI 的芯片，可以提供 USB 接口，让 OpenOCD 控制 JTAG 信号 TMS/TDI/TCK 的变化，并读取 TDO</li>
<li>Debug Transport Module: 在芯片内部的 JTAG 控制器（TAP），符合 JTAG 标准</li>
<li>Debug Module Interface：RISC-V 自定义的一系列寄存器，通过这些寄存器来控制 Debug Module 的行为</li>
<li>Debug Module：调试器，控制 RISC-V 核心，同时也支持直接访问总线，也有内部的 Program Buffer</li>
</ol>
<p>可以看到，DMI 是实际的调试接口，而 JTAG 可以认为是一个传输协议。</p>
<h3 id="jtag"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#jtag">JTAG</a></h3>
<p>首先什么是 JTAG？简单来说，它工作流程是这样的：</p>
<ol>
<li>JTAG TAP 维护了一个状态机，由 TMS 信号控制</li>
<li>当状态机进入 CaptureDR/CaptureIR 状态的时候，加载数据到 DR/IR 中</li>
<li>在 ShiftDR/ShiftIR 状态下，寄存器从 TDI 移入，从 TDO 移出</li>
<li>当进入 UpdateDR/UpdateIR 状态的时候，把 DR/IR 的结果输出到其他单元</li>
</ol>
<p>具体来说，JTAG 定义了两类寄存器：IR 和 DR。可以把 JTAG 理解成一个小的总线，我通过 IR 选择总线上的设备，通过 DR 向指定的设备上进行数据传输。比如在 RISC-V Debug Spec 里面，规定了以下的 5 位 IR 地址定义：</p>
<ol>
<li>0x00/0x1f: BYPASS</li>
<li>0x01: IDCODE</li>
<li>0x10: dtmcs</li>
<li>0x11: dmi</li>
</ol>
<p>可以类比为有四个设备：BYPASS，IDCODE，dtmcs，dmi，对应了一些地址。如果要选择 dtmcs 这个设备，就在 ShiftIR 阶段向 TDI 输入二进制的 00001 即可。选择地址以后，再向 DR 写入时，操作的就是 dtmcs 设备。</p>
<p>那么，每个设备是怎么操作的呢？假如我已经通过 IR 设置了当前设备是 dtmcs，然后进入 ShiftDR 模式时，JTAG 会同时输入和输出。输入的就是当前要输入的数据，输出的就是原来寄存器里的结果，这个结果可能是固定的，也可能是表示上一次输入对应的结果。</p>
<p>举个例子：IDCODE 设备，在 CaptureDR 阶段的时候，DR 总会被设为一个固定的 IDCODE，表示设备的 ID；在 Shift 的时候，这个 IDCODE 就会一位一位从 TDO 中输出，而 TDI 输入的数据都会被忽略掉。BYPASS 设备则是一个 1 位的寄存器，直接从 TDI 到寄存器，寄存器到 TDO，数据就这么流过去了。</p>
<p>那么，在 RISC-V Debug 里面，JTAG 是怎么用的呢？我们可以这么类比一下：CaptureDR 相当于读取寄存器到缓冲区，然后 ShiftDR 在读取缓冲区的同时写入缓冲区，最后 UpdateDR 则是把缓冲区中的数据写入到寄存器中。这和 MMIO 有点类似，只不过每次操作不是单独的写和读，而是一次操作等于先读后写。</p>
<p>还是来看例子。dtmcs 这个设备表示的是 DTM 当前的状态，它有 32 位，读取的时候可以得到 DMI 的状态和配置，写入的时候可以 reset DMI。以 OpenOCD 代码 <code>dtmcontrol_scan</code> 为例子，它做了这么几个事情：</p>
<ol>
<li>首先设置 IR 为 0x10，对应 dtmcs。</li>
<li>向 DR 中写入数据，同时读取数据。</li>
<li>设置 IR 为 0x11，对应 dmi，因为 dmi 操作是比较多的，所以它默认恢复到 dmi。</li>
</ol>
<p>如果我只想读取 dtmcs 寄存器，那么只要设置写入数据为 0 即可，因为寄存器的设计里考虑到，如果写入全 0 是没有副作用的。同理，如果只想写入 dtmcs 寄存器，直接写入即可，因为设计的时候也保证读入寄存器的值是没有副作用的。这样，就在一个一读一写的操作中，实现了读或者写的功能。</p>
<p>那么，dmi 寄存器的用途是什么呢？我们前面提到过，JTAG 其实是一个传输层，而 DMI 又定义了一系列的寄存器，这会让人有点混乱，为啥到处都是寄存器？又是 JTAG 的 IR/DR，又是 dmi，dmi 又有一堆寄存器，这是什么关系？</p>
<p>首先我们来看 dmi 寄存器的定义。它由三部分组成：地址、数据和操作。由于 JTAG 每次操作是一读一写，虽然寄存器定义差不多，但是读和写的含义是不同的。</p>
<p>比如读的时候，它表示的是上一次 dmi 请求的结果。地址还是上一次请求的地址，数据则是上一次请求的结果，操作字段 0 表示成功，2 表示失败，3 表示还没执行完。而写的时候，地址和数据表示了对哪个寄存器写入什么数据，操作字段 0 表示无操作，1 表示读，2 表示写。</p>
<p>可以看到，如果想操作 dmi 定义的寄存器，需要如下几个步骤，这也是 OpenOCD <code>dmi_op_timeout</code> 要做的事情：</p>
<ol>
<li>设置 IR 为 0x11，对应 DMI。</li>
<li>向 DR 写入请求的地址 + 数据 + 操作，丢弃读取的结果。</li>
<li>等待若干个周期。</li>
<li>向 DR 写入全 0，对应无操作，同时读取结果，这个结果就对应上面的请求。</li>
</ol>
<p>可以预期，如果首先写入了一个写操作，那么第二次 DR scan 得到的结果就是是否成功写入；如果首先写入了一个读操作，那么第二次 DR scan 得到的结果就是目标寄存器的值。</p>
<p>可能看起来还是很绕，确实很绕，因为这里有一个封装的过程。首先，DMI 本身定义了一些寄存器，这些寄存器读/写都有一定的含义，比如控制某一个 RISC-V 核心暂停等等。接着，JTAG 需要传输 DMI 的读取和写入操作，同时还要考虑读写尚未完成的情况，怎么办？结论就是通过 DR 来实现，写入 DR 时，按照 DR 中的操作数，对应到 DMI 的写入/读取；然后读取 DR 的时候，按照 DMI 的状态，告诉 OpenOCD 目前是否已经完成了上一次 DMI 操作，和操作的结果。</p>
<h3 id="dmi"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#dmi">DMI</a></h3>
<p>讲完 JTAG 以后，终于来到了 DMI。其实 DMI 就是一系列的寄存器，类似于 MMIO 设备，只不过访问方式不是我们通常的内存读写，而是通过 JTAG 的方式进行。它有很多个寄存器，摘录如下：</p>
<ol>
<li>dmcontrol 0x10: Debug Module Control</li>
<li>dmstatus 0x11: Debug Module Status</li>
<li>hartinfo 0x12: Hart Info</li>
<li>hartsum 0x13: Hart Summary</li>
<li>command 0x16: Abstract Control and Status</li>
<li>data0 0x04: Abstract Data 0</li>
<li>progbuf0 0x20: Program Buffer 0</li>
<li>sbcs 0x38: System Bus Access Control and Status</li>
<li>sbaddress0 0x39: System Bus Address 31:0</li>
<li>sbdata0 0x3c: System Bus Data 31:0</li>
</ol>
<p>OpenOCD 的 <code>examine</code> 函数对 DMI 初始化并进行一些参数的获取。它的操作如下：</p>
<ol>
<li>调用 dtmcontrol_scan，读取 JTAG 里的 dtmcs，可以得到 JTAG-DMI 的配置信息</li>
<li>向 dmcontrol 写入，进行复位</li>
<li>向 dmcontrol 写入，启用调试模块</li>
<li>从 hartinfo 读取 hart 信息</li>
<li>检查各个 hart 的状态</li>
</ol>
<p>类似地，其他各种调试操作都是对这些 DMI 寄存器的读和写进行。RISC-V Debug Spec 附录里还提到了如何实现调试器的一些功能。</p>
<p>比如要读取 CPU 的寄存器（比如通用寄存器，CSR 等等）的话，有如下的方式：</p>
<p>第一种是 Abstract Command，直接向 DMI 写入要寄存器编号，就可以实现读/写。</p>
<p>第二种是 Program Buffer。它是一块小的代码存储，可以通过 DMI 向其中写入指令，比如 <code>csrw s0, mstatus; ebreak</code>，然后设置 s0 寄存器的值，再执行 Program Buffer 里的代码。</p>
<p>以 OpenOCD 代码为例，<code>register_read_abstract</code> 做了以下操作：</p>
<ol>
<li>找到要读取的寄存器对应的 Abstract Register Number</li>
<li>进行 transfer 命令，DM 会读取对应寄存器到 data0 中</li>
<li>从 data0 中读取寄存器内容</li>
</ol>
<p>如果要读取内存的话，也有两种方法。一种是直接向 DMI 写入要读取的总线地址，然后再向指定的寄存器中读取数据。第二种还是利用 Program Buffer，写入一条 <code>lw s0, 0(s0)</code> 指令，然后先向 s0 写入地址，执行 Program Buffer 后，再把 s0 寄存器的值读出来。</p>
<h3 id="abstract-command"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#abstract-command">Abstract Command 实现</a></h3>
<p>那么，如何实现上面提到的 Abstract Command（比如读写寄存器，读写内存等）呢？Debug Spec 里面提到一种 Execution-Based 的方式，即在 Debug mode 下，核心依然在执行代码，只不过执行的是调试用的特殊代码。它做的就是轮询 Debug Module 等待命令，接受到命令以后，就去读写寄存器/内存，然后通过 data0-12 来传输数据。</p>
<p>这里还有一个比较特别的点，就是读取寄存器的时候，寄存器的编号是直接记录在指令中的，所以可以让 Debug Module 动态生成指令，然后让核心刷新 ICache 然后跳转过去。另外，还可以利用 dscratch0/dscratch1 寄存器来保存 gpr，然后用 dret 退出的时候再恢复，这样就有两个 gpr 可以用来实现功能了，实际上这已经够用了（一个技巧是，把地址设为 0 附近，然后直接用 zero 寄存器加偏移来寻址）。</p>
<h3 id="_3"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#_3">单步调试实现</a></h3>
<p>在 dcsr 中，有一个值 step 表示是否在单步调试状态。设 step 为 1 的时候，如果不在 debug mode 中，只需要记录以及执行的指令数，当执行了一条指令后，视为下一个指令发生了进入 debug mode 的异常，这样就实现了单步调试。</p>
<h3 id="_4"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#_4">软件断点实现</a></h3>
<p>调试器为了打断点，一种简单的方式是，往断点处写入 ebreak 指令，然后设置 dcsr 的 ebreakm/s/u，表示在这些特权集里，ebreak 是进入 debug mode，而不是原来的处理过程。然后，程序运行到 ebreak 指令的时候，进入 debug mode，openocd 发现核心进入 halted 状态后，让 gdb 继续进行调试。</p>
<p>硬件方面的实现方法就是，在遇到 ebreak 的时候，判断一下当前的特权集，结合 ebreakm/s/u 判断跳转到什么状态。此外，由于它会写入指令到内存，所以还需要执行 fence.i 指令，而 OpenOCD 需要依赖 progbuf 来执行 fence.i 指令，所以为了让这个方案工作，还得实现 Program Buffer。</p>
<p>当然了，软件断点也有局限性，比如内存不可写，比如 ROM，不能覆盖里面的指令，这样就有可能出问题。而且硬件断点性能也更好，不需要来回这样写指令。</p>
<h3 id="semihosting"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#semihosting">Semihosting</a></h3>
<p>ARM 有一种 semihosting 机制，就是处理器执行一种特定的指令序列，然后调试器看到整个序列的时候，不是进入 GDB 调试状态，而是去进行一些操作，比如输出信息，读写文件等等，然后结果通过 JTAG 写回去。OpenOCD 给 RISC-V 也做了类似的 semihosting 机制，只不过触发的指令序列不大一样，但是机制是类似的。</p>
<p>如果用过 Rocket Chip 仿真的或者以前的 ucb-bar/fpga-zynq 项目的话，会知道还有一个目的有些类似的东西：HTIF + fesvr，它是通过 fromhost/tohost 两组地址来进行通信，但是这个方法缺点是需要 poll tohost/fromhost 地址的内容，相对来说比较麻烦。</p>
<h3 id="program-buffer"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#program-buffer">Program Buffer</a></h3>
<p>此外，debug spec 还有一个可选的功能，就是 Program Buffer，调试器可以往里面插入自定义的指令，然后结合 abstract command 进行操作。这样就可以做一些比较高效的操作，比如 OpenOCD 实现的批量写入内存：</p>
<div class="language-asm highlight"><pre><span></span><code><span id="__span-0-1"><a href="../../hardware/2021/12/12/riscv-debug/#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">sw</span><span class="w"> </span><span class="no">s1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">(</span><span class="no">a0</span><span class="p">)</span>
</span><span id="__span-0-2"><a href="../../hardware/2021/12/12/riscv-debug/#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nf">addi</span><span class="w"> </span><span class="no">a0</span><span class="p">,</span><span class="w"> </span><span class="no">a0</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span>
</span><span id="__span-0-3"><a href="../../hardware/2021/12/12/riscv-debug/#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="nf">ebreak</span>
</span></code></pre></div>
<p>并且设置 abstractauto，然后重复的操作是往 s1 里面写入新的数据，然后跳转到 program buffer，进行上面的 sw 操作，这样就可以一次 dmi 请求完成一次内存的写入，比较高效。</p>
<h3 id="_5"><a class="toclink" href="../../hardware/2021/12/12/riscv-debug/#_5">参考文档</a></h3>
<ol>
<li>RISC-V Debug Spec 0.13</li>
<li>IEEE Standard for JTAG 1149.1-2013</li>
<li>OpenOCD 相关代码</li>
</ol>
<nav class="md-post__action">
<a href="../../hardware/2021/12/12/riscv-debug/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-09 00:00:00">2021年12月9日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/misc/">misc</a></li>
<li class="md-meta__item">
            
              需要 4 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="_1"><a class="toclink" href="../../misc/2021/12/09/education/">教学随想</a></h2>
<h3 id="_2"><a class="toclink" href="../../misc/2021/12/09/education/#_2">背景</a></h3>
<p>最近关于课程改革的讨论比较多，我也来谈谈我的看法。</p>
<h3 id="_3"><a class="toclink" href="../../misc/2021/12/09/education/#_3">动机</a></h3>
<p>一位高中毕业的同学，选择计算机系的动机是什么？我想了想，可能有下面几种：</p>
<ol>
<li>计算机行业就业好，我选了计算机系，毕业以后可以赚到很多钱</li>
<li>喜欢计算机，希望从事计算机方面的工作</li>
<li>计算机系分高，大家都说好，那我就选择去这里吧</li>
<li>我是竞赛保送的，所以来到了这里</li>
</ol>
<p>学校希望计算机系培养出来的学生：</p>
<ol>
<li>有很好的能力</li>
<li>有很好的毕业去向（保研/工作/留校等等）</li>
</ol>
<p>学校为希望计算机系：</p>
<ol>
<li>有更多重大科研成果</li>
<li>能够培养多且精的计算机人才</li>
</ol>
<p>计算机系为了实现上面的目标：</p>
<ol>
<li>教学的专业课程要全面，并且能够支撑后续的科研</li>
<li>吸引更多学生进入实验室科研</li>
</ol>
<p>同时还要与其他院系（软件学院，交叉信息学院，集成电路学院等）有区分（分工）。</p>
<h3 id="_4"><a class="toclink" href="../../misc/2021/12/09/education/#_4">路径</a></h3>
<p>可以看到，上面的这一系列诉求是有矛盾的，可以假想这么几条路径：</p>
<ol>
<li>想赚钱-&gt;读研毕业薪资更高-&gt;读研需要高 GPA-&gt;每门课都要 4.0-&gt;每个课程的可选部分都要做-&gt;工作量太大</li>
<li>想科研-&gt;找好老师-&gt;需要高 GPA 和或论文-&gt;每门课都要 4.0 同时还要在实验室科研-&gt;工作量特别大</li>
<li>不想科研直接工作-&gt;工作不需要高的 GPA-&gt;放弃一些课程的可选部分-&gt;空余时间学习实用技术-&gt;面试轻松过关</li>
<li>对未来没有想法-&gt;从众心理卷 GPA-&gt;每个课程都做可选部分-&gt;花费很多时间-&gt;没有时间做自己喜欢的事情</li>
</ol>
<p>这对于七字班（2017）或者更早同学来说，这可能是难以理解的。当时，保研不需要很高的 GPA，老师会看重科研潜力，想科研的同学可能选择在实验室科研的同时，放弃一些课程。</p>
<p>但是从八字班（2018）开始，多重因素下，问题就凸显了。一是总人数更多，保研难度本身就更大，竞争激烈；二是保研名额严格按照 GPA 排序，导致保研的同学必须科研学习两手抓；三是 GPA 改革以后，4.0 难度变低，以前会想 A B C 课程比较难，大部分人都拿不到 4.0，我 A 课程 3.7，B 课程 3.3 和你 A 课程 3.3，B 课程 3.7 是一样的，精力有限，只做三个里面最简单的一个，但现在会发现，比 GPA 实际上就是比谁 4.0 更多，虽然 A B C 课程也比较难，但是此时只能把三个都做了，不然就会排名下降明显。</p>
<p>这还会带来其他的问题：为了拿到更多 4.0，但精力有限，按照自己的时间，三个课里只能拿到一个 4.0，比不过拿到三个 4.0 的同学，咋办？抄袭。让老师放水，人人 4.0。</p>
<h3 id="_5"><a class="toclink" href="../../misc/2021/12/09/education/#_5">解决</a></h3>
<p>那么，怎么解决这个问题？</p>
<p>从个人的角度出发：尽早想好自己要什么。我要做什么，就在我要做的方向上做好，其他方向可以选择性放弃，不要随大流。</p>
<p>从院系的角度出发：难。</p>
<nav class="md-post__action">
<a href="../../misc/2021/12/09/education/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-06 00:00:00">2021年12月6日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 4 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="manycore"><a class="toclink" href="../../hardware/2021/12/06/manycore/">Manycore 处理器架构分析</a></h2>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/12/06/manycore/#_1">参考文档</a></h3>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/architecture-and-technology/many-integrated-core/intel-many-integrated-core-architecture.html">Intel® Many Integrated Core Architecture (Intel® MIC Architecture) - Advanced</a></li>
<li><a href="https://ieeexplore.ieee.org/abstract/document/7476487">Intel® Xeon Phi coprocessor (codename Knights Corner)</a></li>
<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7453080">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7453080</a></li>
<li><a href="https://www.alcf.anl.gov/files/HC27.25.710-Knights-Landing-Sodani-Intel.pdf">Knights Landing (KNL): 2nd Generation Intel® Xeon Phi™ Processor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fujitsu_A64FX">Fujitsu A64FX</a></li>
<li><a href="https://www.fujitsu.com/global/about/resources/news/press-releases/2018/0822-02.html">Fujitsu Presents Post-K CPU Specifications</a></li>
<li><a href="https://web.archive.org/web/20201205202434/https://hotchips.org/hc30/2conf/2.13_Fujitsu_HC30.Fujitsu.Yoshida.rev1.2.pdf">Fujitsu High Performance CPU for the Post-K Computer</a></li>
<li><a href="https://www.top500.org/system/179807/">SUPERCOMPUTER FUGAKU - SUPERCOMPUTER FUGAKU, A64FX 48C 2.2GHZ, TOFU INTERCONNECT D</a></li>
<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9229635">Preliminary Performance Evaluation of the Fujitsu A64FX Using HPC Applications</a></li>
<li><a href="https://www.fujitsu.com/downloads/SUPER/a64fx/a64fx_datasheet.pdf">FUJITSU Processor A64FX</a></li>
<li><a href="https://images.nvidia.cn/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf">NVIDIA A100 Tensor Core GPU Architecture</a></li>
<li><a href="https://images.nvidia.cn/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf">NVIDIA TESLA V100 GPU ARCHITECTURE</a></li>
<li><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf">NVIDIA A100 TENSOR CORE GPU</a></li>
</ul>
<h3 id="xeon-phi-intel-mic"><a class="toclink" href="../../hardware/2021/12/06/manycore/#xeon-phi-intel-mic">Xeon Phi - Intel MIC</a></h3>
<p>MIC: Many Integrated Core Architecture</p>
<p>Knights Corner:</p>
<p>4 路 SMT，AVX512 指令，32 KB L1I，32 KB L1D，每核心 512KB L2，乱序执行，一条 512 位计算流水线，每个周期双精度性能 <code>512 / 64 * 2 = 16 FLOP/cycle</code>。61 核 1.053GHz 双精度性能是 <code>16 * 61 * 1.053 = 1028 GFLOPS</code>。</p>
<p>向量寄存器分为四组，每组 128 位，两个 DP/四个 SP。SP 和 DP 计算共享乘法器，来优化面积。</p>
<p>Knights Landing:</p>
<p>核心：4 路 SMT，AVX512 指令，乱序执行，两条 512 位计算流水线，每个周期双精度性能 <code>512 / 64 * 2 * 2 = 32 FLOP/cycle</code>，如果是 64 核 1.3 GHz，总双精度性能是 <code>32 * 64 * 1.3 = 2662 GFLOPS</code>。一共 36 个 Tile，每个 Tile 有 2 Core + 2 VPU/core + 1MB 16-way L2，最大 72 个核心。</p>
<p>内存：6-channel 384GB DDR4 2400 RAM（理论 <code>2400 * 6 * 8 = 115.2 GB/s</code>），8-16GB 3D MCDRAM（400+ GB/s）。</p>
<h3 id="fujitsu-a64fx"><a class="toclink" href="../../hardware/2021/12/06/manycore/#fujitsu-a64fx">Fujitsu A64FX</a></h3>
<p>内存：4 组，每组 8GB HBM2，带宽 256 GB/s（<code>1024 bit * 2G</code>），总共 32GB HBM2，带宽 1TB/s。Cache Line 大小 256 B。</p>
<p>核心：4 个 NUMA Node（Core Memory Group），每个 NUMA Node 包括 12 计算核，有 8MB 16 路的 L2 Cache。总共 48 计算核，4 辅助核。</p>
<p>指令集：ARMv8.2+SVE，512 位向量宽度，乱序执行，两个浮点流水线和两个整数流水线，每个周期双精度性能 <code>512 / 64 * 2 * 2 = 32 FLOP/cycle</code>，主频 2.2 GHz，按主频算理论双精度浮点性能 <code>32 * 2.2 * 48 = 3.4 TFLOPS</code>。文档里写的是双精度浮点性能 2.7 TFLOPS，单精度 5.4 TFLOPS，半精度 10.8 TFLOPS，8 位整数 21.6 TOPS，应该是按照实际测出来的算。TOP 500 配置是 7630848 核，对应 <code>7630848 / 48 = 158976</code> 个节点，Rpeak 是 <code>537212 TFLOPS</code>，那么每个节点是 <code>537212 / 158976 = 3.38 TFLOPS</code>，和上面的 3.4 接近。Linpack 跑出来的 Rmax 是 442010 TFLOPS，每个节点是 <code>442010 / 158976 = 2.78 TFLOPS</code>，和文档里说的比较接近。</p>
<p>部分主要特性：</p>
<ul>
<li>Four-operand FMA: ARM FMA 指令只能是 <code>R0=R0+R1*R2</code>，A64FX 可以合并 <code>R0=R3,R0=R0+R1*R2</code> 两条为一条 <code>R0=R3+R1*R2</code> 指令</li>
<li>Gather/Scatter: 非连续访存，同一个 128B 内连续的 lane 可以合并访问，如果数据有局部性的话，可以得到两倍带宽</li>
</ul>
<h3 id="nvidia-gpu"><a class="toclink" href="../../hardware/2021/12/06/manycore/#nvidia-gpu">NVIDIA GPU</a></h3>
<table>
<thead>
<tr>
<th>型号</th>
<th>工艺</th>
<th>Peak DP(TFLOPS)</th>
<th>功耗 (W)</th>
<th>性能功耗比 (TFLOPS/W)</th>
</tr>
</thead>
<tbody>
<tr>
<td>P100</td>
<td>16 nm FinFET+</td>
<td>4.7</td>
<td>250</td>
<td>0.019</td>
</tr>
<tr>
<td>V100</td>
<td>12 nm FFN</td>
<td>7</td>
<td>250-300</td>
<td>0.023-0.028</td>
</tr>
<tr>
<td>A100</td>
<td>7 nm N7</td>
<td>9.7</td>
<td>250-400</td>
<td>0.024-0.039</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>型号</th>
<th>内存容量 (GB)</th>
<th>内存带宽 (GB/s)</th>
<th>内存类型</th>
<th>L2 缓存大小</th>
<th>寄存器堆大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>P100</td>
<td>12-16</td>
<td>549-732</td>
<td>4096 bit HBM2</td>
<td>4096 KB</td>
<td>14336 KB</td>
</tr>
<tr>
<td>V100</td>
<td>16-32</td>
<td>900</td>
<td>4096 bit HBM2</td>
<td>6144 KB</td>
<td>20480 KB</td>
</tr>
<tr>
<td>A100</td>
<td>40-80</td>
<td>1555-2039</td>
<td>5120 bit HBM2</td>
<td>40960 KB</td>
<td>27648 KB</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>型号</th>
<th>SM 数量</th>
<th>CUDA 核心数</th>
<th>FP64 核心数</th>
<th>SM 频率 (MHz)</th>
</tr>
</thead>
<tbody>
<tr>
<td>P100</td>
<td>56</td>
<td>3584</td>
<td>1792</td>
<td>1328</td>
</tr>
<tr>
<td>V100</td>
<td>80</td>
<td>5120</td>
<td>2560</td>
<td>1380</td>
</tr>
<tr>
<td>A100</td>
<td>108</td>
<td>6912</td>
<td>3456</td>
<td>1410</td>
</tr>
</tbody>
</table>
<ul>
<li>CUDA 核心数 = SM 数量 * 64</li>
<li>FP64 核心数 = SM 数量 * 32</li>
<li>Peak DP = FP64 核心数 * SM 频率 * 2</li>
<li>寄存器堆大小 = SM 数量 * 256 KB</li>
</ul>
<nav class="md-post__action">
<a href="../../hardware/2021/12/06/manycore/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-12-04 00:00:00">2021年12月4日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 5 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="sunway"><a class="toclink" href="../../hardware/2021/12/04/sunway/">Sunway 处理器架构分析</a></h2>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/12/04/sunway/#_1">参考文档</a></h3>
<ul>
<li><a href="https://crad.ict.ac.cn/CN/10.7544/issn1000-1239.2021.20201041">高性能众核处理器申威 26010</a></li>
<li><a href="https://cjc.ict.ac.cn/online/onlinepaper/lyy-202065163512.pdf">稀疏矩阵向量乘法在申威众核架构上的性能优化</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sunway_SW26010">Sunway SW26010</a></li>
<li><a href="https://link.springer.com/content/pdf/10.1007/s11432-016-5588-7.pdf">The Sunway TaihuLight supercomputer: system and applications</a></li>
<li><a href="https://www.netlib.org/utk/people/JackDongarra/PAPERS/sunway-report-2016.pdf">Report on the Sunway TaihuLight System</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3458817.3487399">Closing the “Quantum Supremacy” Gap: Achieving Real-Time Simulation of a Random Quantum Circuit Using a New Sunway Supercomputer</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3458817.3476161">SW_Qsim: A Minimize-Memory Quantum Simulator with High-Performance on a New Sunway Supercomputer</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3126908.3126910">18.9-Pflops Nonlinear Earthquake Simulation on Sunway TaihuLight: Enabling Depiction of 18-Hz and 8-Meter Scenarios</a></li>
<li><a href="https://www.nextplatform.com/2021/02/10/a-sneak-peek-at-chinas-sunway-exascale-supercomputer/">A FIRST PEEK AT CHINA’S SUNWAY EXASCALE SUPERCOMPUTER</a></li>
<li><a href="https://www.nextplatform.com/2021/03/10/the-nitty-gritty-of-the-sunway-exascale-system-network-and-storage/">THE NITTY GRITTY OF THE SUNWAY EXASCALE SYSTEM NETWORK AND STORAGE</a></li>
<li><a href="https://www.sciengine.com/publisher/scp/journal/SCIS/64/4/10.1007/s11432-020-3104-7?slug=fulltext">Sunway supercomputer architecture towards exascale computing: analysis and practice</a></li>
</ul>
<h3 id="sw26010"><a class="toclink" href="../../hardware/2021/12/04/sunway/#sw26010">SW26010</a></h3>
<p>Sunway TaihuLight 的层次：</p>
<ol>
<li>1 Sunway TaihuLight = 40 Cabinet</li>
<li>1 Cabinet = 4 Super nodes</li>
<li>1 Super node = 256 nodes</li>
<li>1 node = 4 core groups</li>
<li>1 core group = 1 MPE(management processing element) + 8*8 CPE(computer processing element)</li>
</ol>
<p>MPE 双精度性能：<code>16 FLOP/cycle * 1.45 GHz = 23.2 GFlops</code>
CPE 双精度性能：<code>8 FLOP/cycle * 1.45 GHz = 11.6 GFlops</code>
CPE 单精度性能：<code>8 FLOP/cycle * 1.45 GHz = 11.6 GFlops</code>
单节点双精度性能：<code>4 * 8 * 8 * 11.6 + 4 * 23.2 = 3.0624 TFlops</code>
Sunway TaihuLight 双精度性能：<code>40 * 4 * 256 * 3.0624 = 125.435904 PFlops</code></p>
<p>MPE: 32KB L1I, 32 KB L1D, 256 KB L2(中文文献里写的是 512 KB)。乱序执行，4 译码，7 发射（5 整数 2 浮点）。指令预取，分支预测，寄存器重命名，预测执行。5 条整数流水线，2 条 256 位 SIMD 浮点流水线。</p>
<p>CPE：16KB L1I，无 DCache，有 64KB 可重构局部数据存储器（SPM scratch pad memory/LDM local data memory）。2 译码 2 发射，乱序执行，1 条 256 位 SIMD 流水线，1 条整数流水线。不同精度的 SIMD 宽度不同，单精度浮点运算 128 位（4 个单精度），双精度浮点运算 256 位（4 个双精度）。从 SPM 每个周期可以读取 32 字节的数据（正好一个 SIMD 寄存器）。</p>
<p>每个 core group 中还有一个 MC（Memory Controller），连接 8GB DDR3 memory，每个 MC 内存带宽 <code>128 bit * 2133 MT/s = 34.128 GB/s</code>，单节点内存带宽 <code>4 * 34.128 = 136.512 GB/s</code>。在 Stream Triad 测试，每个 core group 用 DMA 从内存到 SPM 传输数据带宽为 22.6 GB/s，而全局读写 gload/gstore 带宽只有 1.5 GB/s。访问全局内存需要 120+ 个周期。</p>
<p>8x8 矩阵中的从核可以在同行和同列方向上进行低延迟和高带宽的数据传递：2 个从核点对点通信延迟不超过 11 个周期，单个 core group 寄存器通信集合带宽达到 637 GB/s。</p>
<p>28nm 工艺流片，芯片 die 面积超过 500 mm^2，峰值功耗 292.7W，峰值能效比达 10.559 GFLOPS∕W（HPL 6.05 GFLOPS/W）。</p>
<h3 id="sw26010psw26016pro"><a class="toclink" href="../../hardware/2021/12/04/sunway/#sw26010psw26016pro">SW26010P(SW26016pro)</a></h3>
<p>SW26010P 是升级版 SW26010，目前信息还比较少，从上面的论文里可以推断出的区别：</p>
<ol>
<li>每个 node 从 4 个 core group 升级到 6 个，一共有 <code>6 * (8 * 8 + 1) = 390</code> 个核心。峰值双精度浮点性能 <code>6 * 8 * 8 * 11.6 + 6 * 23.2 = 4.5936 TFlops</code>。SIMD 宽度扩展到 512 位，但可能没有增加双精度浮点计算部件：单精度浮点性能 14 TFlops，半精度浮点性能 53 TFlops。</li>
<li>每个 MC 连接了 16 GB DDR4 内存，带宽是 <code>128 bit * 3200 MT/s = 51.2 GB/s</code>；单节点总内存 96 GB，总内存带宽 <code>51.2 * 6 = 307.2 GB/s</code>。</li>
<li>每个 CPE 的局部存储（LDM）从 64KB 升级到 256KB。</li>
<li>CPE 之间的通信可以通过 RMA 进行，而之前的 SW26010 只能在同一行/列之间进行寄存器通信。</li>
</ol>
<h3 id="sw52020"><a class="toclink" href="../../hardware/2021/12/04/sunway/#sw52020">SW52020</a></h3>
<p>在新闻稿和 Sunway supercomputer architecture towards exascale computing: analysis and practice 文章中出现，没有在今年发出来的论文里实际采用，名称可能是新闻稿自己编的，我猜可能没有实际采用，而是做了 SW26010P。和 SW26010 区别：</p>
<ol>
<li>Core Group 从 4 个提升到了 8 个，所以每个 node 有 <code>8 * (8 * 8 + 1) = 520</code> 个核心。</li>
<li>MPE 和 CPE 向量宽度从 256 位扩展到了 512 位。添加了 16 位半精度浮点支持。</li>
<li>每个 node 提供超过 12 TFlops 的双精度浮点性能。应该是靠两倍的 Core Group，乘上两倍的向量计算宽度，达到四倍的性能。</li>
</ol>
<nav class="md-post__action">
<a href="../../hardware/2021/12/04/sunway/">
        继续阅读
      </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2021-10-18 00:00:00">2021年10月18日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="../../category/hardware/">hardware</a></li>
<li class="md-meta__item">
            
              需要 6 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="rocket-chip-on-vcu128"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/">移植系统到 Rocket Chip on VCU128</a></h2>
<h3 id="_1"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#_1">背景</a></h3>
<p>最近需要在 VCU128 上搭建一个 SOC，然后想到可以把 OpenSBI、U-Boot 和 Linux 移植到这个平台上方便测试，于是又开始折腾这些东西。代码仓库都已经开源：</p>
<ul>
<li><a href="https://github.com/jiegec/rocket-chip-vcu128">rocket-chip-vcu128</a></li>
<li><a href="https://github.com/jiegec/opensbi/tree/rocket-chip-vcu128">opensbi</a></li>
<li><a href="https://github.com/jiegec/u-boot/tree/rocket-chip-vcu128">u-boot</a></li>
<li><a href="https://github.com/jiegec/linux/tree/rocket-chip-vcu128">linux</a></li>
</ul>
<h3 id="rocket-chip-on-vcu128_1"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#rocket-chip-on-vcu128_1">Rocket Chip on VCU128</a></h3>
<p>第一部分是基于之前 <a href="https://github.com/jiegec/rocket2thinpad">rocket2thinpad</a> 在 Thinpad 上移植 Rocket Chip 的经验，做了一些更新，主要是因为 VCU128 的外设不大一样，同时我也要运行更复杂的程序，主要做了这些事情：</p>
<ol>
<li>添加了 VCU128 的内存和外设：HBM、SPI、I2C、UART、ETH</li>
<li>打开了更多核心选项：S-mode 和 U-mode</li>
</ol>
<p>主要踩过的坑：</p>
<ol>
<li>BSCAN 不工作，估计是因为一些参数不对，@jsteward 之前在 zcu 平台上做了一些测试，估计要用类似的办法进行修改；我最后直接去掉了这部分逻辑</li>
<li>这个板子的 PHY RESET 信号要通过 I2C 接口访问 TI 的 Port Expander，所以没法直接连，要通过 gpio 输出来手动 reset</li>
<li>SPI Startup Flash 的时序配置，见我之前的<a href="../../hardware/2021/09/27/xilinx-axi-quad-spi-timing/">博客</a></li>
<li>Xilinx PCS/PMA IP 也会自己挂一个设备到 MDIO bus 上，应该有自己的 PHY 地址，而不要和物理的 PHY 冲突</li>
</ol>
<h3 id="u-boot"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#u-boot">U-Boot</a></h3>
<p>在 U-Boot 上花了比较多的时间，用它的目的主要是：</p>
<ol>
<li>BootROM 中的代码只支持从串口加载程序，如果后续要加载 Linux 内核等软件，性能太差。</li>
<li>U-Boot 驱动比较完善，而且 dts 也可以很容易地迁移到 Linux 中</li>
<li>有一些可以参考的资料</li>
</ol>
<p>移植的时候，首先新建一个自定义的 board，然后自己写 defconfig 和 dts，其中 dts 可以参考 rocket chip 生成的 dts 文件。然后，按照各个外设的 device tree binding 去写，然后打开/关闭各个 CONFIG 开关。</p>
<p>对代码主要的改动是，实现了 DCache 的 flush 功能，因为以太网部分用了 DMA，所以要让外设看到内存的更改，这里采用的是 SiFive 的扩展指令 <code>cflush.d.l1</code>。由于编译器还不支持这个指令，就按照网上的方式去构造了汇编指令。实现完成以后，就可以用网络了。</p>
<p>一开始的时候，为了简单，直接在 M-mode 中运行 U-Boot，这样不需要 OpenSBI，同时 DTB 也是内置的。但后续为了运行 Linux，还是需要一个 SBI 实现：OpenSBI，然后在 S-mode 中运行 U-Boot，再引导到 Linux。</p>
<p>此外还花了很多努力来缩小 binary 大小，首先可以用 <code>nm --size -r u-boot | head -20</code> 来找到比较大的一些符号，不考虑其中 BSS 的部分（type=b），主要看哪些代码/数据比较占空间。</p>
<p>UPDATE: U-Boot 在 v2022.01 版本<a href="https://github.com/u-boot/u-boot/commit/eeaa3fe65270758ab0bdb1515e14f9bf936d3a25">修复了一个 BUG</a>，之前的版本在 riscv 架构下没有 reserve lmb region，使得加载 initrd 的时候，会覆盖掉自己的栈空间，这解释了之前的诸多玄学内存问题，升级到 v2022.01 后就好了。</p>
<h3 id="opensbi"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#opensbi">OpenSBI</a></h3>
<p>OpenSBI 移植比较简单，直接参考 template 修改即可，主要就是串口的配置，其他基本不用改。然后，我把 U-Boot 作为 OpenSBI 的 Payload 放到 OpenSBI 的后面，此时要把 U-Boot 配置为 S-mode 模式。接着，遇到了新的问题：<code>cflush.d.l1</code> 指令只能在 M-mode 用，因此我在 OpenSBI 代码中处理了 trap，转而在 M-mode 里面运行这条指令。这样，就可以在 S-mode 里刷新 Cache 了。</p>
<h3 id="linux"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#linux">Linux</a></h3>
<p>Linux 目前可以 boot 到寻找 init，还没有碰文件系统，之后计划用 buildroot 打一个 initramfs 出来。为了在 U-Boot 中启动 Linux，用 U-Boot 的 mkimage 工具生成了 FIT 格式的 uImage，里面打包了 kernel image 和 dtb，就可以用 bootm 命令启动了，注意地址不要和加载地址重复。</p>
<p>此外还遇到一个坑：RV64 里面 Linux dts 的 address cell 得是 2（对应 64 位），否则会有错误。但 U-Boot 对这个没有做要求。</p>
<h3 id="_2"><a class="toclink" href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/#_2">缓存一致性</a></h3>
<p>一开始的时候，AXI DMA 直接接到内存上，所以与 CPU 缓存是不一致的，网卡驱动需要经常地刷缓存。在 Rocket Chip 上，可以用 sifive 自己的 cflush 指令来刷缓存，但是它只能在 M 态执行，同时又支持虚拟地址，这种奇怪的设计就使得要在 OpenSBI，U-Boot 和 Linux 三处都添加逻辑：OpenSBI 处理 illegal instruction，如果发现是 cflush 指令，就再次 cflush；U-Boot 和 Linux 修改驱动，在合适的地方添加 cflush 指令。U-Boot 驱动比较简单，工作得比较好，但是 Linux 的网卡驱动怎么都改不好。</p>
<p>最后决定，打开 Rocket Chip 的 Frontend Bus，添加一个 AXI Slave 接口，然后让 AXI DMA 通过 AXI Slave 接入到 Rocket Chip 中，然后通过 TLBroadcast 实现缓存一致性。这样软件实现会比较简单，但是硬件就更复杂了。</p>
<nav class="md-post__action">
<a href="../../hardware/2021/10/18/port-system-to-rocket-chip-on-vcu128/">
        继续阅读
      </a>
</nav>
</div>
</article>
<nav class="md-pagination">
<a class="md-pagination__link" href="../..">1</a> <span class="md-pagination__dots">..</span> <a class="md-pagination__link" href="../7/">7</a> <a class="md-pagination__link" href="../8/">8</a> <span class="md-pagination__current">9</span> <a class="md-pagination__link" href="../10/">10</a> <a class="md-pagination__link" href="../11/">11</a> <span class="md-pagination__dots">..</span> <a class="md-pagination__link" href="../36/">36</a>
</nav>
</div>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="下一页: 关于" class="md-footer__link md-footer__link--next" href="../../about/" rel="next">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                关于
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/jiegec" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.footer", "content.code.copy", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.780af0f4.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
<script src="../../assets/javascripts/bundle.f11ae8b1.min.js"></script>
<script src="../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.1.0/skins/default.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.1.0/wavedrom.min.js"></script>
</body>
</html>