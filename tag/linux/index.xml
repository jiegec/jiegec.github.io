<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 <title>Tag - linux</title>
 <link href="https://jiegec.me/tag/linux/index.xml" rel="self"/>
 <link href="https://jiegec.me/tag/linux.html"/>
 <updated>2018-10-07T22:32:08+08:00</updated>
 <id>https://jiegec.me/tag/linux.html</id>
 <author>
   <name>Jiege Chen</name>
 </author>
 
 <entry>
   <title>构建简易的 initramfs</title>
   <link href="https://jiegec.me/os/2018/07/16/build-custom-initramfs/"/>
   <updated>2018-07-16T03:43:00+08:00</updated>
   <id>https://jiegec.me/os/2018/07/16/build-custom-initramfs</id>
   <content type="html">一直对 Linux 的启动很感兴趣，但对 initrd 和 initramfs 等概念不大了解，于是上网找了资料，自己成功地看到了现象。

参考资料：
[Build and boot a minimal Linux system with qemu](http://www.kaizou.org/2016/09/boot-minimal-linux-qemu/)
[Custom Initramfs](https://wiki.gentoo.org/wiki/Custom_Initramfs)
[initramfs vs initrd](https://dazdaztech.wordpress.com/2013/04/04/initrd-vs-initramfs/)
[ramfs, rootfs and initramfs](https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt)
[The Kernel Newbie Corner: &quot;initrd&quot; and &quot;initramfs&quot;-- What's Up With That?](https://www.linux.com/learn/kernel-newbie-corner-initrd-and-initramfs-whats)

具体步骤：
```shell
$ cat hello.c
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int main() {
    for (;;) {
        printf(&quot;Hello, world!\n&quot;);
    }
}
$ gcc -static hello.c -o init
$ echo init | cpio -o -H newc | gzip &gt; initrd
$ qemu-system-x86_64 -kernel /boot/vmlinuz-linux -initrd initrd -nographic -append 'console=ttyS0'
# Use C-a c q u i t &lt;Enter&gt; to exit
```

可以看到过一会（三四秒？），可以看到满屏的 Hello world 在输出。
</content>
 </entry>
 
 <entry>
   <title>在脚本中寻找 X11 的 DISPLAY 和 XAUTHORITY</title>
   <link href="https://jiegec.me/programming/2018/05/11/finding-x11-display-and-xauthority/"/>
   <updated>2018-05-11T14:21:00+08:00</updated>
   <id>https://jiegec.me/programming/2018/05/11/finding-x11-display-and-xauthority</id>
   <content type="html">之前在搞一个小工具，在里面需要访问 X11 server ，但是访问 X11 server 我们需要两个东西：DISPLAY和XAUTHORITY两个环境变量。但是，由于它们在不同的发型版和Display Manager下都有些不同，所以花了不少功夫才写了一些。

为了验证我们是否可以连上 X11 server， 我们使用这一句：
```bash
DIMENSIONS=$(xdpyinfo | grep 'dimensions:' | awk '{print $2;exit}')
```

它尝试打开当前的 DISPLAY，并且输出它的分辨率。接下来，我对不同的一些发型版，综合网上的方法，尝试去找到正确的环境变量。

对于 Debian:
```bash
DISPLAY=$(w -hs | awk -v tty=&quot;$(cat /sys/class/tty/tty0/active)&quot; '$2 == tty &amp;&amp; $3 != &quot;-&quot; {print $3; exit}')
USER=$(w -hs | awk -v tty=&quot;$(cat /sys/class/tty/tty0/active)&quot; '$2 == tty &amp;&amp; $3 != &quot;-&quot; {print $1; exit}')
eval XAUTHORITY=~$USER/.Xauthority
export DISPLAY
export XAUTHORITY
DIMENSIONS=$(xdpyinfo | grep 'dimensions:' | awk '{print $2;exit}')
```

对于 Archlinux：
```bash
DISPLAY=$(w -hs | awk 'match($2, /:[0-9]+/) {print $2; exit}')
USER=$(w -hs | awk 'match($2, /:[0-9]+/) {print $1; exit}')
eval XAUTHORITY=/run/user/$(id -u $USER)/gdm/Xauthority
export DISPLAY
export XAUTHORITY
DIMENSIONS=$(xdpyinfo | grep 'dimensions:' | awk '{print $2;exit}')
```

最后一种情况很粗暴的，直接找进程拿：
```bash
XAUTHORITY=$(ps a | awk 'match($0, /Xorg/) {print $0; exit}' | perl -n -e '/Xorg.*\s-auth\s([^\s]+)\s/ &amp;&amp; print $1')
PID=$(ps a | awk 'match($0, /Xorg/) {print $1; exit}')
DISPLAY=$(lsof -p $PID | awk 'match($9, /^\/tmp\/\.X11-unix\/X[0-9]+$/) {sub(&quot;/tmp/.X11-unix/X&quot;,&quot;:&quot;,$9); print $9; exit}')
export DISPLAY
export XAUTHORITY
DIMENSIONS=$(xdpyinfo | grep 'dimensions:' | awk '{print $2;exit}')
```

中间混用了大量的 awk perl 代码，就差 sed 了。牺牲了一点可读性，但是开发起来比较轻松。
</content>
 </entry>
 
 <entry>
   <title>在 macOS 和 Linux 之间搭建 tinc 网络</title>
   <link href="https://jiegec.me/networking/2018/05/09/tinc-between-macos-and-linux/"/>
   <updated>2018-05-09T10:02:00+08:00</updated>
   <id>https://jiegec.me/networking/2018/05/09/tinc-between-macos-and-linux</id>
   <content type="html">一直听说 tinc 比较科学，所以尝试自己用 tinc 搭建一个网络。这里，macOS 这段没有固定 IP 地址，Linux 机器有固定 IP 地址 linux_ip 。假设网络名称为 example , macOS 端名为 macos 地址为 192.168.0.2, linux 端名为 linux 地址为 192.168.0.1。

在 macOS 上配置：
```shell
brew install tinc
mkdir -p /usr/local/etc/tinc/example
```

新建 /usr/local/etc/tinc/example/tinc.conf:
```
Name = macos
Device = utun0 # use an unused number
ConnectTo = linux
```

编辑 /usr/local/etc/tinc/example/tinc-up:
```
#!/bin/sh
ifconfig $INTERFACE 192.168.0.2 192.168.0.1 mtu 1500 netmask 255.255.255.255
```

和 /usr/local/etc/tinc/example/tinc-down:
```
#!/bin/sh
ifconfig $INTERFACE down
```

还有 /usr/local/etc/tinc/example/subnet-up:
```
#!/bin/sh
[ &quot;$NAME&quot; = &quot;$NODE&quot; ] &amp;&amp; exit 0
/usr/local/opt/iproute2mac/bin/ip route add $SUBNET dev $INTERFACE
```

以及 /usr/local/etc/tinc/example/subnet-down:
```
#!/bin/sh
[ &quot;$NAME&quot; = &quot;$NODE&quot; ] &amp;&amp; exit 0
/usr/local/opt/iproute2mac/bin/ip route del $SUBNET dev $INTERFACE
```

然后将它们都设为可执行的：
```
chmod +x tinc-up
chmod +x tinc-down
chmod +x subnet-down
chmod +x subnet-down
```

编辑 /usr/local/etc/tinc/example/macos:
```
Port = 655
Subnet = 192.168.0.1/24
```

执行 `tincd -n example -K` 生成密钥。

到 Linux 机器上：
编辑以下文件：
```shell
$ mkdir -p /etc/tinc/example/hosts
$ cat /etc/tinc/example/tinc.conf
Name = linux
$ cat /etc/tinc/example/tinc-up
$!/bin/sh
ip link set $INTERFACE up
ip addr add 192.168.0.1/24 dev $INTERFACE
$ cat /etc/tinc/example/tinc-down
$!/bin/sh
ip addr del 192.168.0.1/24 dev $INTERFACE
ip link set $INTERFACE down
$ cat /etc/tinc/example/hosts/linux
Address = linux_ip
Port = 655
Subnet = 192.168.0.1/24
$ tincd -n example -K
```

接着，把 linux 上 /etc/tinc/example/hosts/linux 拷贝到 macos 的 /usr/local/etc/tinc/example/hosts/linux ，然后把 macos 上 /usr/local/etc/tinc/example/hosts/macos 拷贝到 /etc/tinc/example/hosts/macos 。在两台机器上都 `tinc -n example -D -d3` 即可看到连接的建立，通过 ping 即可验证网络建立成功。

2018-05-29 Update: Android 上，利用 Tinc GUI 也可以把 Tinc 运行起来，只是配置不大一样：

```shell
$ cat tinc.conf
Name = example
Device = /dev/tun
Mode = switch
ConnectTo = remote
ScriptsInterpreter = /system/bin/sh
$ cat tinc-up
#!/bin/sh
ip link set $INTERFACE up
ip addr add local_ip/24 dev $INTERFACE
$ cat tinc-down
#!/bin/sh
ip addr del local_ip/24 dev $INTERFACE
ip link set $INTERFACE down
$ cat subnet-up
$!/bin/bash
[ &quot;$NAME&quot; = &quot;$NODE&quot; ] &amp;&amp; exit 0
ip route add $SUBNET dev $INTERFACE metric $WEIGHT table local
$ cat subnet-down
#!/bin/bash
[ &quot;$NAME&quot; = &quot;$NODE&quot; ] &amp;&amp; exit 0
ip route del $SUBNET dev $INTERFACE table local
```

注意 table local 的使用。需要 Root 。
</content>
 </entry>
 
 <entry>
   <title>使用 Nginx 转发 VMware ESXi</title>
   <link href="https://jiegec.me/networking/2018/05/08/nginx-proxy-vmware-esxi/"/>
   <updated>2018-05-08T19:26:00+08:00</updated>
   <id>https://jiegec.me/networking/2018/05/08/nginx-proxy-vmware-esxi</id>
   <content type="html">我们的 VMware ESXi 在一台 NAT Router 之后，但是我们希望通过域名可以直接访问 VMware ESXi 。我们首先的尝试是，把 8443 转发到它的 443 端口，比如：

```shell
socat TCP-LISTEN:8443,reuseaddr,fork TCP:esxi_addr:443
```

它能工作地很好（假的，如果你把 8443 换成 9443 它就不工作了），但是，我们想要的是，直接通过 esxi.example.org 就可以访问它。于是，我们需要 Nginx 在其中做一个转发的功能。在这个过程中遇到了很多的坑，最后终于是做好了 （VMware Remote Console等功能还不行，需要继续研究）。

首先讲讲为啥把 8443 换成 9443 不能工作吧 -- 很简单，ESXi 的网页界面会请求 8443 端口。只是恰好我用 8443 转发到 443， 所以可以正常工作。这个很迷，但是测试的结果确实如此。VMware Remote Console 还用到了别的端口，我还在研究之中。

来谈谈怎么配置这个 Nginx 转发吧。首先是 80 跳转 443:
```
server {
        listen 80;
        listen 8080;
        server_name esxi.example.org;

        return 301 https://$host$request_uri;
}
```

这个很简单，接下来是转发 443 端口：
```

server {
        listen 443 ssl;
        server_name esxi.example.org;
        ssl_certificate /path/to/ssl/cert.pem;
        ssl_certificate_key /path/to/ssl/key.pem;

        location / {
                proxy_pass https://esxi_addr;
                proxy_ssl_verify off;
                proxy_ssl_session_reuse on;
                proxy_set_header Host $http_host;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
        }
}
```

此时，打开 https://esxi.example.org 就能看到登录界面了。但是仍然无法登录。从 DevTools 看错误，发现它请求了 8443 端口。于是进行转发：
```
server {
        listen 8443 ssl;
        server_name esxi.example.org;
        ssl_certificate /path/to/ssl/cert.pem;
        ssl_certificate_key /path/to/ssl/key.pem;


        location / {
                if ($request_method = 'OPTIONS') {
                        add_header 'Access-Control-Allow-Origin' 'https://esxi.example.org';
                        add_header 'Access-Control-Allow-Credentials' 'true';
                        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
                        add_header 'Access-Control-Max-Age' 1728000;
                        add_header 'Access-Control-Allow-Headers' 'VMware-CSRF-Token,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Cookie,SOAPAction';
                        add_header 'Content-Type' 'text/plain; charset=utf-8';
                        add_header 'Content-Length' 0;
                        return 204;
                }

                add_header 'Access-Control-Allow-Origin' 'https://esxi.example.org';
                add_header 'Access-Control-Allow-Credentials' 'true';
                proxy_pass https://esxi_addr:443;
                proxy_ssl_verify off;
                proxy_ssl_session_reuse on;
                proxy_set_header Host $http_host;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
        }
}
```

主要麻烦的是配置 CORS 的相关策略。我也是看了 DevTools 的错误提示半天才慢慢写出来的。这样配置以后，就可以成功登录 VMware ESXi 了。

20:02 更新：现在做了 WebSocket 转发，目前可以在浏览器中打开 Web Console 了。但是，在访问 https://esxi.example.org/ 的时候还是会出现一些问题，然而 https://esxi.example.org:8443/ 是好的。

转发 WebSocket：
```
map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
}

server {
        listen 8443 ssl;
        server_name esxi.example.org;
        ssl_certificate /path/to/ssl/cert.pem;
        ssl_certificate_key /path/to/ssl/key.pem;


        location / {

                if ($request_method = 'OPTIONS') {
                        add_header 'Access-Control-Allow-Origin' 'https://esxi.example.org';
                        add_header 'Access-Control-Allow-Credentials' 'true';
                        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
                        add_header 'Access-Control-Max-Age' 1728000;
                        add_header 'Access-Control-Allow-Headers' 'VMware-CSRF-Token,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Cookie,SOAPAction';
                        add_header 'Content-Type' 'text/plain; charset=utf-8';
                        add_header 'Content-Length' 0;
                        return 204;
                }

                add_header 'Access-Control-Allow-Origin' 'https://esxi.example.org' always;
                add_header 'Access-Control-Allow-Credentials' 'true' always;

                proxy_pass https://esxi_addr:443;
                proxy_ssl_verify off;
                proxy_ssl_session_reuse on;
                proxy_set_header Host $http_host;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection $connection_upgrade;
        }
}
```

20:29 更新：找到了 VMware Remote Console 的端口：902，用 iptables 进行 DNAT 即可：
```shell
iptables -A PREROUTING -i wan_interface -p tcp -m tcp --dport 902 -j DNAT --to-destination esxi_addr:902
```

2018-05-09 08:07 更新：最后发现，还是直接隧道到内网访问 ESXi 最科学。或者，让 443 重定向到 8443 ：
```
server {
        listen 443 ssl;
        server_name esxi.example.org;
        ssl_certificate /path/to/ssl/cert.pem;
        ssl_certificate_key /path/to/ssl/key.pem;

        return 301 https://$host:8443$request_uri;
}
```
这样，前面也不用写那么多 CORS 的东西了。
</content>
 </entry>
 
 <entry>
   <title>搭建 FTP server behind NAT</title>
   <link href="https://jiegec.me/networking/2018/05/08/ftp-behind-nat/"/>
   <updated>2018-05-08T13:34:00+08:00</updated>
   <id>https://jiegec.me/networking/2018/05/08/ftp-behind-nat</id>
   <content type="html">我们出现新的需求，要把以前的 FTP 服务器迁移到 NAT 之后的一台机器上。但是，FTP 不仅用到 20 21 端口， PASV 还会用到高端口，这给端口转发带来了一些麻烦。我们一开始测试，直接在 Router 上转发 20 和 21 端口到 Server 上。但是很快发现， Filezilla 通过 PASV 获取到地址为 （内网地址，端口高8位，端口低8位），然后，Filezilla 检测出这个地址是内网地址，于是转而向 router_ip:port 发包，这自然是不会得到结果的。

此时我们去网上找了找资料，找到了一个很粗暴的方法：
```shell
iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 20 -j DNAT --to-destination internal_ip:20
iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 21 -j DNAT --to-destination internal_ip:21
iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 1024:65535 -j DNAT --to-destination internal_ip:1024-65535
```


有趣地是， macOS 自带的 ftp 命令（High Sierra似乎已经删去）可以正常使用。研究发现，它用 EPSV（Extended Passive Mode） 代替 PASV ，这里并没有写内网地址，因而可以正常使用。

这么做， Filezilla 可以成功访问了。但是，用其它客户端的时候，它会直连那个内网地址而不是 Router 的地址，于是还是连不上。而且，使用了 1024-65535 的所有端口，这个太浪费而且会影响我们其它的服务。

我们开始研究我们 FTP 服务器(pyftpdlib)的配置。果然，找到了适用于 FTP behind NAT 的相关配置：
```
     - (str) masquerade_address:
        the &quot;masqueraded&quot; IP address to provide along PASV reply when
        pyftpdlib is running behind a NAT or other types of gateways.
        When configured pyftpdlib will hide its local address and
        instead use the public address of your NAT (default None).
     - (dict) masquerade_address_map:
        in case the server has multiple IP addresses which are all
        behind a NAT router, you may wish to specify individual
        masquerade_addresses for each of them. The map expects a
        dictionary containing private IP addresses as keys, and their
        corresponding public (masquerade) addresses as values.
     - (list) passive_ports:
        what ports the ftpd will use for its passive data transfers.
        Value expected is a list of integers (e.g. range(60000, 65535)).
        When configured pyftpdlib will no longer use kernel-assigned
        random ports (default None).
```

于是，我们配置了 `masquerade_address` 使得 FTP 服务器会在 PASV 中返回 Router 的地址，并且在 `passive_ports` 中缩小了 `pyftpdlib` 使用的端口范围。

进行配置以后，我们在前述的 iptables 命令中相应修改了端口范围，现在工作一切正常。
</content>
 </entry>
 
 <entry>
   <title>使用 iptables 和策略路由进行带源地址的 forwarding</title>
   <link href="https://jiegec.me/networking/2018/05/06/nat-forwarding-with-src-address/"/>
   <updated>2018-05-06T14:07:00+08:00</updated>
   <id>https://jiegec.me/networking/2018/05/06/nat-forwarding-with-src-address</id>
   <content type="html">陈老师打开他的服务器，突然发现 CPU 莫名高负载，然后发现是有一个用户被远程登录拿来挖矿了。但是这台机器在 NAT 后，所以登录的源地址全是 NAT 路由，所以不知道对方的地址是什么。我们为了能使用 fail2ban 来禁用多次尝试失败的 IP ，但又不想因为别人把 NAT 路由的地址给禁了，这样我们自己也用不了了。所以必须要让这台机器能够知道 ssh 的源地址，我们现在简单的 socat 方案不能满足这个需求。

需求：

1. 可以在外网连 NAT 路由的高端口（如2222）来访问这台机器。
2. 在内网中，既可以直接连它的内网地址，也可以连 NAT 路由的高端口来访问这台服务器。此时，由于连 ssh 的机器就在同一个子网中，如果保留了源地址，服务器发的包会直接回来不经过 NAT 。所以我们还是保留了 socat 的方案。

实现方法：

在 NAT Router 上配置 DNAT ，这样发到 NAT Router 上的包就可以转发到服务器上：

```shell
iptables -t nat -A PREROUTING -i external_interface -p tcp -m tcp --dport 2222 -j DNAT --to-destination internal_server_ip:22
```

但是，从服务器回来的包到了 NAT Router 上后，由于路由表的配置问题，默认的路由并不能把包送达对方。

方法1:
我们首先给包打上 mark：

```shell
iptables -t mangle -A PREROUTING -i internal_interface -p tcp -m tcp --sport 22 -j MARK --set-mark 0x2222
```

然后配置策略路由：

```shell
ip rule add fwmark 0x2222 table 2222
ip route add table 2222 default via gateway_address
```

方法2: (UPD 2018-07-07)
利用 `ip rule` 直接达成同样的效果

```shell
ip rule add from internal_ip/prefix table 2222
# or
ip rule add iif internal_interface table 2222
ip route add table 2222 default via gateway_address
```

这样就可以保证 ssh 的回包可以原路返回了。

由于前面提到的原因，上面我们配置的 DNAT 规则只对外网过来的包有效。为了内网的访问，我们仍然采用了 socat 的方式：

```shell
socat TCP-LISTEN:2222,reuseaddr,fork TCP:internal_server_ip:22
```

从不同的机器测试，都可以在 `who` 看到，地址确实是我们想看到的源地址。接下来配置 `fail2ban `即可。
</content>
 </entry>
 
</feed>
