<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 <title>Tag - grafana</title>
 <link href="https://jiege.ch/tag/grafana/index.xml" rel="self"/>
 <link href="https://jiege.ch/tag/grafana.html"/>
 <updated>2019-01-26T12:36:59+08:00</updated>
 <id>https://jiege.ch/tag/grafana.html</id>
 <author>
   <name>Jiege Chen</name>
 </author>
 
 <entry>
   <title>Grafana 中可视化 Ping 时把 Timeout 显示为指定值</title>
   <link href="https://jiege.ch/software/2019/01/13/grafana-influxdb-visualize-ping/"/>
   <updated>2019-01-13T18:36:00+08:00</updated>
   <id>https://jiege.ch/software/2019/01/13/grafana-influxdb-visualize-ping</id>
   <content type="html">&lt;p&gt;刚遇到一个需求，就是用 Telegraf 收集 ping 信息，然后在 Grafana 里可视化当前的延迟，如果超时了，就显示一个指定值，如 999 ，这样就可以放到一个 Gauge 里面可视化了。但是，问题在于，Telegraf 的 ping input 在超时的时候只会在 result_code 里写一个 &lt;a href=&quot;https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping&quot;&gt;2&lt;/a&gt; ，其他项都是空的，因而如果直接用 GROUP BY time(interval) fill(999) 会导致最新的一个数据经常得到 999 。这意味着需要根据 “result_code” 来进行区分 Timeout 的情况。最后捣腾了很久，得到了这个方案：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; select &quot;average_response_ms&quot; * (2 - &quot;result_code&quot;) / 2 + &quot;result_code&quot; / 2 * 999 from (select &quot;average_response_ms&quot;, &quot;result_code&quot; from ping where $timeFilter fill(0))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后的方法很粗糙：当 “result_code” 是 0 也就是成功的时候，得到延迟，而当 “result_code” 是 2 也就是超时的时候，直接得到 999 。这样就解决了这个问题。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Grafana Variable 的 regex 过滤方式</title>
   <link href="https://jiege.ch/software/2019/01/10/grafana-variable-regex-exclusion/"/>
   <updated>2019-01-10T12:47:00+08:00</updated>
   <id>https://jiege.ch/software/2019/01/10/grafana-variable-regex-exclusion</id>
   <content type="html">&lt;p&gt;用 InfluxDB 收集到 Mountpoint 数据的时候，经常会掺杂一些不关心的，如 TimeMachine ，KSInstallAction 和 AppTranslocation 等等。所以，为了在 Variables 里过滤掉他们，需要用 Regex 进行处理。&lt;a href=&quot;https://community.grafana.com/t/templating-regex-exclude-not-working/1077/4&quot;&gt;网上&lt;/a&gt;有人提供了方案，就是通过 Negative Lookahead 实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-regexp&quot;&gt;/^(?!.*TimeMachine)(?!.*KSInstallAction)(?!.*\/private)/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就可以把不想看到的这些 mountpoint 隐藏，节省页面空间了。当然了，这里其实也可以用白名单的方法进行处理，直接写 regex 就可以了。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>《加速奔向2019》小程序编写和运营回顾</title>
   <link href="https://jiege.ch/software/2018/12/27/wxapp-recap/"/>
   <updated>2018-12-27T19:56:00+08:00</updated>
   <id>https://jiege.ch/software/2018/12/27/wxapp-recap</id>
   <content type="html">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;关注清华的同学可能知道，昨天，“清华大学”公众号发了一篇名为&lt;a href=&quot;https://mp.weixin.qq.com/s/Kk7FuTefipW4HpQkoF72WA&quot;&gt;《2018，我们共芳华丨@THUers 致相伴一年的你，请查收这份心意》&lt;/a&gt;的推送，内容大概就是，有那么100个新年台历礼品要送出去，大家如果想要的话，就扫描小程序。小程序模仿了火车抢票的病毒式营销的模式，要求大家分享到群聊或者朋友圈，让别人给自己加速，加速到 2019 的前 100 名即可填写信息领取奖品。&lt;/p&gt;

&lt;p&gt;然后大家就在推送里看到了我。就酱。&lt;/p&gt;

&lt;h2 id=&quot;开始&quot;&gt;开始&lt;/h2&gt;

&lt;p&gt;这件事情据说策划了有一段时间了，只是因为各种原因一直没有做，最后这个锅就路由到了我的头上。一开始说就是个加速小程序，逻辑很简单，但后来逐渐发现需求越来越多，主要是界面上的，动画上的，还有一些非技术因素的功能，嗯。这其实算是一个不大好的软件工程案例。&lt;/p&gt;

&lt;h2 id=&quot;过程&quot;&gt;过程&lt;/h2&gt;

&lt;h3 id=&quot;线上的问题与解决方案&quot;&gt;线上的问题与解决方案&lt;/h3&gt;

&lt;p&gt;然后就是上线了。大概是昨天（2018-12-27）中午的时候推送发出去，很快流量就开始来了。很快，在朋友圈看到有同学在转发了，也有人反映说，网络有点卡，加载资源有点多。我去机器上用 iftop 看了下，流量大概是 250Mb/s ，没打到千兆。我一开始看了下，CPU 和内存占用都良好，以为是网络出口限制的问题，就想着没办法了，就这样吧，扛过去再说。不过，忽然有了转机。&lt;/p&gt;

&lt;p&gt;TUNA 技术群里，忽然有人在讨论 SOMAXCONN 的问题，我想到，会不会是有些参数没开够大，导致了性能瓶颈，又受到啊荣的点拨，立马调整了这些变量：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;net.core.somaxconn
fs.file-max
net.core.netdev_max_backlog
net.ipv4.tcp_max_syn_backlog
nginx: worker_rlimit_nofile
nginx: event.worker_connections
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;很快带宽从 200Mb/s 左右打到了 400Mb/s 多，在 iftop 中看到的峰值接近 600Mb/s，见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2018-12-27-20-35-21.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;事后回来看，发现配置一套科学的监控系统真的很有用，如 TCP 连接的状态图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2018-12-27-20-33-10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里最高的黄线代表的是 TIME_WAIT ，意味着很多的 TCP 连接都卡在了等待资源上，而一当我修改参数以后，立刻就降了下来，ESTBALISHED 的连接有了显著的提升。这个问题从另一个图也可以明地看出：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2018-12-27-20-38-07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个图是 TCP Handshake Issues ，可以看到无论是 activeopen 还是 passiveopen ，都很高，意味着这里无论是发还是收都遇到了问题。而修改参数以后，这些问题立马得到了很好的改善。&lt;/p&gt;

&lt;p&gt;其实这些本应该在上线前做好的，但我低估了清华大学的影响力，没有做好相应的准备，还是在优秀的运维人员的指点下得到了较好的效果。&lt;/p&gt;

&lt;h3 id=&quot;用户数据分析&quot;&gt;用户数据分析&lt;/h3&gt;

&lt;p&gt;当然了，除了 Grafana+InfluxDB+Telegraf 这一套监控系统，我们也部署了 ElasticSearch+Logstash+Kibana ，只不过我们还是用 Grafana 做了 ElasticSearch 的前端了。通过对 Nginx 日志的分析，我们得到了这些关键的数据（从12-26 12:00到12-27 12:00一天时间）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2018-12-27-20-48-48.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2018-12-27-20-49-00.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;除了这些，还有很多有趣的数据，例如用户里北京的最多，也可以大致地看出各个地方网络和手机的普及程度；用户使用的手机的机型里前几名都是苹果的，从单项占领了排名的前很多位，之后则是华为小米OPPO等，但总体上反而是安卓用户更多。&lt;/p&gt;

&lt;p&gt;微信小程序官方也提供了一些数据统计可供参考。例如页面的访问次数信息，一共大约有二十多万次，打开小程序有十三万多次，访问人数是五万多，还有女性用户比男性用户多等等。这个时代，有数据确实能够得到许多有价值的判断。&lt;/p&gt;

&lt;h2 id=&quot;反思&quot;&gt;反思&lt;/h2&gt;

&lt;p&gt;这次学到了很多东西，验证了监控系统的必要性，它能够实时看到服务的运行状态并进行调优，事后也可以回过头来进行进一步的分析和总结。不足的是，遇到大客户量的时候，静态资源就应该用 CDN 服务而不应该自己搭建，成本不高而且用户体验会很好。这次后端在数据库操作都用了原子操作，没有出现大的问题，但如果以后遇到更复杂的需求的时候就没有这么容易了。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Grafana 可视化实践：清华大学 2018 年度人物评选</title>
   <link href="https://jiege.ch/software/2018/12/07/grafana-visualize-vote18/"/>
   <updated>2018-12-07T23:03:00+08:00</updated>
   <id>https://jiege.ch/software/2018/12/07/grafana-visualize-vote18</id>
   <content type="html">&lt;p&gt;最近这段时间，清华内部正在投票选出今年的年度人物，想到最近刚好在学习使用 Grafana+InfluxDB+Telegraf 全家桶，于是想着能不能写个爬虫把数据都拿下来，然后用 Grafana 画出来，就可以得到一个投票随时间变化的趋势。爬虫很简单，就是登录，获取页面信息，然后按照 InfluxDB 的输入格式进行输出即可。代码放在了 &lt;a href=&quot;https://github.com/jiegec/student-tsinghua-vote18&quot;&gt;jiegec/student-tsinghua-vote18&lt;/a&gt; 下。&lt;/p&gt;

&lt;p&gt;接着就是用 Grafana 进行可视化，大概得到了这样一个曲线：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vote18.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为保护隐私，把名字隐去了。实际上的投票时间是从 12-3 号开始到 12-7号结束，但由于宿舍停电的原因所以采样的点在半夜的时候都没有，所以看起来有点奇怪，但还是能够反应总体的趋势的。比如可以看到前两名很早就一马当先，而后一直遥遥领先，下面的选手则排名变动很大，特别是截止前最后一段时间，大家都在拼命拉票，可见大家都是 DDL 选手啊。如果对上面这个图求个导，看看变化率的话：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/vote18-speed.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这显现出了很有意思的一个趋势，就是每天十二点左右都有一个高峰期，然后在零点前大概熄灯附近的时间也是一个高峰期，另外就是截止前最后的抢票阶段，大家都在疯狂拉票，从中午拉到最后时刻。由于停电的原因，在零点附近的数据都比较的鬼畜，不过影响不大，趋势一目了然。&lt;/p&gt;

&lt;p&gt;Grafana 真香！期望可以学到更多高端的查询语法和可视化的骚操作，现在有很多东西不知道该怎么可视化，比较苦恼，不知道大家有没有什么经验可以分享。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>配置 Grafana+InfluxDB+Telegraf 并添加 MIIO 数据来源</title>
   <link href="https://jiege.ch/software/2018/11/27/grafana-influxdb-telegraf-miio/"/>
   <updated>2018-11-27T20:33:00+08:00</updated>
   <id>https://jiege.ch/software/2018/11/27/grafana-influxdb-telegraf-miio</id>
   <content type="html">&lt;p&gt;之前一直想配一个监控系统，现在有机会了，就简单配了一下。发现真的特别简单，用 Homebrew 安装这三个软件并且都跑起来，然后稍微动一下配置，就可以得到可观的效果了。&lt;/p&gt;

&lt;p&gt;然后想利用 miio 配置一下，把宿舍的空气净化器各项参数拿到，以 Telegraf 的插件形式定时上报，然后通过 Grafana 进行可视化。插件放在了 &lt;a href=&quot;https://github.com/jiegec/tools/blob/master/telegraf/miio.py&quot;&gt;jiegec/tools&lt;/a&gt; 下，就是一个简单的 Python 脚本。配置方法如下：&lt;/p&gt;

&lt;p&gt;编辑 &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/local/etc/telegraf.d/miio.conf&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;[[inputs.exec]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;py&quot;&gt;commands&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;[&quot;/usr/local/bin/python3 /Volumes/Data/tools/telegraf/miio.py MIID_HERE&quot;]&lt;/span&gt;
	&lt;span class=&quot;py&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;5s&quot;&lt;/span&gt;
	&lt;span class=&quot;py&quot;&gt;data_format&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;influx&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;默认了 miio 路径为 &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/local/bin/miio&lt;/code&gt; 。&lt;/p&gt;
</content>
 </entry>
 
</feed>
