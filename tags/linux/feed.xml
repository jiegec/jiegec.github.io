<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linux on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jiege.ch/tags/linux/</link>
    <description>Recent content in linux on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Aug 2019 20:18:00 +0800</lastBuildDate>
    
	<atom:link href="https://jiege.ch/tags/linux/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>在 Linux 下捕获 Framebuffer</title>
      <link>https://jiege.ch/software/framebuffer-capture/</link>
      <pubDate>Mon, 12 Aug 2019 20:18:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/framebuffer-capture/</guid>
      <description>最近需要在 linux 下抓取 Framebuffer 的内容，在网上找到了两种方法，在我这里只有第二、第三种可以成功，没有细究具体原因，可能与我的 Framebuffer 配置有关。方法如下：
 fbgrab ：命令就是 fbgrab image.png ，直接得到 png 文件，格式是对的，但是用软件打开就是一片空白。用 ImageMagick 转换为 jpg可以看到一些内容，但是和实际有些不一样。 fbdump ：命令就是 fbdump &amp;gt; image.ppm ，得到裸的 ppm 文件，图像是正确的，也可以转换为别的格式正常打开。 cat+脚本处理：直接 cat /dev/fb0 &amp;gt; image.rgb ，然后用下面的脚本转换为 png 。由于 Framebuffer 格式为 RGB ，本来 A 所在的 channel 都为 0 ，所以用一些软件直接打开都是空白，只好写了脚本直接跳过 Alpha Channel 。  Framebuffer 配置（ fbset 输出）：
mode &amp;quot;640x480-0&amp;quot; # D: 0.000 MHz, H: 0.000 kHz, V: 0.000 Hz geometry 640 480 1024 480 32 timings 0 0 0 0 0 0 0 accel false rgba 8/16,8/8,8/0,0/0 endmode  转换脚本（参考[Tips] 擷取framebuffer畫面）：</description>
    </item>
    
    <item>
      <title>在 Linux 中用 C 代码获取 DNS 服务器列表</title>
      <link>https://jiege.ch/software/get-resolvers-in-c/</link>
      <pubDate>Tue, 30 Apr 2019 17:39:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/get-resolvers-in-c/</guid>
      <description>最近在做一个作业的时候，发现里面有个步骤是获取 Linux 系统中的 DNS 服务器列表，它的方法很粗暴，直接 cat grep cut 再处理。我就在想有没有完全代码的实现，然后搜了一下，果然有：
#include &amp;lt;resolv.h&amp;gt; // ... res_init(); // _res.nsaddr_list is an array of resolvers  用到了全局变量 _res ，虽然很 hacky ，但是至少是工作的，不清楚兼容性几何。</description>
    </item>
    
    <item>
      <title>使用 Rust 实现 VirtIO 驱动</title>
      <link>https://jiege.ch/programming/2019/01/29/virtio-drivers-implementation/</link>
      <pubDate>Tue, 29 Jan 2019 17:23:00 +0800</pubDate>
      
      <guid>https://jiege.ch/programming/2019/01/29/virtio-drivers-implementation/</guid>
      <description>背景 最近在给 rCore 添加驱动层的支持。一开始是想做网卡驱动，后来发现， qemu-system-riscv32 只支持如下的驱动：
# qemu-system-riscv32 -device help Storage devices: name &amp;quot;scsi-cd&amp;quot;, bus SCSI, desc &amp;quot;virtual SCSI CD-ROM&amp;quot; name &amp;quot;scsi-disk&amp;quot;, bus SCSI, desc &amp;quot;virtual SCSI disk or CD-ROM (legacy)&amp;quot; name &amp;quot;scsi-hd&amp;quot;, bus SCSI, desc &amp;quot;virtual SCSI disk&amp;quot; name &amp;quot;virtio-blk-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-scsi-device&amp;quot;, bus virtio-bus Network devices: name &amp;quot;virtio-net-device&amp;quot;, bus virtio-bus Input devices: name &amp;quot;virtconsole&amp;quot;, bus virtio-serial-bus name &amp;quot;virtio-keyboard-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-mouse-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-serial-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-tablet-device&amp;quot;, bus virtio-bus name &amp;quot;virtserialport&amp;quot;, bus virtio-serial-bus Display devices: name &amp;quot;virtio-gpu-device&amp;quot;, bus virtio-bus Misc devices: name &amp;quot;loader&amp;quot;, desc &amp;quot;Generic Loader&amp;quot; name &amp;quot;virtio-balloon-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-crypto-device&amp;quot;, bus virtio-bus name &amp;quot;virtio-rng-device&amp;quot;, bus virtio-bus  所以要实现网卡的话，只能实现这里的 virtio-net-device ，而 VirtIO 驱动之间有很多共通的地方，于是顺带把 gpu mouse 和 blk 实现了。</description>
    </item>
    
    <item>
      <title>Mac 上安装 Arch Linux ， ZFS 真香</title>
      <link>https://jiege.ch/software/zfs-on-macos-and-linux/</link>
      <pubDate>Mon, 26 Nov 2018 20:51:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/zfs-on-macos-and-linux/</guid>
      <description>最近在 Mac 上装了 Arch Linux ，按照 Mac - Arch Linux Wiki 一路一路走，创建单独的一个 EFI 分区给 Arch Linux 放 GRUB 和内核，一个 ext4 作为根分区。由于 Arch ISO 不支持 Broadcom 的无线网卡，于是先拿 Apple Ethernet Adapter 连到路由器上装机。然后把一些需要的驱动装上了，桌面用的 KDE Plasma ，Trackpad 用的 xf86-input-mtrack-git ， HiDPI 设置为 2x Scale ，各种体验都还可以，就是 Wi-Fi 的 802.1X 没配置好，然后 kwalletd5 老是崩没找到原因。常见的应用除了微信基本都有，也终于可以体验 Steam Play ，利用 Proton 在 Linux 上跑一些只支持 Windows 的游戏，不过我已经很少玩游戏了。
然后我就想，怎么做 macOS 和 Linux 之间的文件共享。典型的操作可能是 exFAT ，但是作为数据盘的话，这还是不大适合。或者就直接用 ext4 ，配合 extFS For Mac by Paragon 使用，也可以，最后我选择了 ZFS 。</description>
    </item>
    
    <item>
      <title>USB/IP 实践</title>
      <link>https://jiege.ch/software/usb-ip/</link>
      <pubDate>Tue, 20 Nov 2018 18:50:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/usb-ip/</guid>
      <description>之前一直想玩 USB/IP ，但是一直没有找俩 Linux 设备然后共享，今天终于尝试了一下，没有什么大问题。这次采用的设备是 Raspberri Pi 3 和 SaltedFish Pi 。一开始尝试从后者向前者共享，但总是出现这个错误：
libusbip: error: udev_device_get_sysattr_value failed usbip: error: open vhci_driver  然后我反过来做就好了，比较神奇。
主要过程如下：
 pacman -S usbip 安装用户态软件 systemctl enable --now usbipd 启动 USB/IP 的端口监听 daemon usbip list -l 查看本地有哪些 USB 设备可以共享 usbip bind -b [BUS_ID] 把指定的 USB 设备共享出去，其中 BUS_ID 从上个命令中查看 usbip list -r [IP] 在另一个设备上查看这个设备共享的 USB 设备，可以看到许多信息 usbip attach -r [IP] -b [BUS_ID] 把对方共享的 USB 设备 attach 到本地  效果：把一个 U 盘成功映射到了本地：</description>
    </item>
    
    <item>
      <title>咸鱼派的启动配置</title>
      <link>https://jiege.ch/hardware/salted-fish-pi/</link>
      <pubDate>Mon, 05 Nov 2018 22:17:00 +0800</pubDate>
      
      <guid>https://jiege.ch/hardware/salted-fish-pi/</guid>
      <description>最近刚拿到了一个咸鱼派的测试板子，准备自己把 U-Boot 和 Linux 内核这一套东西跑通，都用主线的东西，尽量减少魔改的部分。首先是编译 u-boot ，我用的是现在的 master 分支的最新版 99431c1c ：
$ # Archlinux $ sudo pacman -Sy arm-none-eabi-gcc $ make LicheePi_Zero_defconfig $ make ARCH=arm CROSS_COMPILE=arm-none-eabi- -j24  这时候会得到一个 u-boot-sunxi-with-spl.bin 的文件。我们只要把它写到 SD 卡的 8192 偏移处，就可以把 U-Boot 跑起来了：
$ diskutil unmountDisk /dev/disk4 $ sudo dd if=u-boot-sunxi-with-spl.bin of=/dev/disk4 bs=1024 seek=8  接着我们做一下分区。我采用的是 MBR 分区，这样保证不会和 U-Boot 冲突。使用 fdisk进行分区，我从 1M 处开始分了一个 10M 的 FAT-32 分区作为启动分区，然后之后都是 EXT4 的系统盘分区。接着就是编译内核。
我用的是八月份时候的 4.18.2 内核，虽然不是很新但也足够新了。一番调整内核参数后，得到了一个可用的内核，然后把 zImage 和 sun8i-v3s-licheepi-zero.dtb 都复制到刚才创建的 FAT-32 启动分区，然后进入 U-Boot 进行启动：</description>
    </item>
    
    <item>
      <title>构建简易的 initramfs</title>
      <link>https://jiege.ch/os/2018/07/16/build-custom-initramfs/</link>
      <pubDate>Mon, 16 Jul 2018 03:43:00 +0800</pubDate>
      
      <guid>https://jiege.ch/os/2018/07/16/build-custom-initramfs/</guid>
      <description>一直对 Linux 的启动很感兴趣，但对 initrd 和 initramfs 等概念不大了解，于是上网找了资料，自己成功地看到了现象。
参考资料： Build and boot a minimal Linux system with qemu Custom Initramfs initramfs vs initrd ramfs, rootfs and initramfs The Kernel Newbie Corner: &amp;ldquo;initrd&amp;rdquo; and &amp;ldquo;initramfs&amp;rdquo;&amp;ndash; What&amp;rsquo;s Up With That?
具体步骤：
$ cat hello.c #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; int main() { for (;;) { printf(&amp;quot;Hello, world!\n&amp;quot;); } } $ gcc -static hello.c -o init $ echo init | cpio -o -H newc | gzip &amp;gt; initrd $ qemu-system-x86_64 -kernel /boot/vmlinuz-linux -initrd initrd -nographic -append &#39;console=ttyS0&#39; # Use C-a c q u i t &amp;lt;Enter&amp;gt; to exit  可以看到过一会（三四秒？），可以看到满屏的 Hello world 在输出。</description>
    </item>
    
    <item>
      <title>在脚本中寻找 X11 的 DISPLAY 和 XAUTHORITY</title>
      <link>https://jiege.ch/programming/2018/05/11/finding-x11-display-and-xauthority/</link>
      <pubDate>Fri, 11 May 2018 14:21:00 +0800</pubDate>
      
      <guid>https://jiege.ch/programming/2018/05/11/finding-x11-display-and-xauthority/</guid>
      <description>之前在搞一个小工具，在里面需要访问 X11 server ，但是访问 X11 server 我们需要两个东西：DISPLAY和XAUTHORITY两个环境变量。但是，由于它们在不同的发型版和Display Manager下都有些不同，所以花了不少功夫才写了一些。
为了验证我们是否可以连上 X11 server， 我们使用这一句：
DIMENSIONS=$(xdpyinfo | grep &#39;dimensions:&#39; | awk &#39;{print $2;exit}&#39;)  它尝试打开当前的 DISPLAY，并且输出它的分辨率。接下来，我对不同的一些发型版，综合网上的方法，尝试去找到正确的环境变量。
对于 Debian:
DISPLAY=$(w -hs | awk -v tty=&amp;quot;$(cat /sys/class/tty/tty0/active)&amp;quot; &#39;$2 == tty &amp;amp;&amp;amp; $3 != &amp;quot;-&amp;quot; {print $3; exit}&#39;) USER=$(w -hs | awk -v tty=&amp;quot;$(cat /sys/class/tty/tty0/active)&amp;quot; &#39;$2 == tty &amp;amp;&amp;amp; $3 != &amp;quot;-&amp;quot; {print $1; exit}&#39;) eval XAUTHORITY=~$USER/.Xauthority export DISPLAY export XAUTHORITY DIMENSIONS=$(xdpyinfo | grep &#39;dimensions:&#39; | awk &#39;{print $2;exit}&#39;)  对于 Archlinux：</description>
    </item>
    
    <item>
      <title>在 macOS 和 Linux 之间搭建 tinc 网络</title>
      <link>https://jiege.ch/networking/2018/05/09/tinc-between-macos-and-linux/</link>
      <pubDate>Wed, 09 May 2018 10:02:00 +0800</pubDate>
      
      <guid>https://jiege.ch/networking/2018/05/09/tinc-between-macos-and-linux/</guid>
      <description>一直听说 tinc 比较科学，所以尝试自己用 tinc 搭建一个网络。这里，macOS 这段没有固定 IP 地址，Linux 机器有固定 IP 地址 linux_ip 。假设网络名称为 example , macOS 端名为 macos 地址为 192.168.0.2, linux 端名为 linux 地址为 192.168.0.1。
2018-11-11 注：本文用的 tinc 版本为 1.0.x ，而不是 1.1-pre ，两个分支命令不同，但协议可以兼容。
在 macOS 上配置：
brew install tinc mkdir -p /usr/local/etc/tinc/example  新建 /usr/local/etc/tinc/example/tinc.conf:
Name = macos Device = utun0 # use an unused number ConnectTo = linux  编辑 /usr/local/etc/tinc/example/tinc-up:
#!/bin/sh ifconfig $INTERFACE 192.168.0.2 192.168.0.1 mtu 1500 netmask 255.</description>
    </item>
    
    <item>
      <title>使用 Nginx 转发 VMware ESXi</title>
      <link>https://jiege.ch/networking/2018/05/08/nginx-proxy-vmware-esxi/</link>
      <pubDate>Tue, 08 May 2018 19:26:00 +0800</pubDate>
      
      <guid>https://jiege.ch/networking/2018/05/08/nginx-proxy-vmware-esxi/</guid>
      <description>我们的 VMware ESXi 在一台 NAT Router 之后，但是我们希望通过域名可以直接访问 VMware ESXi 。我们首先的尝试是，把 8443 转发到它的 443 端口，比如：
socat TCP-LISTEN:8443,reuseaddr,fork TCP:esxi_addr:443  它能工作地很好（假的，如果你把 8443 换成 9443 它就不工作了），但是，我们想要的是，直接通过 esxi.example.org 就可以访问它。于是，我们需要 Nginx 在其中做一个转发的功能。在这个过程中遇到了很多的坑，最后终于是做好了 （VMware Remote Console等功能还不行，需要继续研究）。
首先讲讲为啥把 8443 换成 9443 不能工作吧 &amp;ndash; 很简单，ESXi 的网页界面会请求 8443 端口。只是恰好我用 8443 转发到 443， 所以可以正常工作。这个很迷，但是测试的结果确实如此。VMware Remote Console 还用到了别的端口，我还在研究之中。
来谈谈怎么配置这个 Nginx 转发吧。首先是 80 跳转 443:
server { listen 80; listen 8080; server_name esxi.example.org; return 301 https://$host$request_uri; }  这个很简单，接下来是转发 443 端口：
 server { listen 443 ssl; server_name esxi.</description>
    </item>
    
    <item>
      <title>搭建 FTP server behind NAT</title>
      <link>https://jiege.ch/networking/2018/05/08/ftp-behind-nat/</link>
      <pubDate>Tue, 08 May 2018 13:34:00 +0800</pubDate>
      
      <guid>https://jiege.ch/networking/2018/05/08/ftp-behind-nat/</guid>
      <description>我们出现新的需求，要把以前的 FTP 服务器迁移到 NAT 之后的一台机器上。但是，FTP 不仅用到 20 21 端口， PASV 还会用到高端口，这给端口转发带来了一些麻烦。我们一开始测试，直接在 Router 上转发 20 和 21 端口到 Server 上。但是很快发现， Filezilla 通过 PASV 获取到地址为 （内网地址，端口高8位，端口低8位），然后，Filezilla 检测出这个地址是内网地址，于是转而向 router_ip:port 发包，这自然是不会得到结果的。
此时我们去网上找了找资料，找到了一个很粗暴的方法：
iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 20 -j DNAT --to-destination internal_ip:20 iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 21 -j DNAT --to-destination internal_ip:21 iptables -A PREROUTING -i external_interface -p tcp -m tcp --dport 1024:65535 -j DNAT --to-destination internal_ip:1024-65535  有趣地是， macOS 自带的 ftp 命令（High Sierra似乎已经删去）可以正常使用。研究发现，它用 EPSV（Extended Passive Mode） 代替 PASV ，这里并没有写内网地址，因而可以正常使用。</description>
    </item>
    
    <item>
      <title>使用 iptables 和策略路由进行带源地址的 forwarding</title>
      <link>https://jiege.ch/networking/2018/05/06/nat-forwarding-with-src-address/</link>
      <pubDate>Sun, 06 May 2018 14:07:00 +0800</pubDate>
      
      <guid>https://jiege.ch/networking/2018/05/06/nat-forwarding-with-src-address/</guid>
      <description>陈老师打开他的服务器，突然发现 CPU 莫名高负载，然后发现是有一个用户被远程登录拿来挖矿了。但是这台机器在 NAT 后，所以登录的源地址全是 NAT 路由，所以不知道对方的地址是什么。我们为了能使用 fail2ban 来禁用多次尝试失败的 IP ，但又不想因为别人把 NAT 路由的地址给禁了，这样我们自己也用不了了。所以必须要让这台机器能够知道 ssh 的源地址，我们现在简单的 socat 方案不能满足这个需求。
需求：
 可以在外网连 NAT 路由的高端口（如2222）来访问这台机器。 在内网中，既可以直接连它的内网地址，也可以连 NAT 路由的高端口来访问这台服务器。此时，由于连 ssh 的机器就在同一个子网中，如果保留了源地址，服务器发的包会直接回来不经过 NAT 。所以我们还是保留了 socat 的方案。  实现方法：
在 NAT Router 上配置 DNAT ，这样发到 NAT Router 上的包就可以转发到服务器上：
iptables -t nat -A PREROUTING -i external_interface -p tcp -m tcp --dport 2222 -j DNAT --to-destination internal_server_ip:22  但是，从服务器回来的包到了 NAT Router 上后，由于路由表的配置问题，默认的路由并不能把包送达对方。
方法1: 我们首先给包打上 mark：
iptables -t mangle -A PREROUTING -i internal_interface -p tcp -m tcp --sport 22 -j MARK --set-mark 0x2222  然后配置策略路由：</description>
    </item>
    
  </channel>
</rss>