<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rust on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jia.je/tags/rust/</link>
    <description>Recent content in rust on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Dec 2020 09:27:00 +0800</lastBuildDate><atom:link href="https://jia.je/tags/rust/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rust 在 M1 上的 Code Signing 问题和临时解决方法</title>
      <link>https://jia.je/programming/2020/12/04/workaround-rust-on-m1/</link>
      <pubDate>Fri, 04 Dec 2020 09:27:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2020/12/04/workaround-rust-on-m1/</guid>
      <description>不久前，rust 添加了 Tier2 的 aarch64-apple-darwin 的支持，试了一下，确实可以运行，不过当我编译的时候，出现：
error: failed to run custom build command for `xxxx v1.0 (/path/to/xxxx)` Caused by: process didn&#39;t exit successfully: `/path/to/xxx/target/debug/build/xxx-xxxx/build-script-build` (signal: 9, SIGKILL: kill) 看了一下 Console.app 里面的 crash 日志，发现是 codesigning 问题。解决方法是，用 codesign 命令来签名：
# for build.rs codesign -s - target/debug/build/*/build-script-build # for dylib of some crates codesign -s - target/debug/deps/*.dylib # for final executable codesign -s - target/debug/xxx 多次编译并签名后，就可以正常运行最后的二进制了：
target/debug/xxxx: Mach-O 64-bit executable arm64 然后就可以了。等待上游添加 code signing 支持吧。</description>
    </item>
    
    <item>
      <title>在 arm64 上使用 rust-analyzer</title>
      <link>https://jia.je/programming/2020/09/13/aarch64-rust-analyzer/</link>
      <pubDate>Sun, 13 Sep 2020 16:34:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2020/09/13/aarch64-rust-analyzer/</guid>
      <description>远程到 arm64 的机器上进行开发，发现没有 rust-analyzer 的支持。研究了一下，发现在 rustup 里面可以找到，不过要配置一下：
&amp;gt; rustup toolchain add nightly &amp;gt; rustup component add --toolchain nightly rust-analyzer-preview 这个时候，应该可以找到 ~/.rustup/toolchains/nightly-aarch64-unknown-linux-gnu/bin/rust-analyzer 文件，接下来，配置 VSCode 插件即可：
{ &amp;#34;rust-analyzer.serverPath&amp;#34;: &amp;#34;~/.rustup/toolchains/nightly-aarch64-unknown-linux-gnu/bin/rust-analyzer&amp;#34; } 路径在 ~/.vscode-server/data/Machine/settings.json。
参考：https://github.com/rust-analyzer/rust-analyzer/issues/5256</description>
    </item>
    
    <item>
      <title>实现一个简单的 Decaf LSP</title>
      <link>https://jia.je/programming/2019/11/17/rust-decaf-lsp/</link>
      <pubDate>Sun, 17 Nov 2019 14:40:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/11/17/rust-decaf-lsp/</guid>
      <description>背景 编译原理课程在做 Decaf 的 PA ，之前做了一些比较简单的尝试，包括在线 Decaf、在线 TAC VM 等等，都是套一个前端，然后整个编译到 wasm 跑前端就可以了。如果要做 LSP 的话，工作量会稍微大一些，不过也更加实用。
然后有一天，助教 @equation314 写了 decaf-vscode 一个 VSCode 对 Decaf 的语法高亮插件，我就 Fork 了一份到 jiegec/decaf-vscode，然后添加了 LSP 的支持，让它有了一些更高级的功能。
实现 LSP 服务端一般是一个命令行程序，通过 JSONRPC 进行消息通讯，然后就上午找有没有现成的框架。比较重要的是 lsp-types 和 tower-lsp ，前者封装了 LSP 协议的各个结构体，后者提供了服务端的大概实现。不过由于后者做的不大全，所以我自己 fork 了一份添加了一些。
实际实现的时候，需要实现几个函数，分别相应客户端的请求，比如在 initialize 的时候告诉客户端我都实现了哪些东西，然后相应地提供各种信息，如 symbol，hover，folding，definition等等。为了实现简单，我要求客户端每次修改的时候都把完整的文件传过来，虽然不是很高效，但是很简单，目前也没有啥很长的 Decaf 程序嘛。
每次拿到 Decaf 程序之后，就按照 decaf-rs 的方法，Lex 然后 Parse ，然后遍历 AST ，分别把需要的各个信息都存下来，当客户端在请求的时候，直接返回即可。然后就会在 VSCode 中出现，比如实现了 document symbol ，在左边的 Outline 中就会出现相应的结构；实现了 hover ，当移动到一些地方的时候，客户端发出请求，服务端就把相应的 hover 信息返回给客户端。整个协议并不复杂，后面实际实现其实才是比较复杂的地方。
实现的功能中，symbols hovers ranges definition 都是在得到 AST 后一次遍历都计算好，然后返回，同时在遇到错误的时候，也通过 diagnostic 的形式把检查出来的错误汇报给用户。由于 VSCode 的良好支持，基本不需要写 TypeScript 代码。</description>
    </item>
    
    <item>
      <title>用 Rust Procedure Macro 实现 GLL Parser</title>
      <link>https://jia.je/programming/2019/11/15/rust-proc-macro-gll/</link>
      <pubDate>Fri, 15 Nov 2019 11:13:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/11/15/rust-proc-macro-gll/</guid>
      <description>背景 在编译原理课上，PA 框架采用的是 MashPlant/lalr1 ，是一个比较好用的 Lexer + Parser 的工具，它的大概语法见 一个完整的例子 。然后之前看到了 GLL Parser ，想着可不可以照着类似的语法也写一个 GLL 的 Parser Generator ，也是用 Rust Procedure Macro 的方法，就开始了研究。
尝试 首先是阅读 GLL 的论文，它并不长，大概的意思就是，LL(1) 文法需要考虑 PS 冲突的情况，而 GLL 的解决方法就是“都试一下”，然后为了效率，用了 GSS 表示解析过程和 SPPF 表示解析结果。然后就开始照着论文手写了不同版本的实现，见 jiegec/gll-test 。
第一种就是按照论文里第一段实现直接抄过来，每个可能性作为一个 Continuation 存下来，它有自己的栈和执行位置（Label）。这样 Work 以后呢，我又想到了 async/await ，用类似的方法又写了一遍，相对要简洁一些，也是很平常的递归下降的写法，而不是 Loop + Label 的形式。但这些都不能做到合并栈的目的，所以遇到十分有歧义的文法的时候会很糟糕。
然后开始按照论文中的 GSS 进行编写，基本还是按照论文进行翻译，然后一步一步做，做好以后把 GSS 画出来，和论文的图可以对的上；然后照着 GLL parse-tree generation 的论文把 SPPF 实现了，这时候就可以从 recongizer 变成一个 parser 了。
宏 得到一份可行的代码以后，就要扩展到通用的情况上。学习了一下 MashPlant/lalr1 的实现，实现了一个 proc macro，它读取了用户的程序，从一个模板文件开始，往里面插入一些生成的代码，丢给编译器去编译。这时候就涉及到编译期和运行时的不同了，我把运行时一些通用的结构放到了 gll-pg-core 中，把编译期的代码放到了 gll-pg-macros 。</description>
    </item>
    
    <item>
      <title>在 rCore 上运行 nginx</title>
      <link>https://jia.je/programming/2019/03/08/running-nginx-on-rcore/</link>
      <pubDate>Fri, 08 Mar 2019 18:07:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/03/08/running-nginx-on-rcore/</guid>
      <description>阿 西 吧 nginx 终于能在 rCore 上跑了 orrrrrrrz
通过这半个多月来的大量开发，我和王润基 @wangrunji0408 学长算是终于完成了第一个 milestone：跑起来一个 nginx 。遇到了很多困难，大概有这些：
 syscall 实现不全。各种方面都缺，然后 nginx 在编译的时候又检测到比较新的 OS 版本，所以很多 syscall 都用了新的来替代老的，例如 readv/writev pread/pwrite accept4 等等，所以这方面做了一些工作。另外，还有很多新的 syscall 进来，太多了我就不细说了，基本上一个commit做一点一个commit做一点这个样子。 nginx 用到了 SSE 的寄存器 xmm ，但是之前是没有开的。所以把 sse 打开，然后切换上下文的时候把 sse 通过 fxsave 保存和 fxrstor 恢复（有意思的是，as居然不认这俩，只好手动写字节码），然后为了 16bit 的对齐又写了几行汇编代码。这块问题不大，今天一会就搞定了。但是如果要性能更高一些的话，可能需要在第一次使用 xmm 的时候再开始保存，大概就是加一个bit的事情。 文件系统有点崩。实现还是有很多 BUG ，表现就是需要经常重新 mksfs 一下，再重启加载完好的 fs ，有时候强制关机一下就又崩了。 内存管理做了一些改变。为了实现更加完整的 mmap mumap 和 mprotect ，又发现了一些新的 BUG 在里面，然后慢慢修复了。就是实现的有点粗暴。 死锁问题。这个其实现在还会出现，只是还没调出来，也不会百分百出现。我们计划在锁上面做一些死锁检测，例如记住是谁上锁的，等等。现在就遇到一个很玄学的死锁问题。  然后代码也是一边在写一边在重构吧，很多地方现在都写得很粗暴，FIXME和TODO留了很多，很多地方也写得不够优雅。以后再慢慢重构+优化吧。
截图留念：
再往前的话，还有很多小的问题，例如网卡的中断启用了但没有改 mask ，所以啥也没收到，靠 QEMU Tracing 找到问题。还有一个很有意思的现象，就是如果 elf 的 program header 没有 phdr 这个项的时候，我们发现，可以通过第一个load（如果加载了完整的 elf 头的话），我们可以从这里推断出 phdr 的地址（load的虚拟地址加偏移），然后丢到 auxv 里去让 musl 配置 tls。总之这些都解决了。也不用去考虑兼容 litc 了，已经全部向 linux 靠拢了，稳。</description>
    </item>
    
    <item>
      <title>实现网络的 syscall</title>
      <link>https://jia.je/programming/2019/03/04/implement-network-syscalls/</link>
      <pubDate>Mon, 04 Mar 2019 16:40:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/03/04/implement-network-syscalls/</guid>
      <description>有了网卡驱动，接下来要做的就做网络的 syscall 了。为了测试，首先在 busybox 里找可以用来测试的 applet ，由于没有实现 poll ，所以 nc telnet 啥的都用不了。最后选择到了 ping 和 pscan 上。
ping大家都很了解，pscan就是一个扫端口的，对一个ip连续的若干个端口发起 tcp 请求。这就要求我提供 raw socket和tcp socket状态的支持。由于网络栈本身是异步的，但 read connect 这些函数在不调 setsockopt 的前提下又是同步的，然而现在又没有 signal 可以用，要是 block 了就再也出不来了。于是就采用了 Condvar 的办法，拿一个全局的条件变量，当 poll 不到内容的时候，先把线程拿掉，等到网络栈更新了，再恢复。这样至少不会把 cpu 也 block 住。
然后就是把 socket 部分改了又改吧，数据结构的设计改了几次，为了解决 ownership 问题上锁啊也有点多，但是也更细了，虽然实际上可能没有必要，因为上面还有大的锁。不过性能还不是现在考虑的重点，关键还要先把 send recv accept bind listen 啥的写得差不多了，然后还有把 poll/select 实现了，这个很关键。
中间遇到的最大的坑就是，接收 pci interrupt 的时候总是啥也没有，然后靠万能的 qemu trace 发现，原来是 mask 掉了，所以啥也收不了，然后最后的解决方案就是用 MSI Interrupt #55 搞定了这个问题。至于为啥是 55 呢，因为 23 + 32 = 55 啊（误</description>
    </item>
    
    <item>
      <title>使用 Rust 实现 e1000 驱动</title>
      <link>https://jia.je/programming/2019/02/26/network-driver-again/</link>
      <pubDate>Tue, 26 Feb 2019 20:30:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/02/26/network-driver-again/</guid>
      <description>是的。我又来了。上次做了使用 Rust 实现 VirtIO 驱动之后，继续往 rCore 加更多的驱动支持。由于现在工作重点是 x86_64 下的 syscall 实现，所以选了一个比较有代表性的驱动 e1000 来实现。其实如果只是为了在 qemu 下运行的话，其实只需要支持 virtio-pci 就可以了，原来的 virtio-net 直接拿来用就可以了。
为什么挑 e1000 呢，一方面是支持的设备多，有真实硬件可以测试，虽然不一定要裸机上跑，但是可以通过 PCI passthrough 来测试驱动的正确性。另一方面是网上的资料比较多，有现成的简单的代码可以借鉴。这次主要借鉴了三个来源：一是 Biscuit OS， 二是 Judge Duck OS ，三是 Linux 。
首先是实现了简单的 PCI 总线的枚举，然后找到对应的设备，激活，并且找到映射的内存地址，然后把原来 C 语言的实现搬运到 Rust 中。这个过程中遇到很多坑，例如一开始我以为内核里 pa 和 va 是一个固定的偏移，不过多次尝试后才发现这个假设只对 riscv 平台里的实现成立。
这个时候就可以收到外面给进来的以太网帧了。接着就是把它接入到 smoltcp 的 API 中。但是发包又不工作了，尝试了很多次，各种方法也不行。其中特别要提到的就是 qemu 的 tracing API ，它在帮助我调试之前的 virtio 驱动和这次的 e1000(e) 驱动中起到了很大的帮助。不过，遗憾的是，发包相关的代码里的 trace 不足以让我找到问题的所在，我只好采用了最后一招：
下载 QEMU ，自己改，然后自己编译。
这个方法果然很有效啊，经过简单的几个修改，很快就定位到问题所在了，原来就是一个简单的错误，把 4 写成了 8 。这个过程中我也发现 QEMU 在 incremental build 的时候似乎会 segfault ，我没管这么多，反正编译也不慢，次数也不多，每次 clean 再 build 问题也不大。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（9）</title>
      <link>https://jia.je/programming/2019/02/12/thoughts-on-stanford-cs140e-9/</link>
      <pubDate>Tue, 12 Feb 2019 11:35:00 +0400</pubDate>
      
      <guid>https://jia.je/programming/2019/02/12/thoughts-on-stanford-cs140e-9/</guid>
      <description>距离上一篇 CS140e 系列文章已经过去了很久，距离第一篇文章过了一年零几天。在后来这一段时间内，CS140e 结束了课程，又开始了新一年的 winter 2019 课程，迎来的却是 C 版本的 CS140e ，不禁让人感到失望。还好，Sergio Benitez 放出了原来的 CS140e 的镜像，如果大家仍然想回去查看原版优质的 CS140e ，可以点进去参考。
后来因为机缘巧合参与到了清华的 Rust OS 课程，又想到回来把原来的 CS140e 进行更新，于是顺带把跑在 QEMU 下的一些需要的工作给做了，另外把 Rust nightly 版本更新了（一年前的 nightly 还能叫 nightly ？），才发现标准库变化还是蛮大的，由于 nightly 版本变了，而且原来是内嵌了一个阉割过的 std ，所以主要是从新的 std 里抄代码到内嵌的 std 中。另外，原来的 xargo 也不再维护了，转而使用 rust-xbuild 进行交叉编译。
然后又顺手实现了 backtrace 和从 backtrace 中配合 dward symbols 找函数名的功能，不过实践证明，这些东西还是 addr2line 做得更好，所以也就没有做下去，在 relocation 上也是遇到了各种问题。这个经验也是应用到了 rCore 那边。
再之后也就是寒假写驱动了，见之前的一个博文，我就没有在 CS140e 上去实现它了。有时间有兴趣的时候再考虑做一下 Raspberry Pi 的网卡驱动吧。
写于迪拜雨天。</description>
    </item>
    
    <item>
      <title>Rust 获取 Linker Script 中的地址</title>
      <link>https://jia.je/programming/2019/01/07/rust-access-linker-script-address/</link>
      <pubDate>Mon, 07 Jan 2019 11:57:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/01/07/rust-access-linker-script-address/</guid>
      <description>在 Linker Script 中可以记录下一个地址到一个变量中，大概这样：
.text: { PROVIDE(__text_start = .); *(.text .text.* .gnu.linkonce.t*) PROVIDE(__text_end = .); } 这里的 PROVIDE() 是可选的。这样，代码里就可以获取到 .text 段的地址了。在 C 中，直接 extern 一个同名的变量就可以了，但在 Rust 中，需要这样获取：
extern &amp;#34;C&amp;#34; { fn __text_start(); fn __text_end(); } // __text_start as usize // __text_end as usize 这样就可以拿到地址了。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（8）</title>
      <link>https://jia.je/programming/2018/04/10/thoughts-on-stanford-cs140e-8/</link>
      <pubDate>Tue, 10 Apr 2018 17:27:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/04/10/thoughts-on-stanford-cs140e-8/</guid>
      <description>在上一篇文章之后，我其实还是很忙，但是一直心理惦记着这件事，毕竟只剩最后的一点点就可以做完了，不做完总是觉得心痒。
今天做的部分是调度。我们目前只在 EL0 运行了一个 shell ，每当触发 exception 时回到 kernel 进行处理，再回到原来的地方。但现在，我要实现一个 preemtive round-robin scheduler ，就需要管理当前的所有进程，并且维护当前的进程状态，当时钟中断到来的时候，决定下一个 time slice 要执行的进程，再切换过去。这个过程当然会遇到不少的坑。
首先，我们需要判断一个进程是否可以执行了。考虑到阻塞的 IO ，作者提供了一个优雅的方法：如果这个进程阻塞在 IO 上，那么，提供一个函数，在 scheduler 中调用，判断所需要的数据是否到达。这样，我们就可以一个循环把下一个 time slice 要执行的线程找到。如果找不到，就等待 interrupt 再尝试。
困难的地方在于，在启动的时候，切换到一个起始线程。并且在上下文切换的时候，在 process 1 -&amp;gt; kernel -&amp;gt; process 2 这两步过程中，有许多寄存器都需要仔细考虑如何实现。并且在这个过程中，我也发现了之前写的代码中的问题，最终修复了（目前来看是 working 了）。
我的代码实现在 这里 。下一步就要写 syscall 了。希望能在期中前抽时间赶紧把这个做完。
18:54 PM Update: 刚实现完了 sleep 的 syscall 。比预想中要简单。果然找到了自己实现的调度器的 BUG 。此系列大概是完结了。
2019-02-12 Update: 下一篇文章。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（7）</title>
      <link>https://jia.je/programming/2018/04/07/thoughts-on-stanford-cs140e-7/</link>
      <pubDate>Sat, 07 Apr 2018 14:05:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/04/07/thoughts-on-stanford-cs140e-7/</guid>
      <description>在上一篇文章之后，我很长时间都没有在继续我这个项目，清明节刚好闲下来了我就回来继续啃它。Stanford那边已经结课，最后的 3-spawn 也只有一部分，剩下的部分不知道什么时候作者才会填上去了。
这次主要要写的代码就是，对异常的处理。这里的异常并不是我们编程语言中的 catch/throw ，而是硬件的异常。AArch64 和 x86 一样，也有不同的特权级别的区分，前者是 EL0~EL3 ，后者则是 RING0 和 RING3 。特权级别高可以往特权级别低转换，但是反过来，只能通过异常的方式提高特权等级，并且切换特权等级后只有固定的一些代码可能会跳转，这就是 exception handler/vectors 。这些函数可以知道是什么原因调用了他们，根据硬件规定好的文档，我们可以知道发生了什么事情，是对齐出错了呢，还是用户调用了 syscall 呢，等等。根据不同的情况，我们需要进行不同的处理。当处理完之后，我们需要考虑，跳转回用户代码的时候，回到哪里，提供什么值，不提供什么。
实现的话，需要很多步骤。首先是构造好 exception vector ，这里作者已经写好了一个宏（这里 @BenYip 遇到了一个 assembler 的 BUG ），直接用宏就可以把它写出来。然后，我们需要把它加载到当前 EL 的 VBAR_ELx 寄存器中，当 CPU 抛出异常的时候，就会找到这里相应的处理器进行处理。进到这里以后，我们首先先不考虑太多上下文保存的事情&amp;ndash;我们先保证能处理异常，恢复也是个有很多坑的步骤，作者也是在这里分成了两个 Subphase 。首先还是从 ESR_ELx 中解析到错误的来源的具体内容，如果是我们在 shell 中自己调用的 brk 2 指令，我们就自己新开一个 shell ，修改了提示符以示区别。这样，我们就成功地捕捉到了这个异常。由于我们还无法恢复回去，所以我们直接死循环。
接下来我们要做的是，从异常中恢复出来。由于用户代码可能在各种地方抛出异常，异常也分同步和异步两种情况，这里有许多需要考虑的问题。为了简化，我们目前只考虑同步的 brk 2 导致的 Brk 异常。为了能恢复之后能够正常运行，我们需要把所有的寄存器都保存下来，即 TrapFrame 。保存的时候需要讲究 AArch64 平台下 SP 寄存器的对齐问题。我们也要把一些特殊的寄存器保存下来。还有一点，就是，因为 exception handler 中调用了 context_save 函数，所以此时的 lr 本身也需要进行保存，这个地方也卡了我很久。最后，再把这些一个一个地恢复到原来的样子，调整 ELR_EL1 使得退回到原来的状态时，会跳过当前的 brk 2 指令，调用它的下一调指令。这样，我们就成功地在遇到异常时，弹出一个 shell ，而且还可以回退回来。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（6）</title>
      <link>https://jia.je/programming/2018/03/05/thoughts-on-stanford-cs140e-6/</link>
      <pubDate>Mon, 05 Mar 2018 19:55:49 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/03/05/thoughts-on-stanford-cs140e-6/</guid>
      <description>在上一篇文章之后，作者终于更新了测试的用例，我的程序终于可以成功跑过所有测试，也成功在树莓派跑起来。不过，我的代码中很多地方的错误处理比较偷懒，往往直接 panic ，显然并不友好。同时，我想到了使用 cargo-fuzz 来进行自动化测试，果然，使用这个很快就修复了不少我没想到的会出错的地方，比如乘法溢出，目录项没有正确结束等等。目前还发现一个 timeout 的问题，研究发现大概是文件的 cluster chain 中出现了环，导致一直读取文件而没有停止。要解决这个问题，我目前想到的是 Floyd 的判圈算法，但还没上实现。等过几天，新的 Assignment 3 出了以后，再继续更新。希望作者少点跳票，多点勤奋，哈哈哈哈哈
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（5）</title>
      <link>https://jia.je/programming/2018/03/03/thoughts-on-stanford-cs140e-5/</link>
      <pubDate>Sat, 03 Mar 2018 11:07:30 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/03/03/thoughts-on-stanford-cs140e-5/</guid>
      <description>在上一篇文章之后，作者多次延期跳票之后（again），终于放出了 Assignment 2 Phase 3: Saddle Up 。这次，我们要做的变成了把已经写好的（错漏百出）的 fat32 的驱动搬到树莓派里面去，然后实现一些基本的 shell 命令： ls cat cd 等等。作者首先更新了老版本的新的测试样例，放了一些映像然后提供了预期的结果，结果发现，这里的 fat32 有一些不同，主要的就是 bytes_per_sector 不是 512 了，意味着物理的扇区和逻辑扇区并不一致。同时， sectors_per_cluster 也不是 1 了，需要考虑多个扇区的情况。同时， read_cluster 传入的 offset 也可能不再是第一个 sector 中的，所以需要做一个处理。对于物理和逻辑扇区的问题，作者推荐的方案是，把 fat32 之外的扇区保持不变，把其内的扇区视为逻辑扇区。这样，其它代码都可以透明地工作，而不用到处更改，这就体现了封装的威力。接着，作者提供了一个写好了的 libsd 和一些导出的函数，使用这些函数即可。不过，在错误处理和 timeout 上也遇到了一些坑。后面，把东西搬到树莓派上运行，问题就出现了：读取了第一个扇区（即 MBR 所在的扇区）之后，直接就死掉了。想了半天都没找到方案，突然想起可以利用 panic! 对错误语句进行二分查找。查找了大概有七八个小时之后，终于发现，问题出现在读取一个 u32 类型的变量上。我起初怀疑是栈出了问题，所以放到堆上分配，然而还是不行。忽然想起以前遇到的对齐问题，在 AArch64 架构上，可能为了简化，读取的 u32 必须对齐到四个字节上。于是找了找 Rust 中的对齐方面的文档，找到了 #[repr(align=4)] 这种表示方法，代替了原来的 #[repr(packed)] ，并且把数据先拷贝到对齐后的栈上的对应数据结构，然后再读取对应的项。果然，这个问题就解决了。然后又发现我的盘中会出现 lfn 项并不是从后往前的情况，于是我又修改了一下相关的代码。现在，终于可以成功地 ls cat cd 。
不过还是要吐槽一下，作者的测试用的映像文件中，会出现 0xE5 表示这个项已经被删除的情况，但是似乎作者的代码并没有处理这个，所以在预期的输出中出现了一些明显不正确的结果，导致我的代码跑测试并不能通过。而且，作者的代码在一些情况下会把文件的后缀漏掉。作者后来更新了几次测试的文件，不过这个问题只解决了一部分，并没有完全解决。坐等作者继续放出新的测试文件吧。
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（4）</title>
      <link>https://jia.je/programming/2018/02/27/thoughts-on-stanford-cs140e-4/</link>
      <pubDate>Tue, 27 Feb 2018 22:42:59 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/27/thoughts-on-stanford-cs140e-4/</guid>
      <description>在上一篇文章之后，作者多次延期跳票之后，终于放出了 Assignment 2 Phase 2:32-bit Lipids ，这两天就把只读 FAT32 写完了（不过封装得并不好，许多地方利用了 pub(super) 把变量可以访问的范围控制到 vfat 中，然后直接读，只有少数需要特殊处理的进行了函数的封装）。首先当然是研究了半天 MBR 和 FAT32 的结构，拿了不同来源的 FAT 结构说明进行对比和验证，最后终于把格式搞清楚了，先实现了 MasterBootRecord ，这个其实很好实现，以前也有接触过 MBR ，本身也很简单。然后就是根据 MBR 找到第一个 FAT32 的分区，根据偏移找到分区的开头，开头的第一个扇区就是 EBPB 数据结构，里面保存了 FAT32 分区的各种信息。根据里面的信息，可以找到 FAT 表的位置和数量，还有数据部分的 Cluster 的位置和数量。接着，解析一下 FAT 表，实际上是一个与 Cluster 一一对应的链表结构，用特殊的数据代表链表的尾和空、坏扇区。利用这些，和 EBPB 中根目录所在的第一个 Cluster ，先在 VFat 里面实现了读取一个 Cluster 链的内容的函数，利用这个函数读取一个一个的目录项，解析目录项，把长文件名的项合并到一个之中，然后对应地丢到 Entry 对象中，目录则可以枚举子目录项，根据名字比较去找子目录或者子文件夹，文件则实现了 io::Read和 io::Seek 使得可以读取文件的内容。实现好了这些以后，就拿了 raspbian-strech-lite.img 作为硬盘映像，从文件里读取文件信息，成功地把 config.txt 读取出来。
其中还是遇到许多困难，如各种偏移的计算，如何处理跨 Cluster 和跨 Sector 的读写，等等，有不少的坑在其中，花了两天的空余时间才差不多完善了这个功能。还有就是利用 Rust 现有的功能完成 C 里面很轻易就可以实现的指针操作，也花了不少时间。
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（3）</title>
      <link>https://jia.je/programming/2018/02/16/thoughts-on-stanford-cs140e-3/</link>
      <pubDate>Fri, 16 Feb 2018 20:09:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/16/thoughts-on-stanford-cs140e-3/</guid>
      <description>由于 Assignment 2: File System  延期发布，所以中间那段时间转向 MIT 6.828 稍微研究了一下。前几天放出了新的任务，在上一篇文章之后，我又有了一些进展： 实现了从内存中读取 ATAGS(ARM Tags) 信息的代码，从而可以获得内存大小的信息，根据这个信息，实现了 bump 和 bin 两种内存分配器，并且把二者之一注册为全局内存分配器，利用上更新了的 std 就可以使用需要动态分配内存的相关工具了。利用这个，我实现了 shell 输入历史的回溯，把输入历史保存在一个动态增长的数组中，再特殊处理上下键，把当前的行替换为历史。
这个过程也不是没有踩坑。一开始代码放出来了，但是题目说明还没出，我就自己按照代码做了 ATAGS 和 bump 分配器，后来做完了，看到说明出了以后，发现理解还是有偏差，把代码更改了并修复了分配器的 BUG 。看到 bin 分配器的时候，我按照网上的 buddy memory allocation 实现了一个内存分配器，原理看起来简单实现起来还是有很多细节问题，后来按照新放出的单元测试，修修补补才写得差不多可用了。同时，原来的 bootloader 因为用了新的 std 而缺失了 alloc 不能编译，我就把 kernel 下的相关文件软连接过去，调了数次后把问题解决。此时， kernel 文件大小已经有 40K ，按照 115200 Baudrate 发送需要几秒才能传输过去，我就调到了 230400 Baudrate ，果然现在的传输速度就有所提升，可以接受了。等之后写了 EMMC(SD card) 的驱动和 FAT32 的文件系统后，就可以实现更多的 shell 的功能了。中间还遇到一个问题，就是如果给 kernel 开启了 bin 分配器，使用 exit 回到 bootloader 就无法传新的 kernel 上去了，结果发现是因为 bin 中用到的侵入式 LinkedList 实现覆盖了部分 bootloader 的代码，换回不能回收内存的 bump 分配器即可，反正目前远远还用不了那么多内存。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（2）</title>
      <link>https://jia.je/programming/2018/02/06/thoughts-on-stanford-cs140e-2/</link>
      <pubDate>Tue, 06 Feb 2018 12:52:59 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/06/thoughts-on-stanford-cs140e-2/</guid>
      <description>在上一篇文章之后，我又有了一些进展：UART ，简易的shell ，修复了之前写的 xmodem 中的 BUG，一个可以从 UART 接收一个 kernel 写入到内存中再跳转过去的 bootloader 。
首先是 UART ，就是通过两个 GPIO pin 进行数据传输，首先在 memory mapped IO 上进行相应的初始化，然后包装了 io::Read 和 io::Write （这里实现一开始有 BUG，后来修复了），然后很快地完成了一个仅仅能 echo 的 kernel 。
然后实现了 CONSOLE ，一个对 MiniUart 和单例封装，就可以用 kprint!/kprintln! 宏来输出到 UART ，接着实现了一个 echo 的 shell ，读入一行输出一行。然后实现退格键和方向键，这里的难点在于要控制光标并且用读入的或者空格覆盖掉屏幕上已经显示而不应该显示的内容。接着，利用 skeleton 中的 Command 做了一个简单的 echo 命令。
接着，利用之前编写的 tty ，配合上新编写的 bootloader ，实现通过 UART 把新的 kernel 通过 XMODEM 协议发送到设备，写入 0x80000 启动地址并且调转到新加载的 kernel 中执行。
最后，又实现了 uptime （输出设备启动到现在的时间）和 exit （跳转回 bootloader ，可以上传新的 kernel ）。并添加了 TUNA 作为 shell 启动时输出的 BANNER 。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考</title>
      <link>https://jia.je/programming/2018/02/04/thoughts-on-stanford-cs140e/</link>
      <pubDate>Sun, 04 Feb 2018 22:28:23 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/04/thoughts-on-stanford-cs140e/</guid>
      <description>最近，受各路安利，剁手买下了 这个淘宝商家的树莓派的套餐C ，还买了许多 LED 灯泡、杜邦线和电阻，开始按照 CS 140e 学习 Rust 并且用 Rust 编译写一个简易的操作系统。Assignment 0 的目标就是编写一个向 GPIO 16 连接的 LED 灯闪烁。首先当然就是愉快地按照教程下载 bootloader ，下载交叉编译工具链，顺带装一个 Raspbian 到机器上，随时可以当成一个低性能的 ARM/ARM64 （实际上，Raspbian 只用了armv7l，没有用 64bit）机器来用，以后如果配上 @scateu 团购的 Motorola Laptop Dock 的话就是一个几百块的笔记本了。把课程上的文件丢上去，可以看到绿色的活动指示灯闪烁，后面又把 CP2102 模块连上去，又能看到 Blink on, Blink off 的输出。然后按照要求，自己先码一段 C 语言，实现 blinky:
#define GPIO_BASE (0x3F000000 + 0x200000)  volatile unsigned *GPIO_FSEL1 = (volatile unsigned *)(GPIO_BASE + 0x04); volatile unsigned *GPIO_SET0 = (volatile unsigned *)(GPIO_BASE + 0x1C); volatile unsigned *GPIO_CLR0 = (volatile unsigned *)(GPIO_BASE + 0x28); static void spin_sleep_us(unsigned int us) { for (unsigned int i = 0; i &amp;lt; us * 6; i++) { asm volatile(&amp;#34;nop&amp;#34;); } } static void spin_sleep_ms(unsigned int ms) { spin_sleep_us(ms * 1000); } int main(void) { // STEP 1: Set GPIO Pin 16 as output.</description>
    </item>
    
  </channel>
</rss>
