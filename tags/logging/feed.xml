<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>logging on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jia.je/tags/logging/</link>
    <description>Recent content in logging on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Jul 2022 20:14:00 +0800</lastBuildDate><atom:link href="https://jia.je/tags/logging/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>rsyslog 收集远程日志</title>
      <link>https://jia.je/software/2022/07/01/rsyslog-remote/</link>
      <pubDate>Fri, 01 Jul 2022 20:14:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/01/rsyslog-remote/</guid>
      <description>背景 最近在运维的时候发现网络设备（如交换机）有一个远程发送日志的功能，即可以通过 syslog udp 协议发送日志到指定的服务器。为此，可以在服务器上运行 rsyslog 并收集日志。
rsyslog 配置 默认的 rsyslog 配置是收集系统本地的配置，因此我们需要编写一个 rsyslog 配置，用于收集远程的日志。
首先复制 /etc/rsyslog.conf 到 /etc/rsyslog-remote.conf，然后修改：
 注释掉 imuxsock 和 imklog 相关的 module 加载 去掉 imudp 和 imtcp 相关的注释，这样就会监听在相应的端口上 修改 $WorkDirectory，例如 $WorkDirectory /var/spool/rsyslog-remote，防止与已有的 rsyslog 冲突 注释 $IncludeConfig，防止引入了不必要的配置 注释所有已有的 RULES 下面的配置 添加如下配置：  $template FromIp,&amp;#34;/var/log/rsyslog-remote/%FROMHOST-IP%.log&amp;#34; *.* ?FromIp 这样，就会按照来源的 IP 地址进行分类，然后都写入到 /var/log/rsyslog-remote/x.x.x.x.log 文件里。
systemd service 最后，写一个 systemd service 让它自动启动：
[Unit] ConditionPathExists=/etc/rsyslog-remote.conf Description=Remote Syslog Service  [Service] Type=simple PIDFile=/var/run/rsyslogd-remote.pid ExecStart=/usr/sbin/rsyslogd -n -f /etc/rsyslog-remote.</description>
    </item>
    
    <item>
      <title>用 fluentd 收集 k8s 中容器的日志</title>
      <link>https://jia.je/devops/2021/04/02/k8s-fluentd-log-collect/</link>
      <pubDate>Fri, 02 Apr 2021 23:19:00 +0800</pubDate>
      
      <guid>https://jia.je/devops/2021/04/02/k8s-fluentd-log-collect/</guid>
      <description>背景 在维护一个 k8s 集群的时候，一个很常见的需求就是把日志持久化存下来，一方面是方便日后回溯，一方面也是聚合 replicate 出来的同一个服务的日志。
在我目前的需求下，只需要把日志持久下来，还不需要做额外的分析。所以我并没有部署类似 ElasticSearch 的服务来对日志进行索引。
实现 实现主要参考官方的仓库：https://github.com/fluent/fluentd-kubernetes-daemonset。它把一些常用的插件打包到 docker 镜像中，然后提供了一些默认的设置，比如获取 k8s 日志和 pod 日志等等。为了达到我的需求，我希望：
 每个结点上有一个 fluentd 收集日志，forward 到单独的 log server 上的 fluentd log server 上的 fluentd 把收到的日志保存到文件  由于 log server 不由 k8s 管理，所以按照官网的方式手动安装：
$ curl -L https://toolbelt.treasuredata.com/sh/install-debian-buster-td-agent4.sh | sh 然后，编辑配置 /etc/td-agent/td-agent.conf：
&amp;lt;source&amp;gt;  @type forward  @id input_forward  bind x.x.x.x &amp;lt;/source&amp;gt;  &amp;lt;match **&amp;gt;  @type file  path /var/log/fluentd/k8s  compress gzip  &amp;lt;buffer&amp;gt;  timekey 1d  timekey_use_utc true  timekey_wait 10m  &amp;lt;/buffer&amp;gt; &amp;lt;/match&amp;gt; 分别设置输入：监听 fluentd forward 协议；输出：设置输出文件，和 buffer 配置。如有需要，可以加鉴权。</description>
    </item>
    
  </channel>
</rss>
