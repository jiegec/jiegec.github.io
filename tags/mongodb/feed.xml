<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mongodb on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jiege.ch/tags/mongodb/</link>
    <description>Recent content in mongodb on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Dec 2018 19:56:00 +0800</lastBuildDate>
    
	<atom:link href="https://jiege.ch/tags/mongodb/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>《加速奔向2019》小程序编写和运营回顾</title>
      <link>https://jiege.ch/software/2018/12/27/wxapp-recap/</link>
      <pubDate>Thu, 27 Dec 2018 19:56:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/2018/12/27/wxapp-recap/</guid>
      <description>前言 关注清华的同学可能知道，昨天，“清华大学”公众号发了一篇名为《2018，我们共芳华丨@THUers 致相伴一年的你，请查收这份心意》的推送，内容大概就是，有那么100个新年台历礼品要送出去，大家如果想要的话，就扫描小程序。小程序模仿了火车抢票的病毒式营销的模式，要求大家分享到群聊或者朋友圈，让别人给自己加速，加速到 2019 的前 100 名即可填写信息领取奖品。
然后大家就在推送里看到了我。就酱。
开始 这件事情据说策划了有一段时间了，只是因为各种原因一直没有做，最后这个锅就路由到了我的头上。一开始说就是个加速小程序，逻辑很简单，但后来逐渐发现需求越来越多，主要是界面上的，动画上的，还有一些非技术因素的功能，嗯。这其实算是一个不大好的软件工程案例。
过程 线上的问题与解决方案 然后就是上线了。大概是昨天（2018-12-27）中午的时候推送发出去，很快流量就开始来了。很快，在朋友圈看到有同学在转发了，也有人反映说，网络有点卡，加载资源有点多。我去机器上用 iftop 看了下，流量大概是 250Mb/s ，没打到千兆。我一开始看了下，CPU 和内存占用都良好，以为是网络出口限制的问题，就想着没办法了，就这样吧，扛过去再说。不过，忽然有了转机。
TUNA 技术群里，忽然有人在讨论 SOMAXCONN 的问题，我想到，会不会是有些参数没开够大，导致了性能瓶颈，又受到啊荣的点拨，立马调整了这些变量：
net.core.somaxconn fs.file-max net.core.netdev_max_backlog net.ipv4.tcp_max_syn_backlog nginx: worker_rlimit_nofile nginx: event.worker_connections 很快带宽从 200Mb/s 左右打到了 400Mb/s 多，在 iftop 中看到的峰值接近 600Mb/s，见下图：
事后回来看，发现配置一套科学的监控系统真的很有用，如 TCP 连接的状态图：
这里最高的黄线代表的是 TIME_WAIT ，意味着很多的 TCP 连接都卡在了等待资源上，而一当我修改参数以后，立刻就降了下来，ESTBALISHED 的连接有了显著的提升。这个问题从另一个图也可以明地看出：
这个图是 TCP Handshake Issues ，可以看到无论是 activeopen 还是 passiveopen ，都很高，意味着这里无论是发还是收都遇到了问题。而修改参数以后，这些问题立马得到了很好的改善。
其实这些本应该在上线前做好的，但我低估了清华大学的影响力，没有做好相应的准备，还是在优秀的运维人员的指点下得到了较好的效果。
用户数据分析 当然了，除了 Grafana+InfluxDB+Telegraf 这一套监控系统，我们也部署了 ElasticSearch+Logstash+Kibana ，只不过我们还是用 Grafana 做了 ElasticSearch 的前端了。通过对 Nginx 日志的分析，我们得到了这些关键的数据（从12-26 12:00到12-27 12:00一天时间）：</description>
    </item>
    
    <item>
      <title>部署 adminMongo 的 Docker 镜像</title>
      <link>https://jiege.ch/software/2018/10/23/admin-mongo-docker/</link>
      <pubDate>Tue, 23 Oct 2018 20:08:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/2018/10/23/admin-mongo-docker/</guid>
      <description>之前在软工的平台上部署了一个 MongoDB ，但是自然是仅内网访问，想要浏览内容只能通过网页上的 Console 进去看，体验特别不好。所以想着能不能找一个在线的 MongoDB 浏览器。由于软工平台只能部署 Docker 镜像，所以我找到了mongo-express和adicom/admin-mongo。但软工平台现在还没实现环境变量的配置，所以我选了后者。
首先本地创建一个 app.json ，让它监听 0.0.0.0:80 ，通过 deployer 传到平台上的配置，然后再把配置 mount 到 /app/config 路径上。现在就可以成功地在网页上浏览 MongoDB 了。</description>
    </item>
    
    <item>
      <title>在 Ubuntu 上跨版本迁移 MongoDB</title>
      <link>https://jiege.ch/software/2018/09/13/migrate-mongodb-on-ubuntu/</link>
      <pubDate>Thu, 13 Sep 2018 14:27:00 +0800</pubDate>
      
      <guid>https://jiege.ch/software/2018/09/13/migrate-mongodb-on-ubuntu/</guid>
      <description>由于 MongoDB 只支持当前版本和上一个版本的数据库格式，然后刚刚滚系统升级的时候升级到了 3.6.x ，而数据库格式仍然是 3.2.x 的，于是需要先安装回 3.4.x 版本的 MongoDB，输入命令把数据库升级到 3.4.x 版本后，再用 3.6.x 的数据库进行升级。
以 从 Ubuntu 14.04 LTS 升级到 Ubuntu 18.04.1 LTS 为例，方法如下：
$ wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-3.4.17.tgz $ tar xvf mongodb-linux-x86_64-ubuntu1604-3.4.17.tgz $ cd mongodb-linux-x86_64-ubuntu1604-3.4.17/bin/ $ sudo ./mongod --config /etc/mongodb.conf &amp;amp; $ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#39;3.4&amp;#39; } ) { &amp;#34;ok&amp;#34; : 1 } $ fg ^C $ sudo chown -R mongodb:mongodb /var/lib/mongodb $ sudo systemctl start mongodb $ mongo &amp;gt; db.</description>
    </item>
    
    <item>
      <title>升级 MongoDB 到 4.0</title>
      <link>https://jiege.ch/programming/2018/07/04/upgrade-mongodb-to-4.0/</link>
      <pubDate>Wed, 04 Jul 2018 07:22:00 +0800</pubDate>
      
      <guid>https://jiege.ch/programming/2018/07/04/upgrade-mongodb-to-4.0/</guid>
      <description>MongoDB 4.0 刚刚发布，加入了我很想要的 Transaction 功能。不过，我一更新就发现 MongoDB 起不来了。研究了一下日志，发现由于我创建数据库时，MongoDB版本是 3.4 ，虽然后来升级到了 3.6 ，但还是用着 3.4的兼容模式。这个可以这样来检测：
$ mongo &amp;gt; db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } ) 如果不是 3.6， 升级到 4.0 之前，需要先执行如下操作：
$ # MongoDB version 3.6 $ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#34;3.6&amp;#34; } ) 然后再升级到 MongoDB 4.0 ，才能正常地启动 MongoDB 4.0 。之后可以考虑尝试使用 MongoDB 4.0 的 Transaction 了。不知道什么时候进入 Debian 的 stretch-backports 源中。
为了使用 MongoDB 4.0 的新特性，输入以下命令：
$ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#34;4.0&amp;#34; } ) 之后会尝试一下 MongoDB 4.</description>
    </item>
    
    <item>
      <title>最近写 Node.js 遇到的若干坑</title>
      <link>https://jiege.ch/programming/2018/06/08/nodejs-experiences/</link>
      <pubDate>Fri, 08 Jun 2018 10:33:00 +0800</pubDate>
      
      <guid>https://jiege.ch/programming/2018/06/08/nodejs-experiences/</guid>
      <description>最近在做前后端分离，前端在用 Vue.js 逐步重写，后端则变为 api 的形式。同时，我尝试了用 autocannon 和 clinic 工具测试自己的 api endpoint 的性能，一开始发现有几个延迟会特别高，即使是一个很简单的 api 也有不正常的高延迟。
于是，我用 clinic 生成了 flamegraph ，发现了一些问题：
 我在 session 里保存了一些缓存的信息，这部分内容比较大， express-session 在保存到数据库前会先 JSON.stringify 再 crc 判断是否有改变，如果有改变则保存下来。但是由于我的这个对象嵌套层数多，所以时间花得很多。我调整了这个对象的结构，缩小了很多以后，果然这部分快了很多 有一个 API 需要大量的数据库查询，原本是 O（结点总数）次查询，我考虑到我们数据的结构，改成了O（深度），果然快了许多 之前遇到一个小问题，就是即使我没有登录，服务器也会记录 session 并且返回一个 cookie 。检查以后发现，是 connect-flash 即使在没有使用的时候，也会往 cookie 中写入一个空的对象，这就导致 express-session 认为需要保存，所以出现了问题。解决方案就是，换成了它的一个 fork ： connect-flash-plus ，它解决了这个问题  </description>
    </item>
    
  </channel>
</rss>