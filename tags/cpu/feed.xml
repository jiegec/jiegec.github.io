<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cpu on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jia.je/tags/cpu/</link>
    <description>Recent content in cpu on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Mar 2023 11:18:00 +0800</lastBuildDate><atom:link href="https://jia.je/tags/cpu/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>单核处理器的协同仿真</title>
      <link>https://jia.je/hardware/2023/03/23/core-cosim/</link>
      <pubDate>Thu, 23 Mar 2023 11:18:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2023/03/23/core-cosim/</guid>
      <description>背景 今年的龙芯杯又开始报名了，我来写一篇关于协同仿真（cosim）的博客蹭蹭热度。下面的内容参考了一些已有的协同仿真的框架，例如 ibex co-sim 和 OpenXiangShan/difftest。
协同仿真 RTL 层次的协同仿真可以做不同层次的，这里讨论的是指令提交层次，具体来讲，就是把 CPU 和一个模拟器放在一起协同仿真，检查每条指令执行完以后的状态是否一致。基于代码样例的测试虽然可以覆盖很多情况，但是如果出了错误，报错的地方不一定是出现问题的地方，有些时候就需要往回找很久，才能找到刚出现问题的地方。软件上，大家经常苦于内存错误，经常找不到刚出现溢出的地方，所以要用 valgrind 或者 asan 等工具来直接定位第一次出错的地方。硬件上也是类似，为了精确定位到出错的波形，可以用 cosim。
cosim 是怎么工作的呢？模拟器是软件实现的，它原子地执行一条条指令，同时记录下当前的状态，例如寄存器的取值、内存的状态等等。如果可以让 CPU 和模拟器锁步运行，也就是 CPU 执行一条指令，模拟器执行一条指令，然后比对状态，一旦出现不一致，就直接报错。但实际上 CPU 可能会更加复杂，因为它指令的执行拆分成了很多部分，需要针对流水线进行一些修改，使得它可以生成一个匹配模拟器的原子的执行流。
整体的工作流程如下：
选择一个模拟器，自己写或者使用一个现成的。考虑到模拟器实现的功能和 CPU 不一定一致，有时候需要修改模拟器的源码，所以可以考虑使用一些现成的开源软件，如果是为了 cosim 设计的就更好了。 找到模拟器的单步执行接口，并且让模拟器可以把内部状态暴露出来。这一步可能需要修改源代码。 修改 RTL，把指令的提交信息、寄存器堆的内容通过一些方法传递出来。 修改仿真顶层，每当指令提交的时候，单步执行模拟器，然后比对双方的状态。 模拟器 选择模拟器，要根据你所实现的指令集来选择。下面以 Spike 为例，用来和 RISC-V CPU 进行协同仿真。spike 实现了比较完整的 RISC-V 指令集，并且以库的形式提供了它的 API，但还需要一些修改，让它更加适合协同仿真。这一部分参考了 ibex co-sim的文档。
首先，spike 提供了 step 函数，就是我们想要的单步执行。但是，spike 的 step 在遇到异常或者中断的时候也会返回，但实际上在处理器一侧，通常异常是单独处理的，所以这时候就要修改 spike 的 step 函数，如果遇到异常了，继续执行，直到执行了一条指令为止。与此同时，spike 没有记录最后一次执行的指令的 pc，只记录了下一个 PC，那么在发生异常的时候，就不会记录异常处理的第一条指令的 PC，这里也要进行针对性的修改。
state.last_inst_pc = pc; pc = execute_insn_logged(this, pc, fetch); advance_pc(); 做了这些修改以后，就足够在 cosim 中运行一些简单的程序了。</description>
    </item>
    
    <item>
      <title>Intel 处理器</title>
      <link>https://jia.je/hardware/2023/01/11/intel-cpu/</link>
      <pubDate>Wed, 11 Jan 2023 08:59:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2023/01/11/intel-cpu/</guid>
      <description>Xeon 系列 命名方式：
第一位数字：8-9 对应 Platinum，5-6 对应 Gold，4 对应 Silver，3 对应 Bronze 第二位数字：对应代次，1 对应 1st Generation，2 对应 2nd Generation，依此类推 第三位第四位数字：一般越大性能越好 后缀：H/L/M/N/P/Q/S/T/U/V/Y/Y+/+ L：大内存 M：媒体/大内存 N：网络 P：虚拟化，IaaS Q: 水冷 S：存储/搜索 T：长寿命 U：单插槽 V：虚拟化，SaaS Y: Speed Select 4th Generation Intel® Xeon® Scalable Processors/Xeon CPU Max Series CPU 型号列表 Xeon CPU Max 型号列表 发布时间：Q1&#39;23 代号：Sapphire Rapids/Sapphire Rapids HBM 用途：Server 旗舰：Xeon CPU Max 9480(56C112T，112.5 MB L3，HBM)/Xeon Platinum 8490H(60C120T，Golden Cove，112.5 MB L3)/Xeon Platinum 8480+(56C112T，105 MB L3) 3rd Generation Intel® Xeon® Scalable Processors CPU 型号列表 发布时间：Q2&#39;21(Ice Lake), Q2&#39;20(Cooper Lake) 代号：Cooper Lake/Ice Lake 用途：Server 旗舰：Xeon Platinum 8380(40C80T，Sunny Cove，60 MB L3) 相关阅读：Ice Lake 2nd Generation Intel® Xeon® Scalable Processors CPU 型号列表 发布时间：Q1&#39;20, Q2&#39;19 代号：Cascade Lake 用途：Server 旗舰：Xeon Platinum 9282(56C112T)，Xeon Platinum 8280(28C56T，38.</description>
    </item>
    
    <item>
      <title>AMD 处理器</title>
      <link>https://jia.je/hardware/2023/01/09/amd-cpu/</link>
      <pubDate>Mon, 09 Jan 2023 19:37:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2023/01/09/amd-cpu/</guid>
      <description>Ryzen 系列 Ryzen 5000 代号 用途 核显 插槽 微架构 型号 Vermeer 桌面 无 AM4 Zen 3 5950X/5900(X)/5800(X(3D))/5700X/5600(X) Chagall 工作站 无 sWRX8 Zen 3 5995WX/5975WX/5965WX/5955WX/5945WX Cezanne 桌面 GCN5 AM4 Zen 3 5750G/5700G(E)/5650G/5600G(E)/5500/5300G(E) Cezanne 笔记本 GCN5 FP6 Zen 3 5980HX/5980HS/5900HX/5900HS/5800H(S)/5800U/5600H(S)/5600U/5560U/5400U Barceló 笔记本 GCN5 FP6 Zen 3 5825U/5825C/5625U/5625C/5425U/5425C/5125C Lucienne 笔记本 GCN5 FP6 Zen 2 5700U/5500U/5300U 注：Ryzen 5 5500 虽然代号是 Cezanne，但是去掉了核显。
Ryzen 6000 代号 用途 核显 插槽 微架构 型号 Rembrandt 笔记本 RDNA2 FP7 Zen 3+ 6980HX/6980HS/6900HX/6900HS/6800H(S)/6800U/6600H(S)/6600U Ryzen 7000 代号 用途 核显 插槽 微架构 型号 Raphael 桌面 RDNA2 AM5 Zen 4 7950X(3D)/7900(X(3D))/7800X3D/7700(X)/7600(X) Dragon Range 笔记本 RDNA2 FL1 Zen 4 7945HX/7845HX/7745HX/7645HX Phoenix 笔记本 RDNA3 FP7/FP7r2/FP8 Zen 4 7940HS/7840HS/7640HS Rembrandt R 笔记本 RDNA2 FP7 Zen 3+ 7735HS/7535HS/7736U/7735U/7535U/7335U Barcelo R 笔记本 GCN5?</description>
    </item>
    
    <item>
      <title>浅谈乱序执行 CPU（二）</title>
      <link>https://jia.je/hardware/2022/03/31/brief-into-ooo-2/</link>
      <pubDate>Thu, 31 Mar 2022 01:18:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2022/03/31/brief-into-ooo-2/</guid>
      <description>背景 之前写过一个浅谈乱序执行 CPU，随着学习的深入，内容越来越多，页面太长，因此把后面的一部分内容独立出来，变成了这篇博客文章。之后也许会有（三）（四）等等。
内存访问 内存访问是一个比较复杂的操作，它涉及到缓存、页表、内存序等问题。在乱序执行中，要尽量优化内存访问对其他指令的延迟的影响，同时也要保证正确性。这里参考的是 BOOM 的 LSU 设计。
首先是正确性。一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。
其次是性能，我们希望 Load 指令可以尽快地完成，这样可以使得后续的计算指令可以尽快地开始进行。当 Load 指令的地址已经计算好的时候，就可以去取数据，这时候，首先要去 Store Queue 里面找，如果有 Store 指令要写入的地址等于 Load 的地址，说明后面的 Load 依赖于前面的 Store，如果 Store 的数据已经准备好了，就可以直接把数据转发过来，就不需要从 Cache 中获取，如果数据还没准备好，就需要等待这一条 Store 完成；如果没有找到匹配的 Store 指令，再从内存中取。不过，有一种情况就是，当 Store 指令的地址迟迟没有计算出来，而后面的 Load 已经提前从 Cache 中获取数据了，这时候就会出现错误，所以当 Store 计算出地址的时候，需要检查后面的 Load 指令是否出现地址重合，如果出现了，就要把这条 Load 以及依赖这条 Load 指令的其余指令重新执行。POWER8 处理器微架构论文中对此也有类似的表述：
The POWER8 IFU also implements mechanisms to mitigate performance degradation associated with pipeline hazards.</description>
    </item>
    
    <item>
      <title>「教学」缓存一致性协议分析</title>
      <link>https://jia.je/hardware/2021/12/17/cache-coherency-protocol/</link>
      <pubDate>Fri, 17 Dec 2021 07:39:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2021/12/17/cache-coherency-protocol/</guid>
      <description>本文的内容已经整合到知识库中。
背景 最近在《高等计算机系统结构》课程中学习缓存一致性协议算法，这里用自己的语言来组织一下相关知识的讲解。
Write-invalidate 和 Write-update 最基础的缓存一致性思想有两种：
Write-invalidate：写入数据的时候，将其他 Cache 中这条 Cache Line 设为 Invalid Write-update：写入数据的时候，把新的结果写入到有这条 Cache Line 的其他 Cache Write-once 协议 Write-once 协议定义了四个状态：
Invalid：表示这个块不合法 Valid：表示这个块合法，并可能是共享的，同时数据没有修改 Reserved：表示这个块合法，不是共享的，同时数据没有更改 Dirty：表示这个块合法，不是共享的，数据做了修改，和内存不同。 可见，当一个缓存状态在 R 或者 D，其他缓存只能是 I；而缓存状态是 V 的时候，可以有多个缓存在 V 状态。
Write-once 协议的特点是，第一次写的时候，会写入到内存（类似 Write-through），连续写入则只写到缓存中，类似 Write-back。
当 Read hit 的时候，状态不变。
Read hit: The information is supplied by the current cache. No state change. 当 Read miss 的时候，会查看所有缓存，如果有其他缓存处于 Valid/Reserved/Dirty 状态，就从其他缓存处读取数据，然后设为 Valid，其他缓存也设为 Valid。如果其他缓存处于 Dirty 状态，还要把数据写入内存。
Read miss: The data is read from main memory.</description>
    </item>
    
    <item>
      <title>「教学」RISC-V Debug 协议</title>
      <link>https://jia.je/hardware/2021/12/12/riscv-debug/</link>
      <pubDate>Sun, 12 Dec 2021 14:01:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2021/12/12/riscv-debug/</guid>
      <description>背景 之前用过一些 RISC-V 核心，但是遇到调试相关的内容的时候就两眼一抹黑，不知道原理，出了问题也不知道如何排查，趁此机会研究一下工作原理。
架构 为了调试 RISC-V 核心，需要很多部件一起工作。按 RISC-V Debug Spec 所述，有这么几部分：
Debugger: GDB，连接到 OpenOCD 启动的 GDB Server Debug Translator: OpenOCD，向 GDB 提供 Server 实现，同时会通过 FTDI 等芯片控制 JTAG Debug Transport Hardware: 比如 FTDI 的芯片，可以提供 USB 接口，让 OpenOCD 控制 JTAG 信号 TMS/TDI/TCK 的变化，并读取 TDO Debug Transport Module: 在芯片内部的 JTAG 控制器（TAP），符合 JTAG 标准 Debug Module Interface：RISC-V 自定义的一系列寄存器，通过这些寄存器来控制 Debug Module 的行为 Debug Module：调试器，控制 RISC-V 核心，同时也支持直接访问总线，也有内部的 Program Buffer 可以看到，DMI 是实际的调试接口，而 JTAG 可以认为是一个传输协议。
JTAG 首先什么是 JTAG？简单来说，它工作流程是这样的：</description>
    </item>
    
    <item>
      <title>Manycore 处理器架构分析</title>
      <link>https://jia.je/hardware/2021/12/06/manycore/</link>
      <pubDate>Mon, 06 Dec 2021 00:11:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2021/12/06/manycore/</guid>
      <description>参考文档 Intel® Many Integrated Core Architecture (Intel® MIC Architecture) - Advanced Intel® Xeon Phi coprocessor (codename Knights Corner) https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=7453080 Knights Landing (KNL): 2nd Generation Intel® Xeon Phi™ Processor Fujitsu A64FX Fujitsu Presents Post-K CPU Specifications Fujitsu High Performance CPU for the Post-K Computer SUPERCOMPUTER FUGAKU - SUPERCOMPUTER FUGAKU, A64FX 48C 2.2GHZ, TOFU INTERCONNECT D Preliminary Performance Evaluation of the Fujitsu A64FX Using HPC Applications FUJITSU Processor A64FX NVIDIA A100 Tensor Core GPU Architecture NVIDIA TESLA V100 GPU ARCHITECTURE NVIDIA A100 TENSOR CORE GPU Xeon Phi - Intel MIC MIC: Many Integrated Core Architecture</description>
    </item>
    
    <item>
      <title>Sunway 处理器架构分析</title>
      <link>https://jia.je/hardware/2021/12/04/sunway/</link>
      <pubDate>Sat, 04 Dec 2021 09:13:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2021/12/04/sunway/</guid>
      <description>参考文档 高性能众核处理器申威 26010 稀疏矩阵向量乘法在申威众核架构上的性能优化 Sunway SW26010 The Sunway TaihuLight supercomputer: system and applications Report on the Sunway TaihuLight System Closing the “Quantum Supremacy” Gap: Achieving Real-Time Simulation of a Random Quantum Circuit Using a New Sunway Supercomputer SW_Qsim: A Minimize-Memory Quantum Simulator with High-Performance on a New Sunway Supercomputer 18.9-Pflops Nonlinear Earthquake Simulation on Sunway TaihuLight: Enabling Depiction of 18-Hz and 8-Meter Scenarios A FIRST PEEK AT CHINA’S SUNWAY EXASCALE SUPERCOMPUTER THE NITTY GRITTY OF THE SUNWAY EXASCALE SYSTEM NETWORK AND STORAGE Sunway supercomputer architecture towards exascale computing: analysis and practice SW26010 Sunway TaihuLight 的层次：</description>
    </item>
    
    <item>
      <title>浅谈乱序执行 CPU</title>
      <link>https://jia.je/hardware/2021/09/14/brief-into-ooo/</link>
      <pubDate>Tue, 14 Sep 2021 13:47:00 +0800</pubDate>
      
      <guid>https://jia.je/hardware/2021/09/14/brief-into-ooo/</guid>
      <description>背景 最早学习乱序执行 CPU 的时候，是在 Wikipedia 上自学的，后来在计算机系统结构课上又学了一遍，但发现学的和现在实际采用的乱序执行 CPU 又有很大区别，后来又仔细研究了一下，觉得理解更多了，就想总结一下。
经典 Tomasulo 参考 Stanford 教材
经典 Tomasulo，也是 Wikipedia 上描述的 Tomasulo 算法，它的核心是保留站。指令在 Decode 之后，会被分配到一个保留站中。保留站有以下的这些属性：
Op：需要执行的操作 Qj，Qk：操作数依赖的指令目前所在的保留站 ID Vj，Qk：操作数的值 Rj，Rk：操作数是否 ready（或者用特殊的 Qj，Qk 值表示是否 ready） Busy：这个保留站被占用 此外还有一个 mapping（Wikipedia 上叫做 RegisterStat），记录了寄存器是否会被某个保留站中的指令写入。
指令分配到保留站的时候，会查询 RegisterStat，得知操作数寄存器是否 ready，如果不 ready，说明有一个先前的指令要写入这个寄存器，那就记录下对应的保留站 ID。当操作数都 ready 了，就可以进入计算单元计算。当一条指令在执行单元中完成的时候，未出现 WAW 时会把结果写入寄存器堆，并且通过 Common Data Bus 进行广播，目前在保留站中的指令如果发现，它所需要的操作数刚好计算出来了，就会把取值保存下来。
这里有一些细节：因为保留站中的指令可能要等待其他指令的完成，为了保证计算单元利用率更高，对于同一个计算类型（比如 ALU），需要有若干个同类的保留站（比如 Add1，Add2，Add3）。在 Wikipedia 的表述中，每个保留站对应了一个计算单元，这样性能比较好，但自然面积也就更大。如果节省面积，也可以减少计算单元的数量，然后每个计算单元从多个保留站中获取计算的指令。
可以思考一下，这种方法的瓶颈在什么地方。首先，每条指令都放在一个保留站中，当保留站满的时候就不能发射新的指令。其次，如果计算单元的吞吐跟不上保留站的填充速度，也会导致阻塞。
这种方法的一个比较麻烦的点在于难以实现精确异常。精确异常的关键在于，异常之前的指令都生效，异常和异常之后的指令不生效，但这种方法无法进行区分。
从寄存器重命名的角度来看，可以认为这种方法属于 Implicit Register Renaming，也就是说，把 Register 重命名为保留站的 ID。
再分析一下寄存器堆需要哪些读写口。有一条规律是，寄存器堆的面积与读写口个数的平方成正比。对于每条发射的指令，都需要从寄存器堆读操作数，所以读口是操作数 x 指令发射数。当执行单元完成计算的时候，需要写入寄存器堆，所以每个执行单元都对应一个寄存器堆的写口。
硬件实现的时候，为了性能，希望保留站可以做的比较多，这样可以容纳更多的指令。但是，保留站里面至少要保存操作数的值，会比较占用面积，并且时延也比较大。
ROB (ReOrder Buffer) 参考教材</description>
    </item>
    
    <item>
      <title>Verilog 初体验</title>
      <link>https://jia.je/programming/2018/06/21/verilog-first-try/</link>
      <pubDate>Thu, 21 Jun 2018 21:36:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/21/verilog-first-try/</guid>
      <description>自己以前一直对硬件方面没有接触，但是大二大三很快就要接触相关知识，所以自己就先预习一下 Verilog HDL，以便以后造计算机。听学长们推荐了一本书叫《自己动手写 CPU》，由于自己手中只有很老的 Spartan-3 板子，手上没有可以用来试验的 FPGA，所以选择用 Verilog + Verilator 进行模拟。既然是模拟，自然是会有一定的问题，不过这个以后再说。
然后就是模仿着这本书的例子，写了指令的获取和指令的解码两部分很少很少的代码，只能解码 ori (or with immidiate) 这一个指令。然后，通过 verilator 跑模拟，输出 vcd 文件，再用 gtkwave 显示波形，终于能够看到我想要的结果了。能够看到，前一个时钟周期获取指令，下一个时钟周期进行解码，出现了流水线的结果。这让我十分开心。
接下来就是实现一些基本的算术指令，然后讲计算的结果写入到相应的寄存器中。这样做完之后，就可以做一个基于 verilator 的简易 A+B 程序了。
我的代码发布在jiegec/learn_verilog中。最近马上到考试周，可能到暑假会更频繁地更新吧。</description>
    </item>
    
    <item>
      <title>用 CPUID 获取评测机器的 CPU</title>
      <link>https://jia.je/others/2017/10/30/use-cpuid-to-get-machine-cpu/</link>
      <pubDate>Mon, 30 Oct 2017 21:07:23 +0800</pubDate>
      
      <guid>https://jia.je/others/2017/10/30/use-cpuid-to-get-machine-cpu/</guid>
      <description>受用 CPUID 检测各大 OJ 测评机所用的 CPU（以及日常黑 BZOJ）的启发，我决定去测试一下徐老师自己写的 OJ（名为 Tyche）所跑的机器是什么 CPU。于是我改造一下代码，用以下代码测评：
#include &amp;lt;stdint.h&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;time.h&amp;gt; #include &amp;lt;cpuid.h&amp;gt; #include &amp;lt;sys/time.h&amp;gt; static void cpuid(uint32_t func, uint32_t sub, uint32_t data[4]) { __cpuid_count(func, sub, data[0], data[1], data[2], data[3]); } int main() { uint32_t data[4]; char str[48]; for(int i = 0; i &amp;lt; 3; ++i) { cpuid(0x80000002 + i, 0, data); for(int j = 0; j &amp;lt; 4; ++j) reinterpret_cast&amp;lt;uint32_t*&amp;gt;(str)[i * 4 + j] = data[j]; } struct timeval stop, start; gettimeofday(&amp;amp;start, NULL); while(1) { gettimeofday(&amp;amp;stop, NULL); if(stop.</description>
    </item>
    
  </channel>
</rss>
