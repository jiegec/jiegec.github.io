<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jia.je/category/programming/</link>
    <description>Recent content in programming on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Jul 2022 10:49:00 +0800</lastBuildDate><atom:link href="https://jia.je/category/programming/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>编程作业中的学术诚信</title>
      <link>https://jia.je/programming/2022/07/12/writing-code-cn/</link>
      <pubDate>Tue, 12 Jul 2022 10:49:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2022/07/12/writing-code-cn/</guid>
      <description>本文是我自己对 Academic Integrity at MIT: Writing Code 的非官方中文翻译。本文已经得到了官方的邮件授权。
编写代码 Writing Code 与学术写作类似，当你在做课程项目的时候，如果使用了或者改编了其他人开发的代码，你必须要引用代码的来源。你可以在代码注释中引用代码来源。这些注释不仅保护了他人的劳动成果，也会帮助你理解代码和调试。
Writing code is similar to academic writing in that when you use or adapt code developed by someone else as part of your project, you must cite your source. However, instead of quoting or paraphrasing a source, you include an inline comment in the code. These comments not only ensure you are giving proper credit, but help with code understanding and debugging.</description>
    </item>
    
    <item>
      <title>C&#43;&#43; 11 的 ABI 问题</title>
      <link>https://jia.je/programming/2021/06/23/cpp-11-abi-problem/</link>
      <pubDate>Wed, 23 Jun 2021 14:48:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2021/06/23/cpp-11-abi-problem/</guid>
      <description>背景 有同学遇到这样的一个问题，代码中链接了一个第三方的动态库，在链接的时候出现了不一致的问题，比如有一个函数签名如下：
void foobar(std::string s) {} 使用 GCC 11.1.0 编译上面的代码，可以发现它需要的符号是 _Z6foobarNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE，但是第三方库里面却是 _Z6foobarSs，因此找不到对应的符号，链接失败。
问题 经过一番研究，发现 Ss 在 Itanium ABI 中表示的是缩写：
In addition, the following catalog of abbreviations of the form &amp;#34;Sx&amp;#34; are used: &amp;lt;substitution&amp;gt; ::= St # ::std:: &amp;lt;substitution&amp;gt; ::= Sa # ::std::allocator &amp;lt;substitution&amp;gt; ::= Sb # ::std::basic_string &amp;lt;substitution&amp;gt; ::= Ss # ::std::basic_string &amp;lt; char, ::std::char_traits&amp;lt;char&amp;gt;, ::std::allocator&amp;lt;char&amp;gt; &amp;gt; &amp;lt;substitution&amp;gt; ::= Si # ::std::basic_istream&amp;lt;char, std::char_traits&amp;lt;char&amp;gt; &amp;gt; &amp;lt;substitution&amp;gt; ::= So # ::std::basic_ostream&amp;lt;char, std::char_traits&amp;lt;char&amp;gt; &amp;gt; &amp;lt;substitution&amp;gt; ::= Sd # ::std::basic_iostream&amp;lt;char, std::char_traits&amp;lt;char&amp;gt; &amp;gt; 这看起来很正常，_Z6foobarSs 表示的是 foobar(std::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;)，但是 GCC 11.</description>
    </item>
    
    <item>
      <title>Rust 在 M1 上的 Code Signing 问题和临时解决方法</title>
      <link>https://jia.je/programming/2020/12/04/workaround-rust-on-m1/</link>
      <pubDate>Fri, 04 Dec 2020 09:27:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2020/12/04/workaround-rust-on-m1/</guid>
      <description>不久前，rust 添加了 Tier2 的 aarch64-apple-darwin 的支持，试了一下，确实可以运行，不过当我编译的时候，出现：
error: failed to run custom build command for `xxxx v1.0 (/path/to/xxxx)` Caused by: process didn&amp;#39;t exit successfully: `/path/to/xxx/target/debug/build/xxx-xxxx/build-script-build` (signal: 9, SIGKILL: kill) 看了一下 Console.app 里面的 crash 日志，发现是 codesigning 问题。解决方法是，用 codesign 命令来签名：
# for build.rs codesign -s - target/debug/build/*/build-script-build # for dylib of some crates codesign -s - target/debug/deps/*.dylib # for final executable codesign -s - target/debug/xxx 多次编译并签名后，就可以正常运行最后的二进制了：
target/debug/xxxx: Mach-O 64-bit executable arm64 然后就可以了。等待上游添加 code signing 支持吧。</description>
    </item>
    
    <item>
      <title>在 arm64 上使用 rust-analyzer</title>
      <link>https://jia.je/programming/2020/09/13/aarch64-rust-analyzer/</link>
      <pubDate>Sun, 13 Sep 2020 16:34:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2020/09/13/aarch64-rust-analyzer/</guid>
      <description>远程到 arm64 的机器上进行开发，发现没有 rust-analyzer 的支持。研究了一下，发现在 rustup 里面可以找到，不过要配置一下：
&amp;gt; rustup toolchain add nightly &amp;gt; rustup component add --toolchain nightly rust-analyzer-preview 这个时候，应该可以找到 ~/.rustup/toolchains/nightly-aarch64-unknown-linux-gnu/bin/rust-analyzer 文件，接下来，配置 VSCode 插件即可：
{ &amp;#34;rust-analyzer.serverPath&amp;#34;: &amp;#34;~/.rustup/toolchains/nightly-aarch64-unknown-linux-gnu/bin/rust-analyzer&amp;#34; } 路径在 ~/.vscode-server/data/Machine/settings.json。
参考：https://github.com/rust-analyzer/rust-analyzer/issues/5256</description>
    </item>
    
    <item>
      <title>实现一个简单的 Decaf LSP</title>
      <link>https://jia.je/programming/2019/11/17/rust-decaf-lsp/</link>
      <pubDate>Sun, 17 Nov 2019 14:40:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/11/17/rust-decaf-lsp/</guid>
      <description>背景 编译原理课程在做 Decaf 的 PA，之前做了一些比较简单的尝试，包括在线 Decaf、在线 TAC VM 等等，都是套一个前端，然后整个编译到 wasm 跑前端就可以了。如果要做 LSP 的话，工作量会稍微大一些，不过也更加实用。
然后有一天，助教 @equation314 写了 decaf-vscode 一个 VSCode 对 Decaf 的语法高亮插件，我就 Fork 了一份到 jiegec/decaf-vscode，然后添加了 LSP 的支持，让它有了一些更高级的功能。
实现 LSP 服务端一般是一个命令行程序，通过 JSONRPC 进行消息通讯，然后就上午找有没有现成的框架。比较重要的是 lsp-types 和 tower-lsp ，前者封装了 LSP 协议的各个结构体，后者提供了服务端的大概实现。不过由于后者做的不大全，所以我自己 fork 了一份添加了一些。
实际实现的时候，需要实现几个函数，分别相应客户端的请求，比如在 initialize 的时候告诉客户端我都实现了哪些东西，然后相应地提供各种信息，如 symbol，hover，folding，definition 等等。为了实现简单，我要求客户端每次修改的时候都把完整的文件传过来，虽然不是很高效，但是很简单，目前也没有啥很长的 Decaf 程序嘛。
每次拿到 Decaf 程序之后，就按照 decaf-rs 的方法，Lex 然后 Parse，然后遍历 AST，分别把需要的各个信息都存下来，当客户端在请求的时候，直接返回即可。然后就会在 VSCode 中出现，比如实现了 document symbol，在左边的 Outline 中就会出现相应的结构；实现了 hover，当移动到一些地方的时候，客户端发出请求，服务端就把相应的 hover 信息返回给客户端。整个协议并不复杂，后面实际实现其实才是比较复杂的地方。
实现的功能中，symbols hovers ranges definition 都是在得到 AST 后一次遍历都计算好，然后返回，同时在遇到错误的时候，也通过 diagnostic 的形式把检查出来的错误汇报给用户。由于 VSCode 的良好支持，基本不需要写 TypeScript 代码。</description>
    </item>
    
    <item>
      <title>用 Rust Procedure Macro 实现 GLL Parser</title>
      <link>https://jia.je/programming/2019/11/15/rust-proc-macro-gll/</link>
      <pubDate>Fri, 15 Nov 2019 11:13:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/11/15/rust-proc-macro-gll/</guid>
      <description>背景 在编译原理课上，PA 框架采用的是 MashPlant/lalr1 ，是一个比较好用的 Lexer + Parser 的工具，它的大概语法见 一个完整的例子 。然后之前看到了 GLL Parser，想着可不可以照着类似的语法也写一个 GLL 的 Parser Generator，也是用 Rust Procedure Macro 的方法，就开始了研究。
尝试 首先是阅读 GLL 的论文，它并不长，大概的意思就是，LL(1) 文法需要考虑 PS 冲突的情况，而 GLL 的解决方法就是“都试一下”，然后为了效率，用了 GSS 表示解析过程和 SPPF 表示解析结果。然后就开始照着论文手写了不同版本的实现，见 jiegec/gll-test 。
第一种就是按照论文里第一段实现直接抄过来，每个可能性作为一个 Continuation 存下来，它有自己的栈和执行位置（Label）。这样 Work 以后呢，我又想到了 async/await，用类似的方法又写了一遍，相对要简洁一些，也是很平常的递归下降的写法，而不是 Loop + Label 的形式。但这些都不能做到合并栈的目的，所以遇到十分有歧义的文法的时候会很糟糕。
然后开始按照论文中的 GSS 进行编写，基本还是按照论文进行翻译，然后一步一步做，做好以后把 GSS 画出来，和论文的图可以对的上；然后照着 GLL parse-tree generation 的论文把 SPPF 实现了，这时候就可以从 recongizer 变成一个 parser 了。
宏 得到一份可行的代码以后，就要扩展到通用的情况上。学习了一下 MashPlant/lalr1 的实现，实现了一个 proc macro，它读取了用户的程序，从一个模板文件开始，往里面插入一些生成的代码，丢给编译器去编译。这时候就涉及到编译期和运行时的不同了，我把运行时一些通用的结构放到了 gll-pg-core 中，把编译期的代码放到了 gll-pg-macros 。</description>
    </item>
    
    <item>
      <title>前端解析上传的 CSV</title>
      <link>https://jia.je/programming/2019/07/17/parse-upload-csv-frontend/</link>
      <pubDate>Wed, 17 Jul 2019 13:05:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/07/17/parse-upload-csv-frontend/</guid>
      <description>之前做过一个在前端解析上传的 CSV 的功能，但是只能支持部分的 encoding，遇到 gbk 就傻眼了。一番研究以后，找到了比较科学的方案：
import * as Chardet from &amp;#39;chardet&amp;#39;; import * as Iconv from &amp;#39;iconv-lite&amp;#39;; const reader = new FileReader(); reader.onload = (e) =&amp;gt; { const data = e.target.result; const view = Buffer.from(data); // detect encoding and convert const encoding = Chardet.detect(view); const result = Iconv.decode(view, encoding); const csvData = Papa.parse(result).data; // do anything with it }; reader.readAsArrayBuffer(blob_here); 依赖了两个库：chardet 和 iconv-lite ，测试了一下，解析 UTF-8 GBK UTF-16BE 都没问题。
P.S. 在生成 csv 的时候，也会出现 Excel 打开后乱码的问题，一开始我以为需要转 UTF-16 然后再添加 BOM Mark，后来发现只要在最前面加上 0xEF 0xBB 0xFB（UTF-8 编码下的 BOM Mark）即可。</description>
    </item>
    
    <item>
      <title>IP 前缀转换上意外遇到的 Undefined Behavior</title>
      <link>https://jia.je/programming/2019/06/21/ip-prefix-unexpected-undefined-behavior/</link>
      <pubDate>Fri, 21 Jun 2019 21:23:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/06/21/ip-prefix-unexpected-undefined-behavior/</guid>
      <description>最近发现了两个很神奇的 Undefined Behavior，出现在 Prefix Len 和 Netmask 的转换的问题下。一个简单思路可能是：
#define PREFIX_BIN2DEC(bin) (32 - __builtin_ctz((bin))) #define PREFIX_DEC2BIN(hex) (((~0) &amp;gt;&amp;gt; (32 - (hex))) &amp;lt;&amp;lt; (32 - (hex)) 乍一看，似乎没有什么问题。但是，在一些平台下，可能会出现这样的结果：
PREFIX_BIN2DEC(0x00000000) = 33 PREFIX_DEC2BIN(0) = 0xFFFFFFFF 而且只能在一些平台上不确定地复现，最后发现其实是 Undefined Behavior，在 C 的标准中：
In any case, the behavior is undefined if rhs is negative or is greater or equal the number of bits in the promoted lhs. 意味着， 0xFFFFFFFF &amp;gt;&amp;gt; 32 是一个 UB，所以出现了上面的问题。
另外，__builtin_ctz 有这样的说明：
Returns the number of trailing 0-bits in x, starting at the least significant bit position.</description>
    </item>
    
    <item>
      <title>在 rCore 上运行 nginx</title>
      <link>https://jia.je/programming/2019/03/08/running-nginx-on-rcore/</link>
      <pubDate>Fri, 08 Mar 2019 18:07:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/03/08/running-nginx-on-rcore/</guid>
      <description>阿 西 吧 nginx 终于能在 rCore 上跑了 orrrrrrrz
通过这半个多月来的大量开发，我和王润基 @wangrunji0408 学长算是终于完成了第一个 milestone：跑起来一个 nginx。遇到了很多困难，大概有这些：
syscall 实现不全。各种方面都缺，然后 nginx 在编译的时候又检测到比较新的 OS 版本，所以很多 syscall 都用了新的来替代老的，例如 readv/writev pread/pwrite accept4 等等，所以这方面做了一些工作。另外，还有很多新的 syscall 进来，太多了我就不细说了，基本上一个 commit 做一点一个 commit 做一点这个样子。 nginx 用到了 SSE 的寄存器 xmm，但是之前是没有开的。所以把 sse 打开，然后切换上下文的时候把 sse 通过 fxsave 保存和 fxrstor 恢复（有意思的是，as 居然不认这俩，只好手动写字节码），然后为了 16bit 的对齐又写了几行汇编代码。这块问题不大，今天一会就搞定了。但是如果要性能更高一些的话，可能需要在第一次使用 xmm 的时候再开始保存，大概就是加一个 bit 的事情。 文件系统有点崩。实现还是有很多 BUG，表现就是需要经常重新 mksfs 一下，再重启加载完好的 fs，有时候强制关机一下就又崩了。 内存管理做了一些改变。为了实现更加完整的 mmap mumap 和 mprotect，又发现了一些新的 BUG 在里面，然后慢慢修复了。就是实现的有点粗暴。 死锁问题。这个其实现在还会出现，只是还没调出来，也不会百分百出现。我们计划在锁上面做一些死锁检测，例如记住是谁上锁的，等等。现在就遇到一个很玄学的死锁问题。 然后代码也是一边在写一边在重构吧，很多地方现在都写得很粗暴，FIXME 和 TODO 留了很多，很多地方也写得不够优雅。以后再慢慢重构 + 优化吧。</description>
    </item>
    
    <item>
      <title>实现网络的 syscall</title>
      <link>https://jia.je/programming/2019/03/04/implement-network-syscalls/</link>
      <pubDate>Mon, 04 Mar 2019 16:40:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/03/04/implement-network-syscalls/</guid>
      <description>有了网卡驱动，接下来要做的就做网络的 syscall 了。为了测试，首先在 busybox 里找可以用来测试的 applet，由于没有实现 poll，所以 nc telnet 啥的都用不了。最后选择到了 ping 和 pscan 上。
ping 大家都很了解，pscan 就是一个扫端口的，对一个 ip 连续的若干个端口发起 tcp 请求。这就要求我提供 raw socket 和 tcp socket 状态的支持。由于网络栈本身是异步的，但 read connect 这些函数在不调 setsockopt 的前提下又是同步的，然而现在又没有 signal 可以用，要是 block 了就再也出不来了。于是就采用了 Condvar 的办法，拿一个全局的条件变量，当 poll 不到内容的时候，先把线程拿掉，等到网络栈更新了，再恢复。这样至少不会把 cpu 也 block 住。
然后就是把 socket 部分改了又改吧，数据结构的设计改了几次，为了解决 ownership 问题上锁啊也有点多，但是也更细了，虽然实际上可能没有必要，因为上面还有大的锁。不过性能还不是现在考虑的重点，关键还要先把 send recv accept bind listen 啥的写得差不多了，然后还有把 poll/select 实现了，这个很关键。
中间遇到的最大的坑就是，接收 pci interrupt 的时候总是啥也没有，然后靠万能的 qemu trace 发现，原来是 mask 掉了，所以啥也收不了，然后最后的解决方案就是用 MSI Interrupt #55 搞定了这个问题。至于为啥是 55 呢，因为 23 + 32 = 55 啊（误</description>
    </item>
    
    <item>
      <title>使用 Rust 实现 e1000 驱动</title>
      <link>https://jia.je/programming/2019/02/26/network-driver-again/</link>
      <pubDate>Tue, 26 Feb 2019 20:30:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/02/26/network-driver-again/</guid>
      <description>是的。我又来了。上次做了使用 Rust 实现 VirtIO 驱动之后，继续往 rCore 加更多的驱动支持。由于现在工作重点是 x86_64 下的 syscall 实现，所以选了一个比较有代表性的驱动 e1000 来实现。其实如果只是为了在 qemu 下运行的话，其实只需要支持 virtio-pci 就可以了，原来的 virtio-net 直接拿来用就可以了。
为什么挑 e1000 呢，一方面是支持的设备多，有真实硬件可以测试，虽然不一定要裸机上跑，但是可以通过 PCI passthrough 来测试驱动的正确性。另一方面是网上的资料比较多，有现成的简单的代码可以借鉴。这次主要借鉴了三个来源：一是 Biscuit OS，二是 Judge Duck OS，三是 Linux。
首先是实现了简单的 PCI 总线的枚举，然后找到对应的设备，激活，并且找到映射的内存地址，然后把原来 C 语言的实现搬运到 Rust 中。这个过程中遇到很多坑，例如一开始我以为内核里 pa 和 va 是一个固定的偏移，不过多次尝试后才发现这个假设只对 riscv 平台里的实现成立。
这个时候就可以收到外面给进来的以太网帧了。接着就是把它接入到 smoltcp 的 API 中。但是发包又不工作了，尝试了很多次，各种方法也不行。其中特别要提到的就是 qemu 的 tracing API，它在帮助我调试之前的 virtio 驱动和这次的 e1000(e) 驱动中起到了很大的帮助。不过，遗憾的是，发包相关的代码里的 trace 不足以让我找到问题的所在，我只好采用了最后一招：
下载 QEMU，自己改，然后自己编译。
这个方法果然很有效啊，经过简单的几个修改，很快就定位到问题所在了，原来就是一个简单的错误，把 4 写成了 8。这个过程中我也发现 QEMU 在 incremental build 的时候似乎会 segfault，我没管这么多，反正编译也不慢，次数也不多，每次 clean 再 build 问题也不大。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（9）</title>
      <link>https://jia.je/programming/2019/02/12/thoughts-on-stanford-cs140e-9/</link>
      <pubDate>Tue, 12 Feb 2019 11:35:00 +0400</pubDate>
      
      <guid>https://jia.je/programming/2019/02/12/thoughts-on-stanford-cs140e-9/</guid>
      <description>距离上一篇 CS140e 系列文章已经过去了很久，距离第一篇文章过了一年零几天。在后来这一段时间内，CS140e 结束了课程，又开始了新一年的 winter 2019 课程，迎来的却是 C 版本的 CS140e，不禁让人感到失望。还好，Sergio Benitez 放出了原来的 CS140e 的镜像，如果大家仍然想回去查看原版优质的 CS140e，可以点进去参考。
后来因为机缘巧合参与到了清华的 Rust OS 课程，又想到回来把原来的 CS140e 进行更新，于是顺带把跑在 QEMU 下的一些需要的工作给做了，另外把 Rust nightly 版本更新了（一年前的 nightly 还能叫 nightly？），才发现标准库变化还是蛮大的，由于 nightly 版本变了，而且原来是内嵌了一个阉割过的 std，所以主要是从新的 std 里抄代码到内嵌的 std 中。另外，原来的 xargo 也不再维护了，转而使用 rust-xbuild 进行交叉编译。
然后又顺手实现了 backtrace 和从 backtrace 中配合 dward symbols 找函数名的功能，不过实践证明，这些东西还是 addr2line 做得更好，所以也就没有做下去，在 relocation 上也是遇到了各种问题。这个经验也是应用到了 rCore 那边。
再之后也就是寒假写驱动了，见之前的一个博文，我就没有在 CS140e 上去实现它了。有时间有兴趣的时候再考虑做一下 Raspberry Pi 的网卡驱动吧。
写于迪拜雨天。</description>
    </item>
    
    <item>
      <title>使用 Rust 实现 VirtIO 驱动</title>
      <link>https://jia.je/programming/2019/01/29/virtio-drivers-implementation/</link>
      <pubDate>Tue, 29 Jan 2019 17:23:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/01/29/virtio-drivers-implementation/</guid>
      <description>背景 最近在给 rCore 添加驱动层的支持。一开始是想做网卡驱动，后来发现， qemu-system-riscv32 只支持如下的驱动：
# qemu-system-riscv32 -device help Storage devices: name &amp;#34;scsi-cd&amp;#34;, bus SCSI, desc &amp;#34;virtual SCSI CD-ROM&amp;#34; name &amp;#34;scsi-disk&amp;#34;, bus SCSI, desc &amp;#34;virtual SCSI disk or CD-ROM (legacy)&amp;#34; name &amp;#34;scsi-hd&amp;#34;, bus SCSI, desc &amp;#34;virtual SCSI disk&amp;#34; name &amp;#34;virtio-blk-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-scsi-device&amp;#34;, bus virtio-bus Network devices: name &amp;#34;virtio-net-device&amp;#34;, bus virtio-bus Input devices: name &amp;#34;virtconsole&amp;#34;, bus virtio-serial-bus name &amp;#34;virtio-keyboard-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-mouse-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-serial-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-tablet-device&amp;#34;, bus virtio-bus name &amp;#34;virtserialport&amp;#34;, bus virtio-serial-bus Display devices: name &amp;#34;virtio-gpu-device&amp;#34;, bus virtio-bus Misc devices: name &amp;#34;loader&amp;#34;, desc &amp;#34;Generic Loader&amp;#34; name &amp;#34;virtio-balloon-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-crypto-device&amp;#34;, bus virtio-bus name &amp;#34;virtio-rng-device&amp;#34;, bus virtio-bus 所以要实现网卡的话，只能实现这里的 virtio-net-device ，而 VirtIO 驱动之间有很多共通的地方，于是顺带把 gpu mouse 和 blk 实现了。</description>
    </item>
    
    <item>
      <title>Rust 获取 Linker Script 中的地址</title>
      <link>https://jia.je/programming/2019/01/07/rust-access-linker-script-address/</link>
      <pubDate>Mon, 07 Jan 2019 11:57:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2019/01/07/rust-access-linker-script-address/</guid>
      <description>在 Linker Script 中可以记录下一个地址到一个变量中，大概这样：
.text: { PROVIDE(__text_start = .); *(.text .text.* .gnu.linkonce.t*) PROVIDE(__text_end = .); } 这里的 PROVIDE() 是可选的。这样，代码里就可以获取到 .text 段的地址了。在 C 中，直接 extern 一个同名的变量就可以了，但在 Rust 中，需要这样获取：
extern &amp;#34;C&amp;#34; { fn __text_start(); fn __text_end(); } // __text_start as usize // __text_end as usize 这样就可以拿到地址了。</description>
    </item>
    
    <item>
      <title>升级 MongoDB 到 4.0</title>
      <link>https://jia.je/programming/2018/07/04/upgrade-mongodb-to-4.0/</link>
      <pubDate>Wed, 04 Jul 2018 07:22:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/07/04/upgrade-mongodb-to-4.0/</guid>
      <description>MongoDB 4.0 刚刚发布，加入了我很想要的 Transaction 功能。不过，我一更新就发现 MongoDB 起不来了。研究了一下日志，发现由于我创建数据库时，MongoDB 版本是 3.4，虽然后来升级到了 3.6，但还是用着 3.4 的兼容模式。这个可以这样来检测：
$ mongo &amp;gt; db.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } ) 如果不是 3.6，升级到 4.0 之前，需要先执行如下操作：
$ # MongoDB version 3.6 $ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#34;3.6&amp;#34; } ) 然后再升级到 MongoDB 4.0，才能正常地启动 MongoDB 4.0。之后可以考虑尝试使用 MongoDB 4.0 的 Transaction 了。不知道什么时候进入 Debian 的 stretch-backports 源中。
为了使用 MongoDB 4.0 的新特性，输入以下命令：
$ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#34;4.0&amp;#34; } ) 之后会尝试一下 MongoDB 4.</description>
    </item>
    
    <item>
      <title>Verilog 初体验</title>
      <link>https://jia.je/programming/2018/06/21/verilog-first-try/</link>
      <pubDate>Thu, 21 Jun 2018 21:36:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/21/verilog-first-try/</guid>
      <description>自己以前一直对硬件方面没有接触，但是大二大三很快就要接触相关知识，所以自己就先预习一下 Verilog HDL，以便以后造计算机。听学长们推荐了一本书叫《自己动手写 CPU》，由于自己手中只有很老的 Spartan-3 板子，手上没有可以用来试验的 FPGA，所以选择用 Verilog + Verilator 进行模拟。既然是模拟，自然是会有一定的问题，不过这个以后再说。
然后就是模仿着这本书的例子，写了指令的获取和指令的解码两部分很少很少的代码，只能解码 ori (or with immidiate) 这一个指令。然后，通过 verilator 跑模拟，输出 vcd 文件，再用 gtkwave 显示波形，终于能够看到我想要的结果了。能够看到，前一个时钟周期获取指令，下一个时钟周期进行解码，出现了流水线的结果。这让我十分开心。
接下来就是实现一些基本的算术指令，然后讲计算的结果写入到相应的寄存器中。这样做完之后，就可以做一个基于 verilator 的简易 A+B 程序了。
我的代码发布在jiegec/learn_verilog中。最近马上到考试周，可能到暑假会更频繁地更新吧。</description>
    </item>
    
    <item>
      <title>在 ArchLinux 上编译 LineageOS for Huawei Angler</title>
      <link>https://jia.je/programming/2018/06/18/building-lineageos-in-archlinux/</link>
      <pubDate>Mon, 18 Jun 2018 05:47:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/18/building-lineageos-in-archlinux/</guid>
      <description>实践了一下如何在 ArchLinux 上编译自己的 LineageOS。本文主要根据官方文档 进行编写。
$ # for py2 virtualenv and running x86 prebuilt binaries(e.g. bison) $ sudo pacman -Sy python2-virtualenv lib32-gcc-libs $ mkdir -p ~/bin $ mkdir -p ~/virtualenv $ # build script is written in python 2 $ cd ~/virtualenv $ virtualenv2 -p /usr/bin/python2 py2 $ mkdir -p ~/android/lineage $ curl https://storage.googleapis.com/git-repo-downloads/repo &amp;gt; ~/bin/repo $ chmod a+x ~/bin/repo $ vim ~/.config/fish/config.fish set -x PATH ~/bin $PATH set -x USE_CCACHE=1 $ exec fish -l $ cd ~/android/lineage $ repo init -u https://github.</description>
    </item>
    
    <item>
      <title>编写 eBPF 程序和利用 HyperLogLog 统计包的信息</title>
      <link>https://jia.je/programming/2018/06/15/ebpf-with-hyperloglog/</link>
      <pubDate>Fri, 15 Jun 2018 22:03:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/15/ebpf-with-hyperloglog/</guid>
      <description>前段时间在写概率论与数理统计的期末论文，讨论的主题是如何对一个十分巨大的多重集合（或者是流）中相异元素个数进行估计，写的是 HyperLogLog 等算法。联想到前段时间 LWN 上多次提到的 eBPF 和 BCC 的文章，我准备自己用 eBPF 实现一个高效的估计 inbound packet 中来相异源地址的个数和 outbound packet 中相异目的地址的个数。经过了许多的尝试和努力，最终是写成了 jiegec/hll_ebpf ，大致原理如下：
由于 eBPF 是一个采用专用的 bytecode 并且跑在内核中的语言，虽然我们可以用 clang 写 C 语言然后交给 LLVM 生成相应地 eBPF bytecode，但仍然收到许多的限制。而且，我很少接触 Linux 内核开发，于是在找内核头文件时费了一番功夫。首先是核心代码：
struct bpf_map_def SEC(&amp;#34;maps&amp;#34;) hll_ebpf_out_daddr = { .type = BPF_MAP_TYPE_PERCPU_ARRAY, .key_size = sizeof(u32), .value_size = sizeof(u32), .max_entries = 256, .pinning = 2 // PIN_GLOBAL_NS }; SEC(&amp;#34;out_daddr&amp;#34;) int bpf_out_daddr(struct __sk_buff *skb) { u32 daddr = get_daddr(skb); u32 hash = Murmur3(daddr, 0); update_hll(&amp;amp;hll_ebpf_out_daddr, hash); return 0; } 首先是声名一个类型为 PERCPU_ARRAY 的 eBPF MAP 类型。这里的 MAP 不是字典，Array 才是真是的数据结构，只不过提供的 API 是类似于字典的。SEC 宏则是指定这个东西要放在哪一个段，这个在后面会提到。这个函数的作用就是，获取 IP 包的目的地址（其实应该判断一下是否是 IPv4 的），然后根据 HyperLogLog 的要求，进行哈希（这里采用的是 Murmur3），然后对得到的哈希值分段，前一部分用于索引，后一部分的 nlz（clz, whatever）用于估计。具体算法详情可以参考 HyperLogLog 的论文。</description>
    </item>
    
    <item>
      <title>调整 Nginx 和 PHP 的上传文件大小限制</title>
      <link>https://jia.je/programming/2018/06/10/nginx-php-upload-size-limit/</link>
      <pubDate>Sun, 10 Jun 2018 16:04:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/10/nginx-php-upload-size-limit/</guid>
      <description>之前迁移的 MediaWiki，有人提出说无法上传一个 1.4M 的文件。我去看了一下网站，上面写的是限制在 2M，但是一上传就说 Entity Too Large，无法上传。后来经过研究，是 Nginx 对 POST 的大小进行了限制，同时 PHP 也有限制。
Nginx 的话，可以在 nginx.conf 的 http 中添加，也可以在 server 或者 location 中加入这么一行：
client_max_body_size 100m; 我的建议是，尽量缩小范围到需要的地方，即 location &amp;gt; server &amp;gt; http 。
在 PHP 中，则修改 /etc/php/7.0/fpm/php.ini：
post_max_size = 100M 回到 MediaWiki 的上传页面，可以看到显示的大小限制自动变成了 100M，这个是从 PHP 的配置中直接获得的。</description>
    </item>
    
    <item>
      <title>最近写 Node.js 遇到的若干坑</title>
      <link>https://jia.je/programming/2018/06/08/nodejs-experiences/</link>
      <pubDate>Fri, 08 Jun 2018 10:33:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/06/08/nodejs-experiences/</guid>
      <description>最近在做前后端分离，前端在用 Vue.js 逐步重写，后端则变为 api 的形式。同时，我尝试了用 autocannon 和 clinic 工具测试自己的 api endpoint 的性能，一开始发现有几个延迟会特别高，即使是一个很简单的 api 也有不正常的高延迟。
于是，我用 clinic 生成了 flamegraph，发现了一些问题：
我在 session 里保存了一些缓存的信息，这部分内容比较大，express-session 在保存到数据库前会先 JSON.stringify 再 crc 判断是否有改变，如果有改变则保存下来。但是由于我的这个对象嵌套层数多，所以时间花得很多。我调整了这个对象的结构，缩小了很多以后，果然这部分快了很多 有一个 API 需要大量的数据库查询，原本是 O（结点总数）次查询，我考虑到我们数据的结构，改成了 O（深度），果然快了许多 之前遇到一个小问题，就是即使我没有登录，服务器也会记录 session 并且返回一个 cookie。检查以后发现，是 connect-flash 即使在没有使用的时候，也会往 cookie 中写入一个空的对象，这就导致 express-session 认为需要保存，所以出现了问题。解决方案就是，换成了它的一个 fork：connect-flash-plus，它解决了这个问题 </description>
    </item>
    
    <item>
      <title>在脚本中寻找 X11 的 DISPLAY 和 XAUTHORITY</title>
      <link>https://jia.je/programming/2018/05/11/finding-x11-display-and-xauthority/</link>
      <pubDate>Fri, 11 May 2018 14:21:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/05/11/finding-x11-display-and-xauthority/</guid>
      <description>之前在搞一个小工具，在里面需要访问 X11 server，但是访问 X11 server 我们需要两个东西：DISPLAY 和 XAUTHORITY 两个环境变量。但是，由于它们在不同的发型版和 Display Manager 下都有些不同，所以花了不少功夫才写了一些。
为了验证我们是否可以连上 X11 server，我们使用这一句：
DIMENSIONS=$(xdpyinfo | grep &amp;#39;dimensions:&amp;#39; | awk &amp;#39;{print $2;exit}&amp;#39;) 它尝试打开当前的 DISPLAY，并且输出它的分辨率。接下来，我对不同的一些发型版，综合网上的方法，尝试去找到正确的环境变量。
对于 Debian:
DISPLAY=$(w -hs | awk -v tty=&amp;#34;$(cat /sys/class/tty/tty0/active)&amp;#34; &amp;#39;$2 == tty &amp;amp;&amp;amp; $3 != &amp;#34;-&amp;#34; {print $3; exit}&amp;#39;) USER=$(w -hs | awk -v tty=&amp;#34;$(cat /sys/class/tty/tty0/active)&amp;#34; &amp;#39;$2 == tty &amp;amp;&amp;amp; $3 != &amp;#34;-&amp;#34; {print $1; exit}&amp;#39;) eval XAUTHORITY=~$USER/.Xauthority export DISPLAY export XAUTHORITY DIMENSIONS=$(xdpyinfo | grep &amp;#39;dimensions:&amp;#39; | awk &amp;#39;{print $2;exit}&amp;#39;) 对于 Archlinux：</description>
    </item>
    
    <item>
      <title>把 GDB 降级到 8.0.1</title>
      <link>https://jia.je/programming/2018/04/17/downgrade-gdb/</link>
      <pubDate>Tue, 17 Apr 2018 13:08:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/04/17/downgrade-gdb/</guid>
      <description>在 macOS 上使用 GDB 需要 codesigning。但是在 GDB 升级到 8.1 后这种方法不知道为何失效了。所以我安装回了 GDB 8.0.1 并且重新 codesigning，现在又可以正常升级了。
对 Formula 进行 patch：
diff --git a/Formula/gdb.rb b/Formula/gdb.rb index 29a1c590..25360893 100644 --- a/Formula/gdb.rb +++ b/Formula/gdb.rb @@ -1,14 +1,15 @@ class Gdb &amp;lt; Formula desc &amp;#34;GNU debugger&amp;#34; homepage &amp;#34;https://www.gnu.org/software/gdb/&amp;#34; - url &amp;#34;https://ftp.gnu.org/gnu/gdb/gdb-8.1.tar.xz&amp;#34; - mirror &amp;#34;https://ftpmirror.gnu.org/gdb/gdb-8.1.tar.xz&amp;#34; - sha256 &amp;#34;af61a0263858e69c5dce51eab26662ff3d2ad9aa68da9583e8143b5426be4b34&amp;#34; + url &amp;#34;https://ftp.gnu.org/gnu/gdb/gdb-8.0.1.tar.xz&amp;#34; + mirror &amp;#34;https://ftpmirror.gnu.org/gdb/gdb-8.0.1.tar.xz&amp;#34; + sha256 &amp;#34;3dbd5f93e36ba2815ad0efab030dcd0c7b211d7b353a40a53f4c02d7d56295e3&amp;#34; bottle do - sha256 &amp;#34;43a6d6cca157ef70d13848f35c04e11d832dc0c96f5bcf53a43330f524b3ac40&amp;#34; =&amp;gt; :high_sierra - sha256 &amp;#34;fe7c6261f9164e7a744c9c512ba7e5afff0e74e373ece9b5aa19d5da6443bfc2&amp;#34; =&amp;gt; :sierra - sha256 &amp;#34;cd89001bcf8c93b5d6425ab91a400aeffe0cd5bbb0eccd8ab38c719ab5ca34ba&amp;#34; =&amp;gt; :el_capitan + sha256 &amp;#34;e98ad847402592bd48a9b1468fefb2fac32aff1fa19c2681c3cea7fb457baaa0&amp;#34; =&amp;gt; :high_sierra + sha256 &amp;#34;0fdd20562170c520cfb16e63d902c13a01ec468cb39a85851412e7515b6241e9&amp;#34; =&amp;gt; :sierra + sha256 &amp;#34;f51136c70cff44167dfb8c76b679292d911bd134c2de3fef40777da5f1f308a0&amp;#34; =&amp;gt; :el_capitan + sha256 &amp;#34;2b32a51703f6e254572c55575f08f1e0c7bc2f4e96778cb1fa6582eddfb1d113&amp;#34; =&amp;gt; :yosemite end deprecated_option &amp;#34;with-brewed-python&amp;#34; =&amp;gt; &amp;#34;with-python@2&amp;#34; </description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（8）</title>
      <link>https://jia.je/programming/2018/04/10/thoughts-on-stanford-cs140e-8/</link>
      <pubDate>Tue, 10 Apr 2018 17:27:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/04/10/thoughts-on-stanford-cs140e-8/</guid>
      <description>在上一篇文章之后，我其实还是很忙，但是一直心理惦记着这件事，毕竟只剩最后的一点点就可以做完了，不做完总是觉得心痒。
今天做的部分是调度。我们目前只在 EL0 运行了一个 shell，每当触发 exception 时回到 kernel 进行处理，再回到原来的地方。但现在，我要实现一个 preemtive round-robin scheduler，就需要管理当前的所有进程，并且维护当前的进程状态，当时钟中断到来的时候，决定下一个 time slice 要执行的进程，再切换过去。这个过程当然会遇到不少的坑。
首先，我们需要判断一个进程是否可以执行了。考虑到阻塞的 IO，作者提供了一个优雅的方法：如果这个进程阻塞在 IO 上，那么，提供一个函数，在 scheduler 中调用，判断所需要的数据是否到达。这样，我们就可以一个循环把下一个 time slice 要执行的线程找到。如果找不到，就等待 interrupt 再尝试。
困难的地方在于，在启动的时候，切换到一个起始线程。并且在上下文切换的时候，在 process 1 -&amp;gt; kernel -&amp;gt; process 2 这两步过程中，有许多寄存器都需要仔细考虑如何实现。并且在这个过程中，我也发现了之前写的代码中的问题，最终修复了（目前来看是 working 了）。
我的代码实现在 这里 。下一步就要写 syscall 了。希望能在期中前抽时间赶紧把这个做完。
18:54 PM Update: 刚实现完了 sleep 的 syscall。比预想中要简单。果然找到了自己实现的调度器的 BUG。此系列大概是完结了。
2019-02-12 Update: 下一篇文章。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（7）</title>
      <link>https://jia.je/programming/2018/04/07/thoughts-on-stanford-cs140e-7/</link>
      <pubDate>Sat, 07 Apr 2018 14:05:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/04/07/thoughts-on-stanford-cs140e-7/</guid>
      <description>在上一篇文章之后，我很长时间都没有在继续我这个项目，清明节刚好闲下来了我就回来继续啃它。Stanford 那边已经结课，最后的 3-spawn 也只有一部分，剩下的部分不知道什么时候作者才会填上去了。
这次主要要写的代码就是，对异常的处理。这里的异常并不是我们编程语言中的 catch/throw，而是硬件的异常。AArch64 和 x86 一样，也有不同的特权级别的区分，前者是 EL0~EL3，后者则是 RING0 和 RING3。特权级别高可以往特权级别低转换，但是反过来，只能通过异常的方式提高特权等级，并且切换特权等级后只有固定的一些代码可能会跳转，这就是 exception handler/vectors 。这些函数可以知道是什么原因调用了他们，根据硬件规定好的文档，我们可以知道发生了什么事情，是对齐出错了呢，还是用户调用了 syscall 呢，等等。根据不同的情况，我们需要进行不同的处理。当处理完之后，我们需要考虑，跳转回用户代码的时候，回到哪里，提供什么值，不提供什么。
实现的话，需要很多步骤。首先是构造好 exception vector ，这里作者已经写好了一个宏（这里 @BenYip 遇到了一个 assembler 的 BUG），直接用宏就可以把它写出来。然后，我们需要把它加载到当前 EL 的 VBAR_ELx 寄存器中，当 CPU 抛出异常的时候，就会找到这里相应的处理器进行处理。进到这里以后，我们首先先不考虑太多上下文保存的事情&amp;ndash;我们先保证能处理异常，恢复也是个有很多坑的步骤，作者也是在这里分成了两个 Subphase。首先还是从 ESR_ELx 中解析到错误的来源的具体内容，如果是我们在 shell 中自己调用的 brk 2 指令，我们就自己新开一个 shell ，修改了提示符以示区别。这样，我们就成功地捕捉到了这个异常。由于我们还无法恢复回去，所以我们直接死循环。
接下来我们要做的是，从异常中恢复出来。由于用户代码可能在各种地方抛出异常，异常也分同步和异步两种情况，这里有许多需要考虑的问题。为了简化，我们目前只考虑同步的 brk 2 导致的 Brk 异常。为了能恢复之后能够正常运行，我们需要把所有的寄存器都保存下来，即 TrapFrame 。保存的时候需要讲究 AArch64 平台下 SP 寄存器的对齐问题。我们也要把一些特殊的寄存器保存下来。还有一点，就是，因为 exception handler 中调用了 context_save 函数，所以此时的 lr 本身也需要进行保存，这个地方也卡了我很久。最后，再把这些一个一个地恢复到原来的样子，调整 ELR_EL1 使得退回到原来的状态时，会跳过当前的 brk 2 指令，调用它的下一调指令。这样，我们就成功地在遇到异常时，弹出一个 shell ，而且还可以回退回来。
学到了很多很多。之后大三，我们可能需要做自己的 CPU，在自己的 CPU 上跑自己的操作系统，在自己的操作系统中跑自己的编译器，在自己的编译器中编译一个数据库。希望到时我还活着吧。#flag</description>
    </item>
    
    <item>
      <title>〖新手向〗绕过 C&#43;&#43; 类的访问限制</title>
      <link>https://jia.je/programming/2018/03/07/breaking-c-weak-access-control/</link>
      <pubDate>Wed, 07 Mar 2018 07:59:20 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/03/07/breaking-c-weak-access-control/</guid>
      <description>这是一篇很水的文章，面向萌新，已经知道了的可以自觉绕道。
昨天上课，有同学问，如果用户偷偷把 private 改成 public 再和原有的库链接，是不是就可以在用户代码里更改了。这个答案是肯定的。下面我们就做个实验：
首先，创建 good_class.h 和 good_class.cpp:
class SomeClass { private: int data; public: int getData(); }; #include &amp;#34;good_class.h&amp;#34; int SomeClass::getData() { return data; } 然后，首先编译，
clang++ -c good_class.cpp -o good_class.o 然后，修改 good_class.cpp 并写一个 evil_user.cpp
class SomeClass { public: int data; public: int getData(); }; #include &amp;lt;stdio.h&amp;gt; #include &amp;#34;good_class.h&amp;#34; int main() { SomeClass a; a.data = 37; printf(&amp;#34;%d\n&amp;#34;, a.getData()); return 0; } 编译：
clang++ good_class.o evil_user.cpp -o evil 然后 evil 如愿地输出了 37 。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（6）</title>
      <link>https://jia.je/programming/2018/03/05/thoughts-on-stanford-cs140e-6/</link>
      <pubDate>Mon, 05 Mar 2018 19:55:49 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/03/05/thoughts-on-stanford-cs140e-6/</guid>
      <description>在上一篇文章之后，作者终于更新了测试的用例，我的程序终于可以成功跑过所有测试，也成功在树莓派跑起来。不过，我的代码中很多地方的错误处理比较偷懒，往往直接 panic ，显然并不友好。同时，我想到了使用 cargo-fuzz 来进行自动化测试，果然，使用这个很快就修复了不少我没想到的会出错的地方，比如乘法溢出，目录项没有正确结束等等。目前还发现一个 timeout 的问题，研究发现大概是文件的 cluster chain 中出现了环，导致一直读取文件而没有停止。要解决这个问题，我目前想到的是 Floyd 的判圈算法，但还没上实现。等过几天，新的 Assignment 3 出了以后，再继续更新。希望作者少点跳票，多点勤奋，哈哈哈哈哈
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（5）</title>
      <link>https://jia.je/programming/2018/03/03/thoughts-on-stanford-cs140e-5/</link>
      <pubDate>Sat, 03 Mar 2018 11:07:30 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/03/03/thoughts-on-stanford-cs140e-5/</guid>
      <description>在上一篇文章之后，作者多次延期跳票之后（again），终于放出了 Assignment 2 Phase 3: Saddle Up 。这次，我们要做的变成了把已经写好的（错漏百出）的 fat32 的驱动搬到树莓派里面去，然后实现一些基本的 shell 命令： ls cat cd 等等。作者首先更新了老版本的新的测试样例，放了一些映像然后提供了预期的结果，结果发现，这里的 fat32 有一些不同，主要的就是 bytes_per_sector 不是 512 了，意味着物理的扇区和逻辑扇区并不一致。同时， sectors_per_cluster 也不是 1 了，需要考虑多个扇区的情况。同时， read_cluster 传入的 offset 也可能不再是第一个 sector 中的，所以需要做一个处理。对于物理和逻辑扇区的问题，作者推荐的方案是，把 fat32 之外的扇区保持不变，把其内的扇区视为逻辑扇区。这样，其它代码都可以透明地工作，而不用到处更改，这就体现了封装的威力。接着，作者提供了一个写好了的 libsd 和一些导出的函数，使用这些函数即可。不过，在错误处理和 timeout 上也遇到了一些坑。后面，把东西搬到树莓派上运行，问题就出现了：读取了第一个扇区（即 MBR 所在的扇区）之后，直接就死掉了。想了半天都没找到方案，突然想起可以利用 panic! 对错误语句进行二分查找。查找了大概有七八个小时之后，终于发现，问题出现在读取一个 u32 类型的变量上。我起初怀疑是栈出了问题，所以放到堆上分配，然而还是不行。忽然想起以前遇到的对齐问题，在 AArch64 架构上，可能为了简化，读取的 u32 必须对齐到四个字节上。于是找了找 Rust 中的对齐方面的文档，找到了 #[repr(align=4)] 这种表示方法，代替了原来的 #[repr(packed)] ，并且把数据先拷贝到对齐后的栈上的对应数据结构，然后再读取对应的项。果然，这个问题就解决了。然后又发现我的盘中会出现 lfn 项并不是从后往前的情况，于是我又修改了一下相关的代码。现在，终于可以成功地 ls cat cd 。
不过还是要吐槽一下，作者的测试用的映像文件中，会出现 0xE5 表示这个项已经被删除的情况，但是似乎作者的代码并没有处理这个，所以在预期的输出中出现了一些明显不正确的结果，导致我的代码跑测试并不能通过。而且，作者的代码在一些情况下会把文件的后缀漏掉。作者后来更新了几次测试的文件，不过这个问题只解决了一部分，并没有完全解决。坐等作者继续放出新的测试文件吧。
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（4）</title>
      <link>https://jia.je/programming/2018/02/27/thoughts-on-stanford-cs140e-4/</link>
      <pubDate>Tue, 27 Feb 2018 22:42:59 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/27/thoughts-on-stanford-cs140e-4/</guid>
      <description>在上一篇文章之后，作者多次延期跳票之后，终于放出了 Assignment 2 Phase 2:32-bit Lipids ，这两天就把只读 FAT32 写完了（不过封装得并不好，许多地方利用了 pub(super) 把变量可以访问的范围控制到 vfat 中，然后直接读，只有少数需要特殊处理的进行了函数的封装）。首先当然是研究了半天 MBR 和 FAT32 的结构，拿了不同来源的 FAT 结构说明进行对比和验证，最后终于把格式搞清楚了，先实现了 MasterBootRecord ，这个其实很好实现，以前也有接触过 MBR ，本身也很简单。然后就是根据 MBR 找到第一个 FAT32 的分区，根据偏移找到分区的开头，开头的第一个扇区就是 EBPB 数据结构，里面保存了 FAT32 分区的各种信息。根据里面的信息，可以找到 FAT 表的位置和数量，还有数据部分的 Cluster 的位置和数量。接着，解析一下 FAT 表，实际上是一个与 Cluster 一一对应的链表结构，用特殊的数据代表链表的尾和空、坏扇区。利用这些，和 EBPB 中根目录所在的第一个 Cluster ，先在 VFat 里面实现了读取一个 Cluster 链的内容的函数，利用这个函数读取一个一个的目录项，解析目录项，把长文件名的项合并到一个之中，然后对应地丢到 Entry 对象中，目录则可以枚举子目录项，根据名字比较去找子目录或者子文件夹，文件则实现了 io::Read和 io::Seek 使得可以读取文件的内容。实现好了这些以后，就拿了 raspbian-strech-lite.img 作为硬盘映像，从文件里读取文件信息，成功地把 config.txt 读取出来。
其中还是遇到许多困难，如各种偏移的计算，如何处理跨 Cluster 和跨 Sector 的读写，等等，有不少的坑在其中，花了两天的空余时间才差不多完善了这个功能。还有就是利用 Rust 现有的功能完成 C 里面很轻易就可以实现的指针操作，也花了不少时间。
更新：下一篇在这里。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（3）</title>
      <link>https://jia.je/programming/2018/02/16/thoughts-on-stanford-cs140e-3/</link>
      <pubDate>Fri, 16 Feb 2018 20:09:00 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/16/thoughts-on-stanford-cs140e-3/</guid>
      <description>由于 Assignment 2: File System 延期发布，所以中间那段时间转向 MIT 6.828 稍微研究了一下。前几天放出了新的任务，在上一篇文章之后，我又有了一些进展： 实现了从内存中读取 ATAGS(ARM Tags) 信息的代码，从而可以获得内存大小的信息，根据这个信息，实现了 bump 和 bin 两种内存分配器，并且把二者之一注册为全局内存分配器，利用上更新了的 std 就可以使用需要动态分配内存的相关工具了。利用这个，我实现了 shell 输入历史的回溯，把输入历史保存在一个动态增长的数组中，再特殊处理上下键，把当前的行替换为历史。
这个过程也不是没有踩坑。一开始代码放出来了，但是题目说明还没出，我就自己按照代码做了 ATAGS 和 bump 分配器，后来做完了，看到说明出了以后，发现理解还是有偏差，把代码更改了并修复了分配器的 BUG 。看到 bin 分配器的时候，我按照网上的 buddy memory allocation 实现了一个内存分配器，原理看起来简单实现起来还是有很多细节问题，后来按照新放出的单元测试，修修补补才写得差不多可用了。同时，原来的 bootloader 因为用了新的 std 而缺失了 alloc 不能编译，我就把 kernel 下的相关文件软连接过去，调了数次后把问题解决。此时， kernel 文件大小已经有 40K ，按照 115200 Baudrate 发送需要几秒才能传输过去，我就调到了 230400 Baudrate ，果然现在的传输速度就有所提升，可以接受了。等之后写了 EMMC(SD card) 的驱动和 FAT32 的文件系统后，就可以实现更多的 shell 的功能了。中间还遇到一个问题，就是如果给 kernel 开启了 bin 分配器，使用 exit 回到 bootloader 就无法传新的 kernel 上去了，结果发现是因为 bin 中用到的侵入式 LinkedList 实现覆盖了部分 bootloader 的代码，换回不能回收内存的 bump 分配器即可，反正目前远远还用不了那么多内存。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考（2）</title>
      <link>https://jia.je/programming/2018/02/06/thoughts-on-stanford-cs140e-2/</link>
      <pubDate>Tue, 06 Feb 2018 12:52:59 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/06/thoughts-on-stanford-cs140e-2/</guid>
      <description>在上一篇文章之后，我又有了一些进展：UART ，简易的shell ，修复了之前写的 xmodem 中的 BUG，一个可以从 UART 接收一个 kernel 写入到内存中再跳转过去的 bootloader 。
首先是 UART ，就是通过两个 GPIO pin 进行数据传输，首先在 memory mapped IO 上进行相应的初始化，然后包装了 io::Read 和 io::Write （这里实现一开始有 BUG，后来修复了），然后很快地完成了一个仅仅能 echo 的 kernel 。
然后实现了 CONSOLE ，一个对 MiniUart 和单例封装，就可以用 kprint!/kprintln! 宏来输出到 UART ，接着实现了一个 echo 的 shell ，读入一行输出一行。然后实现退格键和方向键，这里的难点在于要控制光标并且用读入的或者空格覆盖掉屏幕上已经显示而不应该显示的内容。接着，利用 skeleton 中的 Command 做了一个简单的 echo 命令。
接着，利用之前编写的 tty ，配合上新编写的 bootloader ，实现通过 UART 把新的 kernel 通过 XMODEM 协议发送到设备，写入 0x80000 启动地址并且调转到新加载的 kernel 中执行。
最后，又实现了 uptime （输出设备启动到现在的时间）和 exit （跳转回 bootloader ，可以上传新的 kernel ）。并添加了 TUNA 作为 shell 启动时输出的 BANNER 。</description>
    </item>
    
    <item>
      <title>近来做 Stanford CS140e 的一些进展和思考</title>
      <link>https://jia.je/programming/2018/02/04/thoughts-on-stanford-cs140e/</link>
      <pubDate>Sun, 04 Feb 2018 22:28:23 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/02/04/thoughts-on-stanford-cs140e/</guid>
      <description>最近，受各路安利，剁手买下了 这个淘宝商家的树莓派的套餐 C ，还买了许多 LED 灯泡、杜邦线和电阻，开始按照 CS 140e 学习 Rust 并且用 Rust 编译写一个简易的操作系统。Assignment 0 的目标就是编写一个向 GPIO 16 连接的 LED 灯闪烁。首先当然就是愉快地按照教程下载 bootloader，下载交叉编译工具链，顺带装一个 Raspbian 到机器上，随时可以当成一个低性能的 ARM/ARM64（实际上，Raspbian 只用了 armv7l，没有用 64bit）机器来用，以后如果配上 @scateu 团购的 Motorola Laptop Dock 的话就是一个几百块的笔记本了。把课程上的文件丢上去，可以看到绿色的活动指示灯闪烁，后面又把 CP2102 模块连上去，又能看到 Blink on, Blink off 的输出。然后按照要求，自己先码一段 C 语言，实现 blinky:
#define GPIO_BASE (0x3F000000 + 0x200000) volatile unsigned *GPIO_FSEL1 = (volatile unsigned *)(GPIO_BASE + 0x04); volatile unsigned *GPIO_SET0 = (volatile unsigned *)(GPIO_BASE + 0x1C); volatile unsigned *GPIO_CLR0 = (volatile unsigned *)(GPIO_BASE + 0x28); static void spin_sleep_us(unsigned int us) { for (unsigned int i = 0; i &amp;lt; us * 6; i++) { asm volatile(&amp;#34;nop&amp;#34;); } } static void spin_sleep_ms(unsigned int ms) { spin_sleep_us(ms * 1000); } int main(void) { // STEP 1: Set GPIO Pin 16 as output.</description>
    </item>
    
    <item>
      <title>再次吐槽 VS 关于 scanf 和 scanf_s 的问题</title>
      <link>https://jia.je/programming/2018/01/30/more-on-scanf-and-scanf_s/</link>
      <pubDate>Tue, 30 Jan 2018 16:05:33 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/01/30/more-on-scanf-and-scanf_s/</guid>
      <description>继上次的吐槽后，今天再次遇到同学因为 scanf 在 VS 下的 deprecation error 感到十分迷茫，在知乎上求助又因为拍照的原因被说，我就在此再次吐槽一下 VS 这对初学者很不友善很不友善的两点。
一点就是上面提到的这个，另一点就是程序结束后任意键以退出这一功能要做得更加醒目一点。前者由于大多数新手在学习 C/C++ 的时候都会跟着书上或者网上的代码敲一遍输入输出的代码，很容易就会撞到这个问题。后者则会让新手习惯性地以为程序闪退了，没有出结果，而不知道其实是程序执行结束后关闭而已。</description>
    </item>
    
    <item>
      <title>我正在使用的两个 Emacs 的 Patch</title>
      <link>https://jia.je/programming/2018/01/07/two-patches-of-emacs-i-am-using/</link>
      <pubDate>Sun, 07 Jan 2018 14:24:24 +0800</pubDate>
      
      <guid>https://jia.je/programming/2018/01/07/two-patches-of-emacs-i-am-using/</guid>
      <description>我在本地对 emacs.rb 进行了修改：
diff --git a/Formula/emacs.rb b/Formula/emacs.rb index d0138cd..de3c5ff 100644 --- a/Formula/emacs.rb +++ b/Formula/emacs.rb @@ -4,6 +4,14 @@ class Emacs &amp;lt; Formula url &amp;#34;https://ftp.gnu.org/gnu/emacs/emacs-25.3.tar.xz&amp;#34; sha256 &amp;#34;253ac5e7075e594549b83fd9ec116a9dc37294d415e2f21f8ee109829307c00b&amp;#34; + patch do + url &amp;#34;https://gist.githubusercontent.com/aatxe/260261daf70865fbf1749095de9172c5/raw/214b50c62450be1cbee9f11cecba846dd66c7d06/patch-multicolor-font.diff&amp;#34; + end + + patch do + url &amp;#34;https://debbugs.gnu.org/cgi/bugreport.cgi?filename=0001-Fix-child-frame-placement-issues-bug-29953.patch;bug=29953;att=1;msg=8&amp;#34; + end + bottle do sha256 &amp;#34;d5ce62eb55d64830264873a363a99f3de58c35c0bd1602cb7fd0bc37137b0c9d&amp;#34; =&amp;gt; :high_sierra sha256 &amp;#34;4d7ff7f96c9812a9f58cd45796aef789a1b5d26c58e3e68ecf520fab34af524d&amp;#34; =&amp;gt; :sierra 主要涉及到两个 Patch：
启用对 Multicolor font，比如 Emoji 的支持。由于一些 ethic problems 暂时在 Emacs 中被禁用了，所以自己启用回来。 打上我前几天上报的 BUG #29953 的修复。已经在上游 Merge 到 emacs-26 分支中，这个修复会在下一个版本中。 有了第一个，就可以正常显示 Emoji（对不起，RMS）；有了第二个，就解决了 pyim 和 lsp-ui-peek 用 child-frame 显示的一些问题了。</description>
    </item>
    
    <item>
      <title>有趣的 Java 日期格式化问题</title>
      <link>https://jia.je/programming/2017/12/31/interesting-java-formatting-problem/</link>
      <pubDate>Sun, 31 Dec 2017 10:55:23 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/12/31/interesting-java-formatting-problem/</guid>
      <description>今天在群里看到有人说，Java 的日期格式化有问题，如果用 YYYY-MM-dd ，今天的日期就会显示 2018-12-31 。我立马在本地用 Java REPL (aka Groovy) 跑了一下，果然如此：
$ date = new Date() ===&amp;gt; Sun Dec 31 10:51:26 CST 2017 $ import java.text.SimpleDateFormat ===&amp;gt; java.text.SimpleDateFormat $ new SimpleDateFormat(&amp;#34;YYYY-MM-dd&amp;#34;).format(date) ===&amp;gt; 2018-12-31 解决方案是，把格式换为 yyyy-MM-dd ，确实就可以了。于是我就去研究了一下文档： Class SimpleDateFormat ，发现了问题：
y 代表 year ，而 Y 代表 week year 。根据 week year ，因为今年最后的一个星期在明年的部分更多，于是这个星期被归在了明年，所以这一周属于 2018，这就可以解释之前的那个输出问题了。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2017/12/12/lsp-and-cpp/</link>
      <pubDate>Tue, 12 Dec 2017 08:13:40 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/12/12/lsp-and-cpp/</guid>
      <description>之前时间，巨硬发布了 LSP（Language Server Protocol），目的是解决目前 IDE 和各语言的 m+n 问题。想法很好，不过直到最近，终于有我觉得可以用的工具出来了，并且已经代替了我在使用的其它的插件。
由于我最近主要就是做做程设作业，做做 OJ 这些，主要就是和 C++打交道。所以我当然就开始找一些比较成熟的 C++的 LSP server。有一个 Sourcegraph 维护的 langserver.org ，上面有着目前的各个语言和编辑器/IDE 的支持情况，我刚才提到的 cquery 也会加入到这个列表里去。从这个列表里可以看到，我用的比较多的 Python 和 Haskell 都已经有不错的的 LSP server，我已经开始在本地体验 pyls 和 hie 了，感觉做得挺不错的。
回到 C++，我的主力编辑器是 Emacs，其次是 CLion，而 Emacs 上的LSP 支持 lsp-mode也在快速发展，与之配合的lsp-ui 也出现了很多很棒的功能。
下面开始编译并配置cquery：
git clone https://github.com/jacobdufault/cquery --recursive cd cquery ./waf configure # to use system clang, append --use-system-clang ./waf build 然后配置 Emacs：
(use-package lsp-mode :ensure t :diminish lsp-mode :commands (lsp-mode) :config (lsp-define-stdio-client lsp-pyls &amp;#34;python&amp;#34; #&amp;#39;get-project-root &amp;#39;(&amp;#34;/usr/local/bin/pyls&amp;#34;))) (use-package lsp-ui :commands lsp-ui-mode :init (add-hook &amp;#39;lsp-mode-hook &amp;#39;lsp-ui-mode)) (use-package cquery :load-path &amp;#34;path_to_cquery/emacs&amp;#34; :config (setq cquery-executable &amp;#34;path_to_cquery/build/app&amp;#34; cquery-resource-dir &amp;#34;path_to_cquery/clang_resource_dir&amp;#34;)) 接下来，需要配置 基于 Clang 的 工具都需要的 Compilation Database。Sacrasm 对这个有一个非常完整的总结 ，可以查看里面的方法。我这里推荐在 CMake 项目中用 CMake 自带的，加上nickdiego/compiledb-generator 应付基于Makefile/Autotools的项目。如果都不适用，就按照cquery的README写一个简单的.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2017/12/02/on-nginx-memory-pool/</link>
      <pubDate>Sat, 02 Dec 2017 22:16:07 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/12/02/on-nginx-memory-pool/</guid>
      <description>今晚参加了 Tunight，会长给我们讲了 Nginx 的一些内部运作的机制和原理。中间的时候，会长展示的代码中用到了线程池方面的一些函数，但是大多地方只有调用 ngx_pcalloc 而没有看到相应的对象释放的过程，于是在演示的最后，会长应大家要求对 Nginx 魔幻的线程池实现做了现场代码分析。
在分析的中途遇到了很多坑，最后才终于理清了内存池的工作原理。这里直接解释结论吧。以下代码均摘自 Nginx 1.13.7，代码都可以在官方仓库找到。
首先分析一下创建一个内存池的函数：
ngx_pool_t * ngx_create_pool(size_t size, ngx_log_t *log) { ngx_pool_t *p; p = ngx_memalign(NGX_POOL_ALIGNMENT, size, log); if (p == NULL) { return NULL; } p-&amp;gt;d.last = (u_char *) p + sizeof(ngx_pool_t); p-&amp;gt;d.end = (u_char *) p + size; p-&amp;gt;d.next = NULL; p-&amp;gt;d.failed = 0; size = size - sizeof(ngx_pool_t); p-&amp;gt;max = (size &amp;lt; NGX_MAX_ALLOC_FROM_POOL) ? size : NGX_MAX_ALLOC_FROM_POOL; p-&amp;gt;current = p; p-&amp;gt;chain = NULL; p-&amp;gt;large = NULL; p-&amp;gt;cleanup = NULL; p-&amp;gt;log = log; return p; } 现在开始分段分析这个函数：在这里，一个内存池用一个 ngx_pool_t (aka struct ngx_pool_s) 类型的数据进行包装，所有的关于内存池的操作都基于相应的内存池对象。 ngx_log_t 表示输出信息的对象，与内存池无关，后面也不会讨论它。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2017/11/30/run-cpp-in-jupyter-notebook/</link>
      <pubDate>Thu, 30 Nov 2017 18:07:10 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/11/30/run-cpp-in-jupyter-notebook/</guid>
      <description>刚刚在 HN 上看到了这么一个文章：Interactive Workflows for C++ with Jupyter HN ，终于可以在 Jupyter Notebook 里跑 C++代码了，很开心，于是开始自己研究了起来怎么本地跑。
首先当然是更新一波 jupyter，安装一波 cling：
pip3 install -U jupyter brew install cling 然后根据官方教程里的要求执行：
cd /usr/local/share/cling/Jupyter/kernel pip3 install -e . jupyter kernelspec install cling-cpp11 jupyter kernelspec install cling-cpp14 jupyter kernelspec install cling-cpp17 jupyter kernelspec install cling-cpp1z 结果发现找不到jupyter-kernelspec，遂重装了一下jupyter-client这个包，果然就可以了。打开一个 notebook 测试：
jupyter notebook 然后创建一个 C++14 的 Notebook，结果发现一直 Kernel rebooting，错误信息是说找不到../Cellar/cling/0.5/lib/libclingJupyter.dylib。这一看就是路径处理的问题，当前目录肯定不是/usr/local，肯定出现了什么问题，然后研究发现cling-kernel.py中对cling判断是否是个连接，如果是连接则按照连接去找cling的安装目录，但是！没有考虑到这个连接是个相对路径的问题（Homebrew 你背锅吗）。于是我愉快地改了代码并提交了PR。修复了以后就可以用了。
以下是一个小小的例子：
&amp;gt;&amp;gt; jupyter console --kernel cling-cpp14 Jupyter console 5.2.0 cling-X In [1]: #include &amp;lt;stdio.</description>
    </item>
    
    <item>
      <title>分析一个我第一次见的素数测试函数</title>
      <link>https://jia.je/programming/2017/10/17/analysis-on-a-primality-test/</link>
      <pubDate>Tue, 17 Oct 2017 21:05:28 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/10/17/analysis-on-a-primality-test/</guid>
      <description>今天逛到这个连接，发现其中的第四种素数判定方法很有意思：
#include&amp;lt;stdio.h&amp;gt; #include&amp;lt;math.h&amp;gt; int p[8]={4,2,4,2,4,6,2,6}; int prime(int n) { int i=7,j,q; if(n==1)return 0; if(n==2||n==5||n==3)return 1; if(n%2==0||n%3==0||n%5==0)return 0; q=(int)sqrt(n); for(;i&amp;lt;=q;){ for(j=0;j&amp;lt;8;j++){ if(n%i==0)return 0; i+=p[j]; } if(n%i==0)return 0; } return 1; } void main() { int n; scanf(&amp;#34;%d&amp;#34;,&amp;amp;n); if(prime(n))puts(&amp;#34;Yes&amp;#34;); else puts(&amp;#34;No&amp;#34;); } 仔细研究发现，这里利用的是这样的原理：
判断是不是 1, 2, 3, 5 及其倍数 从 7 开始，不断考虑其是否是素数，那么，这个 p 是什么回事呢？ 首先把 p 的各个元素加起来，和为 30，然后就可以发现一个规律： 7 为质数，7+2=9 不是质数，7+4=11 为质数，11+2=13 为质数，13+2=15 为合数，15+2=17 为质数，17+2=19 为质数，19+2=21 为合数，21+2=23 为质数，23+2=25 为合数，25+2=27 为合数，27+2=29 为质数，29+1=31 为质数，31+2=33 为合数，33+2=35 为合数，35+2=37 为质数。 观察以上所有的合数，都含有 2 或者 3 或者 5 的因子，而 30 又是 2,3,5 的公倍数，也就是说，后面的素数模 30 的余数不可能是上面这些合数，而剩下的素数才可能是真正的素数，于是跳过了很多素数的判断。</description>
    </item>
    
    <item>
      <title>关于 scanf 和 scanf_s 的问题</title>
      <link>https://jia.je/programming/2017/10/17/on-scanf-and-scanf_s/</link>
      <pubDate>Tue, 17 Oct 2017 16:46:40 +0800</pubDate>
      
      <guid>https://jia.je/programming/2017/10/17/on-scanf-and-scanf_s/</guid>
      <description>最近作为程设基础的小教员，收到很多同学的求助，关于scanf和scanf_s的问题已经遇到了两次，特此写一篇博文来叙述一下这个问题。
一开始，有同学问我，
char a; scanf(&amp;#34;%c&amp;#34;,&amp;amp;a); 为什么会报错？我说，vs 默认强制要求使用 scanf_s 函数，于是我建议这位同学把这个错误信息关掉了。嗯。经过百度，这位同学的问题解决了。
后来，又有一位同学问我，
char a; scanf_s(&amp;#34;%c&amp;#34;,&amp;amp;a); 程序为什么会崩溃？我想了想，如果 scanf_s 和 scanf 是一样的行为，这段代码是没问题的。但 scanf_s 既然安全，必然是在字符串方面做了处理。这里的 char*勉强也算一个？网上一查，果然，应该写成scanf_s(&amp;quot;%c&amp;quot;,&amp;amp;a,1);，字符串则要写成scanf_s(&amp;quot;%s&amp;quot;,str,sizeof(str))，来保证缓冲区不会溢出。
但是，这样解决这个问题又面临着不同的选择：
学习scanf_s和scanf的不同，把所有scanf换成scanf_s并做相应的修改。 这样当然符合了语言进化的潮流，也会让 vs 闭嘴。但是，scanf_s 只有在 C11 标准中有，而且，根据cpprefrence.com 上关于 scanf 的描述，只有在__STDC_LIB_EXT1__被定义且在#include&amp;lt;stdio.h&amp;gt;之前#define __STDC_WANT_LIB_EXT1__才能确保使用scanf_s能使用，当然在 vs 较新版本中是默认可以使用的。但是，程设基础的作业是要丢到 oj 上的，而 oj 上的编译器不一定支持这些，所以这个选项不行。 坚持用scanf，自己按照题目要求保证缓冲区不溢出，同时让 vs 闭嘴。 网上已有教程，已经讲的很全面了，大家可以根据这个教程把 vs 教训一顿。为了能在 oj 里跑，建议用里面的方法五到八。（个人最推荐在文件头添加#define _CRT_SECURE_NO_WARNINGS） 以后再遇到这个问题，我就丢这个连接上来就好了咯。yeah！</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2016/07/23/a-good-way-to-show-git-diff-for-compressed-files/</link>
      <pubDate>Sat, 23 Jul 2016 14:46:41 +0800</pubDate>
      
      <guid>https://jia.je/programming/2016/07/23/a-good-way-to-show-git-diff-for-compressed-files/</guid>
      <description>I have found a good way to track changes in .gz files: Add these to ~/.gitconfig:
[core] attributesFile = ~/.gitattributes [diff &amp;#34;zip&amp;#34;] textconv = unzip -p binary = true [diff &amp;#34;gz&amp;#34;] textconv = gzcat binary = true [diff &amp;#34;bz2&amp;#34;] textconv = bzcat binary = true [diff &amp;#34;xz&amp;#34;] textconv = xzcat binary = true [diff &amp;#34;tar&amp;#34;] textconv = tar -O -xf binary = true [diff &amp;#34;tar-bz2&amp;#34;] textconv = tar -O -xjf binary = true [diff &amp;#34;tar-gz&amp;#34;] textconv = tar -O -xzf binary = true [diff &amp;#34;tar-xz&amp;#34;] textconv = tar -O -xJf binary = true [diff &amp;#34;odf&amp;#34;] textconv = odt2txt [diff &amp;#34;pdf&amp;#34;] textconv = pdfinfo [diff &amp;#34;bin&amp;#34;] textconv = hexdump -v -C And these to ~/.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2016/05/22/exciting-new-software-updates/</link>
      <pubDate>Sun, 22 May 2016 07:47:16 +0800</pubDate>
      
      <guid>https://jia.je/programming/2016/05/22/exciting-new-software-updates/</guid>
      <description>Just got a piece of great news: GHC 8.0.1 is out! See the announcement [here][http://article.gmane.org/gmane.comp.lang.haskell.ghc.devel/11928].
So excited! And Emacs 25 release will be out soon. Using Emacs 25.0.94 now. Many new features available. See [this][http://puntoblogspot.blogspot.com/2016/05/emacs-251-news.html] for more information.
Recently I have finally started to use mu4e and gnus. What makes it truly great is that they integrate org, bbdb and so on.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2016/04/09/interesting-links/</link>
      <pubDate>Sat, 09 Apr 2016 06:17:34 +0800</pubDate>
      
      <guid>https://jia.je/programming/2016/04/09/interesting-links/</guid>
      <description>Having a bad cold. Really annoying.
Okay, here comes the interesting links:
https://glyph.twistedmatrix.com/2015/11/editor-malware.html
http://kitchingroup.cheme.cmu.edu/blog/2016/04/07/Writing-hy-code-from-hy-code/
https://github.com/holomorph/transmission
https://github.com/bergey/org-babel-diagrams
http://ess.r-project.org/
http://projects.haskell.org/diagrams/</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2016/04/03/tips-on-git-shallow-clone/</link>
      <pubDate>Sun, 03 Apr 2016 14:38:09 +0800</pubDate>
      
      <guid>https://jia.je/programming/2016/04/03/tips-on-git-shallow-clone/</guid>
      <description>Just learned a new tip on git shallow clone. As you know, some repository are really really large, such as emacs and linux. Cloning is slow and unstable. And there is no way to pause and resume a git clone. So I use shallow clone to clone them. But what if I want to clone other branches?
From here: http://stackoverflow.com/a/27393574/2148614
git remote set-branches origin &amp;#39;*&amp;#39; </description>
    </item>
    
    <item>
      <title></title>
      <link>https://jia.je/programming/2016/03/09/some-interesting-links/</link>
      <pubDate>Wed, 09 Mar 2016 22:10:31 +0800</pubDate>
      
      <guid>https://jia.je/programming/2016/03/09/some-interesting-links/</guid>
      <description>I&amp;rsquo;m here to share some interesting links. I do not have much time writing the blog now.
Recently I have been working on CodeFalling/MacGesture on Github. If you are interested in it, go and have a look.
Here are the links to share: https://twitter.com/PoolpOrg/status/694593152670437376 https://github.com/wellle/targets.vim http://thecodelesscode.com/case/225 https://twitter.com/zhangyuze320602/status/706457155763712000
I have done reading the biography of Steve Jobs. Great book.</description>
    </item>
    
  </channel>
</rss>
