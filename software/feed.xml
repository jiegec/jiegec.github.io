<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Softwares on 杰哥的{运维,编程,调板子}小笔记</title>
    <link>https://jia.je/software/</link>
    <description>Recent content in Softwares on 杰哥的{运维,编程,调板子}小笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Aug 2022 20:50:00 +0800</lastBuildDate><atom:link href="https://jia.je/software/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>从 TeX 到 PDF 的过程</title>
      <link>https://jia.je/software/2022/08/05/from-tex-to-pdf/</link>
      <pubDate>Fri, 05 Aug 2022 20:50:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/08/05/from-tex-to-pdf/</guid>
      <description>背景 今天跑 xdvipdfmx 的时候出现了报错，忽然想研究一下，DVI 格式是什么，TeX 是如何一步步变成 PDF 的。
流程 实际上从 TeX 到 PDF 有不同的工具，其中可能经历了不同的转化过程。
我们今天来看一种比较原始的转换方式：从 TeX 到 DVI，从 DVI 到 PS，再 PS 到 PDF，主要目的是看看这些格式内部都是什么样子的。
从 TeX 到 DVI 举一个很小的例子，例如 test.tex 有如下的内容：
Hello, world! \bye 在命令行中运行 tex test.tex，可以看到它生成了 test.dvi 文件：
$ tex test.tex (test.tex [1] ) Output written on test.dvi (1 page, 228 bytes). Transcript written on test.log. 那么 DVI 就是 TeX 引擎输出的默认格式了。我们可以用 dviinfox 和 dviasm 工具来看它的一些信息：
$ dviinfox test.dvi test.dvi: DVI format 2; 1 page Magnification: 1000/1000 Size unit: 1000x25400000/(1000x473628672)dum = 0.</description>
    </item>
    
    <item>
      <title>用 Nix 编译 Rust 项目</title>
      <link>https://jia.je/software/2022/08/02/rust-nix/</link>
      <pubDate>Tue, 02 Aug 2022 14:28:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/08/02/rust-nix/</guid>
      <description>背景 Rust 项目一般是用 Cargo 管理，但是它的缺点是每个项目都要重新编译一次所有依赖，硬盘空间占用较大，不能跨项目共享编译缓存。调研了一下，有若干基于 Nix 的 Rust 构建工具：
cargo2nix: https://github.com/cargo2nix/cargo2nix carnix: 不再更新 crane: https://github.com/ipetkov/crane crate2nix: https://github.com/kolloch/crate2nix naersk: https://github.com/nix-community/naersk nocargo: https://github.com/oxalica/nocargo 下面我分别来尝试一下这几个工具的使用。
下面出现的一些命令参考了对应项目的文档。
cargo2nix 卖点 cargo2nix 的 README 提到了它的卖点：
Development Shell - knowing all the dependencies means easy creation of complete shells. Run nix develop or direnv allow in this repo and see! Caching - CI &amp;amp; CD pipelines move faster when purity guarantees allow skipping more work! Reproducibility - Pure builds.</description>
    </item>
    
    <item>
      <title>invalid date 报错与时区的关系</title>
      <link>https://jia.je/software/2022/07/26/invalid-date-timezone/</link>
      <pubDate>Tue, 26 Jul 2022 21:51:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/26/invalid-date-timezone/</guid>
      <description>背景 最近在验题的时候，@HarryChen 发现了一个现象：
$ date -d &amp;#34;1919-04-13&amp;#34; date: invalid date ‘1919-04-13’ $ TZ=UTC date -d &amp;#34;1919-04-13&amp;#34; Sun Apr 13 00:00:00 UTC 1919 也就是说，这个现象与时区有关，那么为啥 1919-04-13 是一个不合法的日期呢？
时区 实际上，对于某一个时区来说，有的时间是不存在的，最常见的就是夏令时。在 Timezone DB 里可以看到，恰好在 1919 年 4 月 13 日发生了一次 UTC+8 到 UTC+9 的变化，因此零点变成了一点，就变成了不合法的日期。
这个数据，实际上保存在 tzdata 中，可以用 zdump 工具查看：
$ tzdata -v Asia/Shanghai Asia/Shanghai Fri Dec 13 20:45:52 1901 UTC = Sat Dec 14 04:45:52 1901 CST isdst=0 Asia/Shanghai Sat Dec 14 20:45:52 1901 UTC = Sun Dec 15 04:45:52 1901 CST isdst=0 Asia/Shanghai Sat Apr 12 15:59:59 1919 UTC = Sat Apr 12 23:59:59 1919 CST isdst=0 Asia/Shanghai Sat Apr 12 16:00:00 1919 UTC = Sun Apr 13 01:00:00 1919 CDT isdst=1 Asia/Shanghai Tue Sep 30 14:59:59 1919 UTC = Tue Sep 30 23:59:59 1919 CDT isdst=1 Asia/Shanghai Tue Sep 30 15:00:00 1919 UTC = Tue Sep 30 23:00:00 1919 CST isdst=0 Asia/Shanghai Fri May 31 15:59:59 1940 UTC = Fri May 31 23:59:59 1940 CST isdst=0 Asia/Shanghai Fri May 31 16:00:00 1940 UTC = Sat Jun 1 01:00:00 1940 CDT isdst=1 Asia/Shanghai Sat Oct 12 14:59:59 1940 UTC = Sat Oct 12 23:59:59 1940 CDT isdst=1 Asia/Shanghai Sat Oct 12 15:00:00 1940 UTC = Sat Oct 12 23:00:00 1940 CST isdst=0 Asia/Shanghai Fri Mar 14 15:59:59 1941 UTC = Fri Mar 14 23:59:59 1941 CST isdst=0 Asia/Shanghai Fri Mar 14 16:00:00 1941 UTC = Sat Mar 15 01:00:00 1941 CDT isdst=1 Asia/Shanghai Sat Nov 1 14:59:59 1941 UTC = Sat Nov 1 23:59:59 1941 CDT isdst=1 Asia/Shanghai Sat Nov 1 15:00:00 1941 UTC = Sat Nov 1 23:00:00 1941 CST isdst=0 Asia/Shanghai Fri Jan 30 15:59:59 1942 UTC = Fri Jan 30 23:59:59 1942 CST isdst=0 Asia/Shanghai Fri Jan 30 16:00:00 1942 UTC = Sat Jan 31 01:00:00 1942 CDT isdst=1 Asia/Shanghai Sat Sep 1 14:59:59 1945 UTC = Sat Sep 1 23:59:59 1945 CDT isdst=1 Asia/Shanghai Sat Sep 1 15:00:00 1945 UTC = Sat Sep 1 23:00:00 1945 CST isdst=0 Asia/Shanghai Tue May 14 15:59:59 1946 UTC = Tue May 14 23:59:59 1946 CST isdst=0 Asia/Shanghai Tue May 14 16:00:00 1946 UTC = Wed May 15 01:00:00 1946 CDT isdst=1 Asia/Shanghai Mon Sep 30 14:59:59 1946 UTC = Mon Sep 30 23:59:59 1946 CDT isdst=1 Asia/Shanghai Mon Sep 30 15:00:00 1946 UTC = Mon Sep 30 23:00:00 1946 CST isdst=0 Asia/Shanghai Mon Apr 14 15:59:59 1947 UTC = Mon Apr 14 23:59:59 1947 CST isdst=0 Asia/Shanghai Mon Apr 14 16:00:00 1947 UTC = Tue Apr 15 01:00:00 1947 CDT isdst=1 Asia/Shanghai Fri Oct 31 14:59:59 1947 UTC = Fri Oct 31 23:59:59 1947 CDT isdst=1 Asia/Shanghai Fri Oct 31 15:00:00 1947 UTC = Fri Oct 31 23:00:00 1947 CST isdst=0 Asia/Shanghai Fri Apr 30 15:59:59 1948 UTC = Fri Apr 30 23:59:59 1948 CST isdst=0 Asia/Shanghai Fri Apr 30 16:00:00 1948 UTC = Sat May 1 01:00:00 1948 CDT isdst=1 Asia/Shanghai Thu Sep 30 14:59:59 1948 UTC = Thu Sep 30 23:59:59 1948 CDT isdst=1 Asia/Shanghai Thu Sep 30 15:00:00 1948 UTC = Thu Sep 30 23:00:00 1948 CST isdst=0 Asia/Shanghai Sat Apr 30 15:59:59 1949 UTC = Sat Apr 30 23:59:59 1949 CST isdst=0 Asia/Shanghai Sat Apr 30 16:00:00 1949 UTC = Sun May 1 01:00:00 1949 CDT isdst=1 Asia/Shanghai Fri May 27 14:59:59 1949 UTC = Fri May 27 23:59:59 1949 CDT isdst=1 Asia/Shanghai Fri May 27 15:00:00 1949 UTC = Fri May 27 23:00:00 1949 CST isdst=0 Asia/Shanghai Sat May 3 17:59:59 1986 UTC = Sun May 4 01:59:59 1986 CST isdst=0 Asia/Shanghai Sat May 3 18:00:00 1986 UTC = Sun May 4 03:00:00 1986 CDT isdst=1 Asia/Shanghai Sat Sep 13 16:59:59 1986 UTC = Sun Sep 14 01:59:59 1986 CDT isdst=1 Asia/Shanghai Sat Sep 13 17:00:00 1986 UTC = Sun Sep 14 01:00:00 1986 CST isdst=0 Asia/Shanghai Sat Apr 11 17:59:59 1987 UTC = Sun Apr 12 01:59:59 1987 CST isdst=0 Asia/Shanghai Sat Apr 11 18:00:00 1987 UTC = Sun Apr 12 03:00:00 1987 CDT isdst=1 Asia/Shanghai Sat Sep 12 16:59:59 1987 UTC = Sun Sep 13 01:59:59 1987 CDT isdst=1 Asia/Shanghai Sat Sep 12 17:00:00 1987 UTC = Sun Sep 13 01:00:00 1987 CST isdst=0 Asia/Shanghai Sat Apr 16 17:59:59 1988 UTC = Sun Apr 17 01:59:59 1988 CST isdst=0 Asia/Shanghai Sat Apr 16 18:00:00 1988 UTC = Sun Apr 17 03:00:00 1988 CDT isdst=1 Asia/Shanghai Sat Sep 10 16:59:59 1988 UTC = Sun Sep 11 01:59:59 1988 CDT isdst=1 Asia/Shanghai Sat Sep 10 17:00:00 1988 UTC = Sun Sep 11 01:00:00 1988 CST isdst=0 Asia/Shanghai Sat Apr 15 17:59:59 1989 UTC = Sun Apr 16 01:59:59 1989 CST isdst=0 Asia/Shanghai Sat Apr 15 18:00:00 1989 UTC = Sun Apr 16 03:00:00 1989 CDT isdst=1 Asia/Shanghai Sat Sep 16 16:59:59 1989 UTC = Sun Sep 17 01:59:59 1989 CDT isdst=1 Asia/Shanghai Sat Sep 16 17:00:00 1989 UTC = Sun Sep 17 01:00:00 1989 CST isdst=0 Asia/Shanghai Sat Apr 14 17:59:59 1990 UTC = Sun Apr 15 01:59:59 1990 CST isdst=0 Asia/Shanghai Sat Apr 14 18:00:00 1990 UTC = Sun Apr 15 03:00:00 1990 CDT isdst=1 Asia/Shanghai Sat Sep 15 16:59:59 1990 UTC = Sun Sep 16 01:59:59 1990 CDT isdst=1 Asia/Shanghai Sat Sep 15 17:00:00 1990 UTC = Sun Sep 16 01:00:00 1990 CST isdst=0 Asia/Shanghai Sat Apr 13 17:59:59 1991 UTC = Sun Apr 14 01:59:59 1991 CST isdst=0 Asia/Shanghai Sat Apr 13 18:00:00 1991 UTC = Sun Apr 14 03:00:00 1991 CDT isdst=1 Asia/Shanghai Sat Sep 14 16:59:59 1991 UTC = Sun Sep 15 01:59:59 1991 CDT isdst=1 Asia/Shanghai Sat Sep 14 17:00:00 1991 UTC = Sun Sep 15 01:00:00 1991 CST isdst=0 Asia/Shanghai Mon Jan 18 03:14:07 2038 UTC = Mon Jan 18 11:14:07 2038 CST isdst=0 Asia/Shanghai Tue Jan 19 03:14:07 2038 UTC = Tue Jan 19 11:14:07 2038 CST isdst=0 可以看到，它列出来了历史上 Asia/Shanghai 时区的变化历史。具体的历史，可以查看 中国时区。</description>
    </item>
    
    <item>
      <title>Archive 中 COMMON 符号的链接问题</title>
      <link>https://jia.je/software/2022/07/11/archive-common-linking/</link>
      <pubDate>Mon, 11 Jul 2022 22:53:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/11/archive-common-linking/</guid>
      <description>背景 最近看到一个 issue: irssi 1.4.1 fails to build on darwin arm64，它的现象是，链接的时候会报错：
Undefined symbols for architecture arm64: &amp;#34;_current_theme&amp;#34;, referenced from: _format_get_text_theme in libfe_common_core.a(formats.c.o) _format_get_text in libfe_common_core.a(formats.c.o) _strip_codes in libfe_common_core.a(formats.c.o) _format_send_as_gui_flags in libfe_common_core.a(formats.c.o) _window_print_daychange in libfe_common_core.a(fe-windows.c.o) _printformat_module_dest_charargs in libfe_common_core.a(printtext.c.o) _printformat_module_gui_args in libfe_common_core.a(printtext.c.o) ... &amp;#34;_default_formats&amp;#34;, referenced from: _format_find_tag in libfe_common_core.a(formats.c.o) _format_get_text_theme_args in libfe_common_core.a(formats.c.o) _printformat_module_dest_args in libfe_common_core.a(printtext.c.o) _printformat_module_gui_args in libfe_common_core.a(printtext.c.o) ld: symbol(s) not found for architecture arm64 代码 themes.c 定义了这两个全局变量：
THEME_REC *current_theme; GHashTable *default_formats; 并且 themes.</description>
    </item>
    
    <item>
      <title>NVIDIA 驱动和 CUDA 安装速查</title>
      <link>https://jia.je/software/2022/07/06/install-nvidia-cuda/</link>
      <pubDate>Wed, 06 Jul 2022 11:42:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/06/install-nvidia-cuda/</guid>
      <description>背景 最近在 Ubuntu 上配置 NVIDIA 驱动和 CUDA 环境的次数比较多，在此总结一下整个流程，作为教程供大家学习。
配置 NVIDIA APT 源 Ubuntu 源有自带的 NVIDIA 驱动版本，但这里我们要使用 NVIDIA 的 APT 源。首先，我们要访问 https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=Ubuntu&amp;amp;target_version=20.04&amp;amp;target_type=deb_network，在网页中选择我们的系统，例如：
Operating System: Linux Architecture: x86_64 Distribution: Ubuntu Version: 20.04 Installer Type: deb (network) 此时，下面就会显示一些命令，复制下来执行：
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub sudo add-apt-repository &amp;#34;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /&amp;#34; sudo apt-get update 最后一步的 sudo apt-get -y install cuda 可以不着急安装，我们在后面再来讨论 CUDA 版本的问题。
NVIDIA 驱动 配置好源以后，接下来，我们就要安装 NVIDIA 驱动了。首先，我们要选取一个 NVIDIA 版本，选择的标准如下：</description>
    </item>
    
    <item>
      <title>切换 ConnectX-4 为以太网模式</title>
      <link>https://jia.je/software/2022/07/02/connectx-4-switch-to-ethernet/</link>
      <pubDate>Sat, 02 Jul 2022 20:26:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/02/connectx-4-switch-to-ethernet/</guid>
      <description>背景 最近在给机房配置网络，遇到一个需求，就是想要把 ConnectX-4 当成以太网卡用，它既支持 Infiniband，又支持 Ethernet，只不过默认是 Infiniband 模式，所以需要用 mlxconfig 工具来做这个切换。
切换方法 在 Using mlxconfig 文档中，写了如何切换网卡为 Infiniband 模式：
$ mlxconfig -d /dev/mst/mt4103_pci_cr0 set LINK_TYPE_P1=1 LINK_TYPE_P2=1 Device #1: ---------- Device type: ConnectX3Pro PCI device: /dev/mst/mt4103_pci_cr0 Configurations: Next Boot New LINK_TYPE_P1 ETH(2) IB(1) LINK_TYPE_P2 ETH(2) IB(1) Apply new Configuration? ? (y/n) [n] : y Applying... Done! -I- Please reboot machine to load new configurations. 那么，我们只需要反其道而行之，设置模式为 ETH(2) 即可。
MST 安装 要使用 mlxconfig，就需要安装 MFT(Mellanox Firmware Tools)。我们用的是 Debian bookworm，于是要下载 DEB：</description>
    </item>
    
    <item>
      <title>rsyslog 收集远程日志</title>
      <link>https://jia.je/software/2022/07/01/rsyslog-remote/</link>
      <pubDate>Fri, 01 Jul 2022 20:14:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/07/01/rsyslog-remote/</guid>
      <description>背景 最近在运维的时候发现网络设备（如交换机）有一个远程发送日志的功能，即可以通过 syslog udp 协议发送日志到指定的服务器。为此，可以在服务器上运行 rsyslog 并收集日志。
rsyslog 配置 默认的 rsyslog 配置是收集系统本地的配置，因此我们需要编写一个 rsyslog 配置，用于收集远程的日志。
首先复制 /etc/rsyslog.conf 到 /etc/rsyslog-remote.conf，然后修改：
注释掉 imuxsock 和 imklog 相关的 module 加载 去掉 imudp 和 imtcp 相关的注释，这样就会监听在相应的端口上 修改 $WorkDirectory，例如 $WorkDirectory /var/spool/rsyslog-remote，防止与已有的 rsyslog 冲突 注释 $IncludeConfig，防止引入了不必要的配置 注释所有已有的 RULES 下面的配置 添加如下配置： $template FromIp,&amp;#34;/var/log/rsyslog-remote/%FROMHOST-IP%.log&amp;#34; *.* ?FromIp 这样，就会按照来源的 IP 地址进行分类，然后都写入到 /var/log/rsyslog-remote/x.x.x.x.log 文件里。
systemd service 最后，写一个 systemd service 让它自动启动：
[Unit] ConditionPathExists=/etc/rsyslog-remote.conf Description=Remote Syslog Service [Service] Type=simple PIDFile=/var/run/rsyslogd-remote.pid ExecStart=/usr/sbin/rsyslogd -n -f /etc/rsyslog-remote.conf -i /var/run/rsyslogd-remote.</description>
    </item>
    
    <item>
      <title>Nix Cookbook</title>
      <link>https://jia.je/software/2022/06/07/nix-cookbook/</link>
      <pubDate>Tue, 07 Jun 2022 22:29:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/06/07/nix-cookbook/</guid>
      <description>背景 最近在尝试 NixOS 和在 macOS 上跑 Nix，下面记录一些我在使用过程中遇到的一些小问题和解决思路。
NixOS 全局配置 NixOS 的全局配置路径：/etc/nixos/configuration.nix 和 /etc/nixos/hardware-configuration.nix
应用更新后的全局配置：
nixos-rebuild switch # or nixos-rebuild switch --upgrade 应用 Flakes 配置文件并显示变化：
#!/usr/bin/env python3 import os user = os.getenv(&amp;#34;USER&amp;#34;) home = f&amp;#34;/nix/var/nix/profiles/&amp;#34; old = home + os.readlink(f&amp;#34;{home}system&amp;#34;) os.system(&amp;#34;sudo nixos-rebuild switch --flake .&amp;#34;) new = home + os.readlink(f&amp;#34;{home}system&amp;#34;) os.system(f&amp;#34;nix store diff-closures {old} {new}&amp;#34;) 更新大版本 如果要更新 NixOS 21.11 到 22.05:
nix-channel --list nix-channel --add https://nixos.org/channels/nixos-22.05 nixos nixos-rebuild switch --upgrade 可以考虑改或者不改 /etc/nixos/configuration.</description>
    </item>
    
    <item>
      <title>在 libvirt 中运行 RISC-V 虚拟机</title>
      <link>https://jia.je/software/2022/05/31/qemu-rv64-in-libvirt/</link>
      <pubDate>Tue, 31 May 2022 09:22:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/05/31/qemu-rv64-in-libvirt/</guid>
      <description>背景 我在 libvirt 中跑了几个 KVM 加速的虚拟机，然后突发奇想，既然 libvirt 背后是 qemu，然后 qemu 是支持跨指令集的，那是否可以让 libvirt 来运行 RISC-V 架构的虚拟机？经过一番搜索，发现可以跑 ARM：How To: Running Fedora-ARM under QEMU，既然如此，我们也可以试试用 libvirt 来运行 RV64 虚拟机。
准备 rootfs 第一步是根据 Debian 的文档 Creating a riscv64 chroot 来创建 rootfs，然后再用 virt-make-fs 来打包。
首先是用 mmdebstrap 来生成一个 chroot：
$ sudo mkdir -p /tmp/riscv64-chroot $ sudo apt install mmdebstrap qemu-user-static binfmt-support debian-ports-archive-keyring $ sudo mmdebstrap --architectures=riscv64 --include=&amp;#34;debian-ports-archive-keyring&amp;#34; sid /tmp/riscv64-chroot &amp;#34;deb http://deb.debian.org/debian-ports sid main&amp;#34; &amp;#34;deb http://deb.debian.org/debian-ports unreleased main&amp;#34; 进入 chroot 以后，进行一些配置：</description>
    </item>
    
    <item>
      <title>LoongArch64 工具链构建</title>
      <link>https://jia.je/software/2022/05/02/loongarch64-toolchain/</link>
      <pubDate>Mon, 02 May 2022 20:35:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/05/02/loongarch64-toolchain/</guid>
      <description>最近因为龙芯杯的原因，想自己搞个 LoongArch64 的交叉编译工具链试试，结果遇到了很多坑，最后终于算是搞出来了。
一开始是想搞一个 newlib 的工具链，比较简单，而且之前做过一个仓库：jiegec/riscv-toolchain，就是构建的 riscv64-unknown-elf 工具链，照着 riscv-gnu-toolchain 就可以了。不过研究发现，newlib 还不支持 loongarch，目前只有 glibc 支持，只好硬着头皮上了。
于是我就在 riscv-toolchain 的基础上搞 loongarch64-unknown-linux-gnu，也就是带 glibc 的工具链，结果发现遇到很多坑。首先编译 libgcc 的时候就找不到头文件，于是先要从 glibc 和 linux 安装头文件到 sysroot 里面，对于 sysroot 里面的头文件路径到底是 include 还是 usr/include 也折腾了半天。然后编译 libgcc 又各种出问题，最后折腾了半天，结果是 gcc stage1 和 glibc 都没问题，gcc stage2 会报链接错误，但是不管它也能用，可以编译出正常的程序，毕竟 libc 是好的。
于是转念一想，要不要试试 crosstool-ng。克隆了一份上游的版本，照着 riscv 的部分抄了一份变成了 loongarch，然后把 config 里面的 linux/glibc/gcc/binutils-gdb 都替换为 custom location，这样我就可以用上游的最新版本了。中途还遇到了 crosstool-ng 对 gcc 12/13 不兼容的 bug，还好下面有人提出了解决方法。这些都搞定以后，终于构建出了一个完整的 loongarch64-unknown-linux-gnu 工具链。仓库地址是 jiegec/ct-ng-loongarch64，需要配合添加了 LoongArch 的 jiegec/crosstool-ng loongarch 分支 使用。</description>
    </item>
    
    <item>
      <title>RISC-V Vector 1.0 工具链构建</title>
      <link>https://jia.je/software/2022/01/25/rvv-1.0-toolchain/</link>
      <pubDate>Tue, 25 Jan 2022 21:41:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2022/01/25/rvv-1.0-toolchain/</guid>
      <description>不久前 RVV 1.0 标准终于是出来了，但是工具链的支持目前基本还处于刚 upstream 还没有 release 的状态。而目前 RVV 1.0 的支持主要在 LLVM 上比较活跃，因此也是采用 LLVM Clang + GCC Newlib Toolchain 的方式进行配合，前者做 RVV 1.0 的编译，后者提供 libc 等基础库。
UPDATE: LLVM 14 已经发布，这个版本已经支持 RVV 1.0，直接从 https://apt.llvm.org 等地安装 LLVM 14 即可。
LLVM Clang 直接采用 upstream 即可。编译选项：
$ cmake -G Ninja ../llvm -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_INSTALL_PREFIX=/prefix/llvm -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=&amp;#34;clang&amp;#34; -DLLVM_TARGETS_TO_BUILD=&amp;#34;RISCV&amp;#34; $ ninja $ ninja install $ /prefix/llvm/bin/clang --version clang version 14.0.0 (https://github.com/llvm/llvm-project.git 8d298355ca3778a47fd6b3110aeee03ea5e8e02b) Target: x86_64-unknown-linux-gnu Thread model: posix InstalledDir: /data/llvm/bin 还需要配合一个 GCC 工具链才可以完整地工作。可以直接采用 riscv-gnu-toolchain nightly 版本，比如 riscv64-elf-ubuntu-20.</description>
    </item>
    
    <item>
      <title>XRDP 和 NVIDIA 显卡兼容性问题</title>
      <link>https://jia.je/software/2021/12/29/xrdp-nvidia/</link>
      <pubDate>Wed, 29 Dec 2021 15:31:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/12/29/xrdp-nvidia/</guid>
      <description>背景 最近在尝试配置 XRDP，发现它在有 NVIDIA 的机器上启动远程桌面后会黑屏，查看错误信息可以看到：
xf86OpenConsole: Cannot open virtual console 1 (Permission denied) 解决方法 XRDP 作者在 issue #2010 中提到了解决方法：
修改 /etc/xrdp/sesman.ini，在 [Xorg] 部分里加上下面的配置：
param=-configdir param=/ 实际上就是不让 Xorg 加载 nvidia xorg 驱动，这样就绕过了问题。</description>
    </item>
    
    <item>
      <title>NVIDIA 驱动和 CUDA 版本信息速查</title>
      <link>https://jia.je/software/2021/12/26/nvidia-cuda/</link>
      <pubDate>Sun, 26 Dec 2021 16:03:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/12/26/nvidia-cuda/</guid>
      <description>背景 之前和 NVIDIA 驱动和 CUDA 搏斗比较多，因此记录一下一些常用信息，方便查询。
常用地址 CUDA Toolkit Downloads NVIDIA Driver Installation Quickstart Guide NVIDIA Driver Downloads NVIDIA Docker Installation Guide CUDA 版本与 NVIDIA 驱动兼容性 可以通过 apt show cuda-runtime-x-x 找到：
cuda 11.7 &amp;gt;= 515 cuda 11.6 &amp;gt;= 510 cuda 11.5 &amp;gt;= 495 cuda 11.4 &amp;gt;= 470 cuda 11.3 &amp;gt;= 465 cuda 11.2 &amp;gt;= 460 cuda 11.1 &amp;gt;= 455 cuda 11.0 &amp;gt;= 450 cuda 10.2 &amp;gt;= 440 cuda 10.1 &amp;gt;= 418 cuda 10.</description>
    </item>
    
    <item>
      <title>Locale 影响排序的特殊副作用</title>
      <link>https://jia.je/software/2021/09/02/locale/</link>
      <pubDate>Thu, 02 Sep 2021 12:35:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/09/02/locale/</guid>
      <description>背景 最近在答疑的时候，发现同一条命令在不同系统上行为不同，一开始以为是 bash 版本问题，排查后最后发现是 locale 的问题。一个例子如下：
$ cat poc.txt | tr &amp;#39;\\n&amp;#39; &amp;#39; &amp;#39; 1 + - * / \ a b A B 一 二 测 试 α $ LANG=&amp;#34;&amp;#34; sort poc.txt | tr &amp;#39;\\n&amp;#39; &amp;#39; &amp;#39; * + - / 1 A B \ a b α 一 二 测 试 $ LANG=&amp;#34;zh_CN.UTF-8&amp;#34; sort poc.txt | tr &amp;#39;\\n&amp;#39; &amp;#39; &amp;#39; * + - / \ 1 测 二 试 一 a A b B α $ LANG=&amp;#34;en_US.</description>
    </item>
    
    <item>
      <title>配置 homebridge-broadlink-rm-pro</title>
      <link>https://jia.je/software/2021/07/24/homebridge-rm-mini-3/</link>
      <pubDate>Sat, 24 Jul 2021 20:42:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/07/24/homebridge-rm-mini-3/</guid>
      <description>背景 最近发现空调遥控器电池有点不足，有时候会自动关机，于是拿出以前买的 Broadlink RM mini 3 充当远程的空调遥控器使用。为了方便手机上配置，分别采用了官方的 App 智慧星和 homebridge 进行配置。
步骤 首先用官方的智慧星配置好 Broadlink RM mini 3 的网络，然后配置 homebridge-broadlink-rm-pro。最早的插件作者不怎么更新了，这个版本是目前用的比较多的一个 fork。
安装好以后，在 Home 里面可以看到 Scan Code 的开关。打开以后，用遥控器在 Broadlink RM mini 3 附近按按键，就可以在 Homebridge 日志里看到 hex code 了。然后，就按照插件教程里的方法写配置，例子如下：
{ &amp;#34;platform&amp;#34;: &amp;#34;BroadlinkRM&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Broadlink RM&amp;#34;, &amp;#34;accessories&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Air Conditioner&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;air-conditioner&amp;#34;, &amp;#34;noHumidity&amp;#34;: true, &amp;#34;minTemperature&amp;#34;: 26, &amp;#34;maxTemperature&amp;#34;: 28, &amp;#34;defaultCoolTemperature&amp;#34;: 27, &amp;#34;data&amp;#34;: { &amp;#34;off&amp;#34;: &amp;#34;2600...&amp;#34;, &amp;#34;cool28&amp;#34;: { &amp;#34;data&amp;#34;: &amp;#34;2600...&amp;#34; }, &amp;#34;cool27&amp;#34;: { &amp;#34;data&amp;#34;: &amp;#34;2600.</description>
    </item>
    
    <item>
      <title>Nginx 处理 POST 请求出现 Internal Server Error 排查一则</title>
      <link>https://jia.je/software/2021/07/16/nginx-post-internal-server-error/</link>
      <pubDate>Fri, 16 Jul 2021 00:16:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/07/16/nginx-post-internal-server-error/</guid>
      <description>前言 最近一个服务忽然出现问题，用户反馈，HTTP POST 一个小的 body 不会出错，POST 一个大的 body 就会 500 Internal Server Error。
排查 观察后端日志，发现没有出错的那一个请求。观察 Nginx 日志，发现最后一次日志是几个小时前。最后几条 Nginx 日志写的是 a client request body is buffered to a temporary file。
结论 继续研究后，发现是硬盘满了。Nginx 在处理 POST body 的时候，如果 body 超过阈值，会写入到临时文件中：
Syntax: client_body_buffer_size size; Default: client_body_buffer_size 8k|16k; Context: http, server, location Sets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file.</description>
    </item>
    
    <item>
      <title>Gnome 的 Fractional Scaling</title>
      <link>https://jia.je/software/2021/03/13/gnome-fractional-scaling/</link>
      <pubDate>Sat, 13 Mar 2021 23:11:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/03/13/gnome-fractional-scaling/</guid>
      <description>背景 最近发现部分软件（包括Google Chrome，Firefox 和 Visual Studio Code） 在 125% 的 Fractional Scaling 模式下会很卡。找到了一些临时解决方法，但是很不优雅，也很麻烦。所以深入研究了一下 Fractional Scaling 的工作方式。
临时解决方法 根据关键字，找到了 Chrome menus too slow after enabling fractional scaling in Ubuntu 20.04。按它的方法，关闭 Google Chrome 的硬件加速，发现卡顿问题确实解决了。
类似地，也可以[关闭 VSCode 的硬件加速](Chrome menus too slow after enabling fractional scaling in Ubuntu 20.04)，在 Firefox 里也可以找到相应的设置。这样操作确实可以解决问题。但是，对于每一个出问题的应用都这样搞一遍，还是挺麻烦的。
另一个思路是，不使用 Fractional Scaling，而只是把字体变大。但毕竟和我们想要的效果不大一样。
一些发现 在物理机进行了一些实验以后，发现一个现象：125% 的时候卡顿，而其他比例（100%，150%，175%，200%）都不卡顿。
网上一顿搜到，找到了 xrandr 工具。下面是观察到的一些现象（GNOME 设置分辨率一直是 1920x1080）：
放缩比例 xrandr 显示的分辨率 xrandr 显示的 transform 100% 1920x1080 diag(1.0, 1.0, 1.0) 125% 3072x1728 diag(1.</description>
    </item>
    
    <item>
      <title>使用 SSSD 的 LDAP 认证</title>
      <link>https://jia.je/software/2021/02/15/sssd-ldap/</link>
      <pubDate>Mon, 15 Feb 2021 10:44:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/02/15/sssd-ldap/</guid>
      <description>前言 最近在研究替换一个老的用户系统，于是顺便学习了一下 LDAP，还有 SSSD。LDAP 是一个目录协议，顺带的，因为用户信息也可以存在里面，所以也就成了一个常见的用户认证协议。SSSD 就是一个 daemon，把系统的 NSS PAM 的机制和 LDAP 连接起来。
配置 其实很简单，安装 sssd 并且配置即可：
$ sudo apt install sssd $ sudo vim /etc/sssd/sssd.conf # file content: [sssd] config_file_version = 2 services = nss,pam domains = LDAP [domain/LDAP] cache_credentials = true enumerate = true entry_cache_timeout = 10 ldap_network_timeout = 2 id_provider = ldap auth_provider = ldap chpass_provider = ldap ldap_uri = ldap://127.0.0.1/ ldap_chpass_uri = ldap://127.0.0.1/ ldap_search_base = dc=example,dc=com ldap_default_bind_dn = cn=localhost,ou=machines,dc=example,dc=com ldap_default_authtok = REDACTED $ sudo systemctl enable --now sssd 一些字段需要按照实际情况编写，请参考sssd.</description>
    </item>
    
    <item>
      <title>在 Big Sur(M1) 上解决 LaTeX 找不到楷体字体的问题</title>
      <link>https://jia.je/software/2021/02/09/big-sur-m1-latex-kaiti-fonts/</link>
      <pubDate>Tue, 09 Feb 2021 20:08:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/02/09/big-sur-m1-latex-kaiti-fonts/</guid>
      <description>背景 最近在尝试移植 MiKTeX 到 Apple Silicon 上，添加了一些 patch 以后就可以工作了，但遇到了新的问题，即找不到 KaiTi
~/Library/Application Support/MiKTeX/texmfs/install/tex/latex/ctex/fontset/ctex-fontset-macnew.def:99: Package fontspec Error: The font &amp;#34;Kaiti SC&amp;#34; cannot be found. 用 miktex-fc-list 命令找了一下，确实没有找到：
$ /Applications/MiKTeX\ Console.app/Contents/bin/miktex-fc-list | grep Kaiti # Nothing 上网搜了一下，找到了一个解决方案：字体在目录 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Support/FontSubsets/Kaiti.ttc 里，所以手动安装一下，就可以让 LaTeX 找到了。但我觉得，与其安装多一份在文件系统里，不如让 LaTeX 去找它。
解决方法 按照上面的线索，找到了 Kaiti.ttc 所在的路径：
$ fd Kaiti.ttc /System/Library/PrivateFrameworks/FontServices.framework/Versions/A/Resources/Fonts/Subsets/Kaiti.ttc 可以看到，和上面的路径又不大一样。研究了一下 fontconfig，发现可以用 miktex-fc-conflist 找到配置文件的目录：
$ /Applications/MiKTeX\ Console.app/Contents/bin/miktex-fc-conflist + ~/Library/Application Support/MiKTeX/texmfs/config/fontconfig/config/localfonts2.conf: No description + ~/Library/Application Support/MiKTeX/texmfs/config/fontconfig/config/localfonts.conf: No description ... 看了下第一个文件（localfonts.conf）：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;!</description>
    </item>
    
    <item>
      <title>COMMON 符号</title>
      <link>https://jia.je/software/2021/02/09/common-symbols-linking/</link>
      <pubDate>Tue, 09 Feb 2021 19:02:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/02/09/common-symbols-linking/</guid>
      <description>背景 在编译一个程序的时候，遇到了 undefined symbol 的问题。具体情况是这样的：
一开始的时候，直接把所有的源代码编译成 .o，再一次性链接，这样不会报错 后来，把一些代码编译成静态库，即把其中一部分源代码编译成 .o 后，用 ar 合并到一个 .a 中，再和其余的 .o 链接在一起，这时候就报错了： Undefined symbols for architecture arm64: &amp;#34;_abcd&amp;#34;, referenced from: ... 如果换台机器，编译（使用的是 gcc 10.2.0）就没有问题。
而如果去找这个符号存在的 .o 里，是可以找到的：
$ objdump -t /path/to/abcd.o 0000000000000028 *COM* 00000008 _abcd 在合成的静态库 .a 里，也是存在的（一个定义+若干个引用）：
$ objdump -t /path/to/libabc.a | grep abcd 0000000000000028 *COM* 00000008 _abcd 0000000000000000 *UND* _abcd 0000000000000000 *UND* _abcd 0000000000000000 *UND* _abcd 0000000000000000 *UND* _abcd 0000000000000000 *UND* _abcd 于是觉得很奇怪，就上网搜了一下，找到了一篇 StackOverflow 讲了这个问题。解决方案很简单，就是：</description>
    </item>
    
    <item>
      <title>在 M1 上用 QEMU 运行 Debian 虚拟机</title>
      <link>https://jia.je/software/2021/01/02/aarch64-debian-in-qemu-m1/</link>
      <pubDate>Sat, 02 Jan 2021 13:05:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2021/01/02/aarch64-debian-in-qemu-m1/</guid>
      <description>背景 看到 @jsteward 在 M1 的 QEMU 中运行了 Windows on ARM，所以我先来试试 Debian on AArch64，这样会简单一些。
参考：https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278#file-readme-md
大约需要 3G 的硬盘空间。
安装 QEMU w/ M1 patches 目前上游的 QEMU 还不支持 M1 的 Hypervisor framework，需要打 patch：
git clone https://mirrors.tuna.tsinghua.edu.cn/git/qemu.git cd qemu git checkout master -b wip/hvf curl &amp;#39;https://patchwork.kernel.org/series/400619/mbox/&amp;#39;|git am --3way mkdir build cd build ../configure --target-list=aarch64-softmmu --enable-cocoa --disable-gnutls make -j4 编译后，得到 qemu-system-aarch64 的二进制
准备好文件系统 需要下载 EFI 固件 和 Debian 安装镜像，解压前者以后把文件放同一个目录中，并且创建需要的文件：
$ ls *.fd QEMU_EFI.fd QEMU_VARS.fd $ dd if=/dev/zero of=pflash0.</description>
    </item>
    
    <item>
      <title>在 Spack 中用 external 的 Slurm 依赖编译 OpenMPI</title>
      <link>https://jia.je/software/2020/11/08/spack-openmpi-slurm-external/</link>
      <pubDate>Sun, 08 Nov 2020 00:51:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2020/11/08/spack-openmpi-slurm-external/</guid>
      <description>最近在一个集群上，需要用一个自己编译的 openmpi，但并没有 root 权限，所以需要自己搞一个 spack，在 spack 里面装 openmpi。但默认的安装选项下，它没有打开 slurm 支持，所以 srun 的话会出问题，只能 sbatch 然后指定 host 去做。于是我研究了一下怎么在 spack 里引入 external 的 slurm，然后用它来编译 openmpi
首先，编译 ~/.spack/packages.yaml：
packages: slurm: buildable: False paths: &amp;#34;slurm@15-08-7-1%gcc@8.3.0 arch=linux-ubuntu16.04-haswell&amp;#34;: /usr 这里 slurm 版本是 15.08.7，我就按照 spack 里面 slurm 的版本号来写了。可以用 spack spec openmpi schedulers=slurm +pmi 来确认一下外部的 slurm 确实出现在了依赖之中。
这一步配好的话，安装的时候就会直接跳过 spack 里面 slurm 的安装。但又出现了 configure 错误，找不到 pmi 的库。于是，先用 external 的 mpirun 看一下配置：
$ module load openmpi-3.0.0 $ ompi_info ... --with-pmi=/usr --with-pmi-libdir=/usr/lib/x86_64-linux-gnu .</description>
    </item>
    
    <item>
      <title>USB/IP 模拟 USB 设备</title>
      <link>https://jia.je/software/2020/05/15/usb-ip-simulation/</link>
      <pubDate>Fri, 15 May 2020 20:20:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2020/05/15/usb-ip-simulation/</guid>
      <description>背景 2018 年的时候发过一篇博客，讲如何用 USB/IP 协议在两台 Linux 电脑之间共享 USB 设备。最近刚好有一个需求，就是针对一个现成的 USB device 的代码，通过 USB/IP 模拟出一个 USB 设备，然后进行调试。
USB/IP 协议 USB/IP 只有一个简略的文档，为数不多的使用 USB/IP 的代码，所以有一些细节没有说的很清楚，只能一点点去尝试。
首先，USB/IP 基于 TCP，端口号 3240 。客户端向服务端发送请求，服务端向客户端进行回应。
请求的类型：OP_REQ_DEVLIST OP_REQ_IMPORT USBIP_CMD_SUBMIT 和 USBIP_CMD_UNLINK
回应的类型：OP_REP_DEVLIST OP_REP_IMPORT USBIP_RET_SUBMIT USBIP_RET_UNLINK
工作的过程大概如下：
OP_REQ_DEVLIST 请求获取设备列表 OP_REP_DEVLIST 返回设备列表 OP_REQ_IMPORT 请求 USB 设备 OP_REP_IMPORT 返回 USB 设备 USBIP_CMD_SUBMIT 发送 URB USBIP_RET_SUBMIT 返回 URB （先不考虑 CMD_UNLINK 和 RET_UNLINK）
其中前面四个比较简单清晰，所需要的字段也都是 Descriptor 中对应的字段。后面两个就相对复杂一些：URB data 的长度需要根据 endpoint 类型和 direction 共同决定。URB 实际上是 Linux 内核里的一个数据结构。</description>
    </item>
    
    <item>
      <title>在 sbt 中 fork 并且并行运行测试</title>
      <link>https://jia.je/software/2020/04/13/sbt-fork-parallel-test/</link>
      <pubDate>Mon, 13 Apr 2020 21:00:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2020/04/13/sbt-fork-parallel-test/</guid>
      <description>问题 最近在 sbt 使用遇到一个问题，有两个测试，分别用 testOnly 测试的时候没有问题，如果同时测试就会出问题，应该是全局的状态上出现了冲突。一个自然的解决思路是 fork，但是 sbt 默认 fork 之后 test 是顺序执行的，这会很慢。所以搜索了一下，找到了 fork 并且并行测试的方法。
解决方法 解决方法在 sbt 文档中其实就有（原文）。简单来说就是：把每个 test 放到单独的 TestGroup 中，每个 TestGroup 分别用一个 forked JVM 去运行；然后让 sbt 的并行限制设高一些：
// move each test into a group and fork them to avoid race condition import Tests._ def singleTests(tests: Seq[TestDefinition]) = tests map { test =&amp;gt; new Group( name = test.name, tests = Seq(test), SubProcess(ForkOptions())) } Test / testGrouping := singleTests( (Test / definedTests).</description>
    </item>
    
    <item>
      <title>在 macOS 上带执行权限 mmap 一个已删除文件遇到的问题和解决方案</title>
      <link>https://jia.je/software/2020/02/07/macos-mmap-exec/</link>
      <pubDate>Fri, 07 Feb 2020 18:11:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2020/02/07/macos-mmap-exec/</guid>
      <description>背景 实验环境：macOS Catalina 10.15.2
最近在 rcore-rs/zircon-rs 项目中遇到一个比较玄学的问题，首先需求是在 macOS 的用户进程里开辟一段地址空间，然后把这个地址空间多次映射（权限可能不同、同一块内存可能被映射到多个地址），通过 mmap 模拟虚拟地址的映射。采用的是如下的方案：
在临时目录创建一个文件，把文件大小设为 16M（暂不考虑扩容） 需要映射一个虚拟地址到物理地址的时候，就对这个文件的物理地址偏移进行 FIXED 映射，虚拟地址就是期望的虚拟地址。 这样的方案在 Linux 下运行地很好，但在 macOS下总是以一定概率在第二部出现 EPERM。网上搜了很多，但也没搜到相关的信息，于是自己断断续续地研究了一下，现在有一个比较初步的结果。
TL；DR 先说结论：调用一个带 PROT_EXEC 并且映射文件的 mmap 时，macOS 会进行安全检测，如果此时发现文件在文件系统上消失了，它会认为这可能是一个恶意软件行为，进行拦截，返回 EPERM。
而代码实际上在第一步和第二步之间，把临时目录删了：由于进程持有 fd，所以文件并不会真的删掉，当软件退出的时候文件自然会删除，这是临时文件的常见做法（见 tmpfile(3)）。
研究过程 查看 Console 在网上一番搜索未果后，就尝试在 Console 里面寻找信息。照着程序名字搜索，可以找到一些信息：
temporarySigning type=1 matchFlags=0x0 path=/path/to/executable 这是编译这个 executable 的时候出现的，好像也没啥问题。然后解除过滤，在这个信息前后按照 syspolicyd 寻找：
initiating malware scan (... info_path: /path/to/temp/file proc_path: /path/to/executable) Unable (errno: 2) to read file at &amp;lt;private&amp;gt; for process path: &amp;lt;private&amp;gt; library path: &amp;lt;private&amp;gt; Disallowing load of &amp;lt;private&amp;gt; in 50001, &amp;lt;private&amp;gt; Library load (/path/to/temp/file) rejected: library load denied by system policy 这几条记录比较可疑，每次运行程序，如果跑挂了，就会出现这几条，如果没跑挂，就不会出现这一条。所以很大概率是被 macOS 拦截了。错误信息的用词是 library ，所以大概率是被当成加载动态库了，但既然内容是空的，所以我想的是文件名触碰到了什么奇怪的规则，然后文件名又是随机的，随机导致 EPERM 是概率性出现的，这好像很有道理。于是我把 tmpfile 换成了固定的路径，忽然就好了。但固定的路径只能保证同时只有一个程序在跑，如果路径拼接上pid，怎么删，谁来删又是一个问题。虽然可以放到 /tmp 下面然后随便搞，但 /tmp 的回收并不是那么积极，在临时目录下丢太多文件也会出现问题。</description>
    </item>
    
    <item>
      <title>用 Nginx 作为 RTMP 服务器并提供直播服务</title>
      <link>https://jia.je/software/2019/09/28/use-nginx-as-rtmp-server/</link>
      <pubDate>Sat, 28 Sep 2019 10:15:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/09/28/use-nginx-as-rtmp-server/</guid>
      <description>Nginx 除了可以做 HTTP 服务器以外，还可以做 RTMP 服务器，同时转成 HLS 再提供给用户，这样可以实现一个直播的服务器，用 OBS 推上来即可。
首先要安装 nginx-rtmp-server 模块，很多的发行版都已经包含了，它的主页是 https://github.com/arut/nginx-rtmp-module ，下面很多内容也是来自于它的教程中。
接着，配置 Nginx ，在 nginx.conf 的顶层中添加如下的配置：
rtmp { server { listen 1935; chunk_size 4096; application live { live on; record off; hls on; hls_path /path/to/save/hls; hls_fragment 1s; hls_playlist_length 10s; } } } 这里表示 Nginx 要在 1935 监听一个 RTMP 服务器，然后把 live 下的视频切成片然后存在目录下，提供一个 m3u8 文件以供播放器使用。这里的参数都可以按照实际需求进行调整。这时候应该可以看到 nginx 正确监听1935 端口，这是 rtmp 的默认端口。
接着，需要在一个 HTTP server 路径下把 HLS serve 出去：
location /hls { # Serve HLS fragments types { application/vnd.</description>
    </item>
    
    <item>
      <title>在 macOS 上创建 ESP 镜像文件</title>
      <link>https://jia.je/software/2019/09/14/create-esp-partition-macos/</link>
      <pubDate>Sat, 14 Sep 2019 16:07:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/09/14/create-esp-partition-macos/</guid>
      <description>最近 rCore 添加了 UEFI 支持，在 QEMU 里跑自然是没有问题，然后尝试放到 VMWare 虚拟机里跑，这时候问题就来了：需要一个带有 ESP 盘的 vmdk 虚拟盘。搜索了一下网络，找到了解决方案：
hdiutil create -fs fat32 -ov -size 60m -volname ESP -format UDTO -srcfolder esp uefi.cdr 其中 60m esp 和 uefi.cdr 都可以按照实际情况修改。它会把 esp 目录下的文件放到 ESP 分区中，然后得到一个镜像文件：
uefi.cdr: DOS/MBR boot sector; partition 1 : ID=0xb, start-CHS (0x3ff,254,63), end-CHS (0x3ff,254,63), startsector 1, 122879 sectors, extended partition table (last) 接着转换为 vmdk ：
qemu-img convert -O vmdk uefi.cdr uefi.vmdk 这样就可以了。</description>
    </item>
    
    <item>
      <title>macOS 下读取并解析 EDID</title>
      <link>https://jia.je/software/2019/08/14/read-edid-decode-macos/</link>
      <pubDate>Wed, 14 Aug 2019 20:39:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/08/14/read-edid-decode-macos/</guid>
      <description>之前听说了 EDID 的存在，但是一直没有细究里面的格式和内容。今天了解了一下，发现其实非常简单，下面是方法：
首先获取所有显示器输出的 EDID ：
ioreg -lw0 | grep IODisplayEDID 输出里会出现 &amp;ldquo;IODisplayEDID&amp;rdquo; = &amp;lt;00ffxxxxxxxxxxxxx&amp;gt; 的内容，尖括号内的就是 EDID 的内容。接着，我们采用 edid-decode 进行解析：
git clone git://linuxtv.org/edid-decode.git cd edid-decode make ./edid-decode &amp;lt;Paste EDID here&amp;gt; 就可以看到很详细的 EDID 数据解析了。
ref: https://gist.github.com/OneSadCookie/641549 https://www.avsforum.com/forum/115-htpc-mac-chat/1466910-ability-dump-display-s-edid-mac.html</description>
    </item>
    
    <item>
      <title>在 Linux 下捕获 Framebuffer</title>
      <link>https://jia.je/software/2019/08/12/framebuffer-capture/</link>
      <pubDate>Mon, 12 Aug 2019 20:18:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/08/12/framebuffer-capture/</guid>
      <description>最近需要在 linux 下抓取 Framebuffer 的内容，在网上找到了两种方法，在我这里只有第二、第三种可以成功，没有细究具体原因，可能与我的 Framebuffer 配置有关。方法如下：
fbgrab ：命令就是 fbgrab image.png ，直接得到 png 文件，格式是对的，但是用软件打开就是一片空白。用 ImageMagick 转换为 jpg可以看到一些内容，但是和实际有些不一样。 fbdump ：命令就是 fbdump &amp;gt; image.ppm ，得到裸的 ppm 文件，图像是正确的，也可以转换为别的格式正常打开。 cat+脚本处理：直接 cat /dev/fb0 &amp;gt; image.rgb ，然后用下面的脚本转换为 png 。由于 Framebuffer 格式为 RGB ，本来 A 所在的 channel 都为 0 ，所以用一些软件直接打开都是空白，只好写了脚本直接跳过 Alpha Channel 。 Framebuffer 配置（ fbset 输出）：
mode &amp;#34;640x480-0&amp;#34; # D: 0.000 MHz, H: 0.000 kHz, V: 0.000 Hz geometry 640 480 1024 480 32 timings 0 0 0 0 0 0 0 accel false rgba 8/16,8/8,8/0,0/0 endmode 转换脚本（参考[Tips] 擷取framebuffer畫面）：</description>
    </item>
    
    <item>
      <title>在 Linux 中用 C 代码获取 DNS 服务器列表</title>
      <link>https://jia.je/software/2019/04/30/get-resolvers-in-c/</link>
      <pubDate>Tue, 30 Apr 2019 17:39:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/04/30/get-resolvers-in-c/</guid>
      <description>最近在做一个作业的时候，发现里面有个步骤是获取 Linux 系统中的 DNS 服务器列表，它的方法很粗暴，直接 cat grep cut 再处理。我就在想有没有完全代码的实现，然后搜了一下，果然有：
#include &amp;lt;resolv.h&amp;gt; // ... res_init(); // _res.nsaddr_list is an array of resolvers 用到了全局变量 _res ，虽然很 hacky ，但是至少是工作的，不清楚兼容性几何。</description>
    </item>
    
    <item>
      <title>rCore 软路由实现</title>
      <link>https://jia.je/software/2019/04/07/rcore-soft-router/</link>
      <pubDate>Sun, 07 Apr 2019 12:13:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/04/07/rcore-soft-router/</guid>
      <description>最近在研究软路由在 rCore 上的实现，但限于硬件限制，目前先在虚拟机里测试。软路由大概要做这些东西：
1. 抓包，解析包里的内容 2. 查路由表，找到下一跳在哪 3. 查ARP，知道下一跳的 MAC 地址 4. 减少TTL，更新 IP Checksum 5. 把包发出去 第一步直接拿 smoltcp 的 Raw Socket 即可，但是目前只能抓指定 IP Protocol 的包，我用的是 ICMP ，但其他的就还抓不了，需要继续改 Smoltcp 源代码。
第二步用的是之前刚修好的 treebitmap 库，它提供了路由表的查询功能，目前路由表还是写死的，之后会用已经部分实现好的 Netlink 接口读取出来。
第三步则是 ioctl 发请求，然后从 smoltcp 内部的 ARP cache 里读取。
第四步很简单，不用多说。
第五步则需要指定出端口，用了一个 index ，放在一个特定的 sockaddr 中。
最后的效果就是，能双向转发 ping 通。
网络拓扑：
可以，这很玄学。
后续在想在真机上实验，但是还缺一个网卡驱动，不然就可以用神奇的办法来做这个实验了。</description>
    </item>
    
    <item>
      <title>静态编译 sqlite3</title>
      <link>https://jia.je/software/2019/03/24/static-building-sqlite/</link>
      <pubDate>Sun, 24 Mar 2019 19:13:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/03/24/static-building-sqlite/</guid>
      <description>最近 rCore 支持了动态链接库，于是想着在测试 sqlite 的时候直接用动态的，不过出现了玄学的问题，它会访问一个不存在的地址，看代码也没看出个所以然来。所以研究了一下 sqlite 的静态编译。首先在 configure 的时候尝试了一下：
$ ./configure CC=x86_64-linux-musl-gcc --disable-shared --enabled-static 发现 libsqlite 确实是静态了，但是 sqlite3 并不是。一番研究以后，发现是 libtool 的原因，只要这样编译：
$ make LTLINK_EXTRAS=-all-static 就可以编译出静态的 sqlite3 ：
sqlite3: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped </description>
    </item>
    
    <item>
      <title>交叉编译 Nginx 1.14.2 到 RISC-V</title>
      <link>https://jia.je/software/2019/03/22/cross-compiling-nginx-to-riscv/</link>
      <pubDate>Fri, 22 Mar 2019 23:18:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/03/22/cross-compiling-nginx-to-riscv/</guid>
      <description>最近又把一定的精力放到了 RISC-V 64 上的 rCore 用户态程序的支持上，同时也借到了 HiFive Unleashed 板子，所以有真实硬件可以拿来跑了。在这之前先在 QEMU 上把能跑的都跑起来。
由于 rCore 对 glibc 的支持一直有问题，RISC-V 也不例外，所以还是选择用 musl 来做这件事情。一般搜索，终于找到了 Linux 下能用的 musl-riscv-toolchain 。编译好工具链以后，很多需要 libc 的用户态都能跑了，于是想着试一下 nginx 的编译。试着编译了一下，遇到了各种问题，最后搜到了交叉编译Hi3536上面使用的nginx，里面的方法解决了这个问题。最后总结出了这样的 patch :
diff --git a/nginx-1.14.2/auto/cc/name b/nginx-1.14.2/auto/cc/name index ded93f5..d6ab27a 100644 --- a/nginx-1.14.2/auto/cc/name +++ b/nginx-1.14.2/auto/cc/name @@ -7,7 +7,7 @@ if [ &amp;#34;$NGX_PLATFORM&amp;#34; != win32 ]; then ngx_feature=&amp;#34;C compiler&amp;#34; ngx_feature_name= - ngx_feature_run=yes + ngx_feature_run=no ngx_feature_incs= ngx_feature_path= ngx_feature_libs= diff --git a/nginx-1.14.2/auto/lib/openssl/make b/nginx-1.14.2/auto/lib/openssl/make index 126a238..7a0e768 100644 --- a/nginx-1.14.2/auto/lib/openssl/make +++ b/nginx-1.</description>
    </item>
    
    <item>
      <title>实现 VSCodeVim 中支持中文分词的单词移动</title>
      <link>https://jia.je/software/2019/01/16/vscode-vim-chinese-word-motion/</link>
      <pubDate>Wed, 16 Jan 2019 00:15:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/01/16/vscode-vim-chinese-word-motion/</guid>
      <description>最近用 VS Code 写中文 LaTeX 比较多，但是编辑起来总是比较麻烦，不能用各种带 w 的 motion ，不然整行都没了。于是 @xalanq 提出能不能拿一个 JS 的分词库，魔改一下 VSCode Vim 来得到同样效果？答案是可以的。
最后代码在 jiegec/VSCodeVimChinese 里，还没有合并到上游的打算。不定期根据上游发版本同步更新，在 Github Release 里发布 vsix 文件，目前版本为 v1.0.1。在 VS Code 里 Extensions: Install from VSIX... 即可安装。
经过对代码的研究，发现对 motion w 的处理都是通过 getWordLeft getWordRight 和 getCurrentWordEnd 完成的。于是我修改了这三个函数，根据原来的返回值把字符串喂给分词器，再返回的新的位置。一开始用的是 nodejieba ，但是因为需要用到 node-gyp 遇到了 Node 版本不兼容的问题，于是换了一个纯 Node 的实现 node-segment ，就完成了这个功能。</description>
    </item>
    
    <item>
      <title>Grafana 中可视化 Ping 时把 Timeout 显示为指定值</title>
      <link>https://jia.je/software/2019/01/13/grafana-influxdb-visualize-ping/</link>
      <pubDate>Sun, 13 Jan 2019 18:36:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/01/13/grafana-influxdb-visualize-ping/</guid>
      <description>刚遇到一个需求，就是用 Telegraf 收集 ping 信息，然后在 Grafana 里可视化当前的延迟，如果超时了，就显示一个指定值，如 999 ，这样就可以放到一个 Gauge 里面可视化了。但是，问题在于，Telegraf 的 ping input 在超时的时候只会在 result_code 里写一个 2 ，其他项都是空的，因而如果直接用 GROUP BY time(interval) fill(999) 会导致最新的一个数据经常得到 999 。这意味着需要根据 &amp;ldquo;result_code&amp;rdquo; 来进行区分 Timeout 的情况。最后捣腾了很久，得到了这个方案：
select &amp;#34;average_response_ms&amp;#34; * (2 - &amp;#34;result_code&amp;#34;) / 2 + &amp;#34;result_code&amp;#34; / 2 * 999 from (select &amp;#34;average_response_ms&amp;#34;, &amp;#34;result_code&amp;#34; from ping where $timeFilter fill(0)) 最后的方法很粗糙：当 &amp;ldquo;result_code&amp;rdquo; 是 0 也就是成功的时候，得到延迟，而当 &amp;ldquo;result_code&amp;rdquo; 是 2 也就是超时的时候，直接得到 999 。这样就解决了这个问题。</description>
    </item>
    
    <item>
      <title>调整 Alacritty 的 Powerline 字体显示偏移</title>
      <link>https://jia.je/software/2019/01/10/alacritty-powerline-font-offset/</link>
      <pubDate>Thu, 10 Jan 2019 20:19:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/01/10/alacritty-powerline-font-offset/</guid>
      <description>今天体验了一下 Alacritty ，以前一直在用 iTerm2 ，但是它的高级功能我都没用到。于是现在用了下 Alacritty ，把 Solarized Dark 配置了，发现 Inconsolata for Powerline 字体显示有点偏差，于是调整了一下：
# Font configuration (changes require restart) font: # Normal (roman) font face normal: family: Inconsolata for Powerline # The `style` can be specified to pick a specific face. #style: Regular # Bold font face bold: family: Inconsolata for Powerline # The `style` can be specified to pick a specific face. #style: Bold # Italic font face italic: family: Inconsolata for Powerline # The `style` can be specified to pick a specific face.</description>
    </item>
    
    <item>
      <title>Grafana Variable 的 regex 过滤方式</title>
      <link>https://jia.je/software/2019/01/10/grafana-variable-regex-exclusion/</link>
      <pubDate>Thu, 10 Jan 2019 12:47:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2019/01/10/grafana-variable-regex-exclusion/</guid>
      <description>用 InfluxDB 收集到 Mountpoint 数据的时候，经常会掺杂一些不关心的，如 TimeMachine ，KSInstallAction 和 AppTranslocation 等等。所以，为了在 Variables 里过滤掉他们，需要用 Regex 进行处理。网上有人提供了方案，就是通过 Negative Lookahead 实现：
/^(?!.*TimeMachine)(?!.*KSInstallAction)(?!.*\/private)/ 这样就可以把不想看到的这些 mountpoint 隐藏，节省页面空间了。当然了，这里其实也可以用白名单的方法进行处理，直接写 regex 就可以了。</description>
    </item>
    
    <item>
      <title>《加速奔向2019》小程序编写和运营回顾</title>
      <link>https://jia.je/software/2018/12/27/wxapp-recap/</link>
      <pubDate>Thu, 27 Dec 2018 19:56:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/12/27/wxapp-recap/</guid>
      <description>前言 关注清华的同学可能知道，昨天，“清华大学”公众号发了一篇名为《2018，我们共芳华丨@THUers 致相伴一年的你，请查收这份心意》的推送，内容大概就是，有那么100个新年台历礼品要送出去，大家如果想要的话，就扫描小程序。小程序模仿了火车抢票的病毒式营销的模式，要求大家分享到群聊或者朋友圈，让别人给自己加速，加速到 2019 的前 100 名即可填写信息领取奖品。
然后大家就在推送里看到了我。就酱。
开始 这件事情据说策划了有一段时间了，只是因为各种原因一直没有做，最后这个锅就路由到了我的头上。一开始说就是个加速小程序，逻辑很简单，但后来逐渐发现需求越来越多，主要是界面上的，动画上的，还有一些非技术因素的功能，嗯。这其实算是一个不大好的软件工程案例。
过程 线上的问题与解决方案 然后就是上线了。大概是昨天（2018-12-27）中午的时候推送发出去，很快流量就开始来了。很快，在朋友圈看到有同学在转发了，也有人反映说，网络有点卡，加载资源有点多。我去机器上用 iftop 看了下，流量大概是 250Mb/s ，没打到千兆。我一开始看了下，CPU 和内存占用都良好，以为是网络出口限制的问题，就想着没办法了，就这样吧，扛过去再说。不过，忽然有了转机。
TUNA 技术群里，忽然有人在讨论 SOMAXCONN 的问题，我想到，会不会是有些参数没开够大，导致了性能瓶颈，又受到啊荣的点拨，立马调整了这些变量：
net.core.somaxconn fs.file-max net.core.netdev_max_backlog net.ipv4.tcp_max_syn_backlog nginx: worker_rlimit_nofile nginx: event.worker_connections 很快带宽从 200Mb/s 左右打到了 400Mb/s 多，在 iftop 中看到的峰值接近 600Mb/s，见下图：
事后回来看，发现配置一套科学的监控系统真的很有用，如 TCP 连接的状态图：
这里最高的黄线代表的是 TIME_WAIT ，意味着很多的 TCP 连接都卡在了等待资源上，而一当我修改参数以后，立刻就降了下来，ESTBALISHED 的连接有了显著的提升。这个问题从另一个图也可以明地看出：
这个图是 TCP Handshake Issues ，可以看到无论是 activeopen 还是 passiveopen ，都很高，意味着这里无论是发还是收都遇到了问题。而修改参数以后，这些问题立马得到了很好的改善。
其实这些本应该在上线前做好的，但我低估了清华大学的影响力，没有做好相应的准备，还是在优秀的运维人员的指点下得到了较好的效果。
用户数据分析 当然了，除了 Grafana+InfluxDB+Telegraf 这一套监控系统，我们也部署了 ElasticSearch+Logstash+Kibana ，只不过我们还是用 Grafana 做了 ElasticSearch 的前端了。通过对 Nginx 日志的分析，我们得到了这些关键的数据（从12-26 12:00到12-27 12:00一天时间）：</description>
    </item>
    
    <item>
      <title>配置 homebridge-mi-aqara 并添加为 telegraf 的数据源</title>
      <link>https://jia.je/software/2018/12/13/homebridge-mi-aqara-telegraf/</link>
      <pubDate>Thu, 13 Dec 2018 20:07:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/12/13/homebridge-mi-aqara-telegraf/</guid>
      <description>最近有了设备，想把设备拿到的数据都导一份存到 influxdb 里，但是目前找到的只有 homebridge-mi-aqara 可以访问并拿到数据，然后它又提供了 mqtt 的数据获取方案，于是自己写了个脚本去读取这些数据。
首先当然是配置一下 homebridge-mi-aqara ，按照网上的教程来，这个不难。然后本地开一个 MQTT Broker （如 mosquitto ），配置为本地监听，然后我编写了脚本 telegraf-mi-aqara.py ，使用前需要 pip install paho-mqtt，并且按照实际路径修改一下内容 。验证能够跑起来后，写一个 telegraf 配置：
[[inputs.exec]] commands = [&amp;#34;/usr/bin/python3 /path/to/telegraf-mi-aqara.py&amp;#34;] timeout = &amp;#34;5s&amp;#34; data_format = &amp;#34;influx&amp;#34; 现在就可以读取到各项信息，如温度，湿度，是否开门，开关用电情况等等。
2018-12-16 更新：
研究了一下绿米网关局域网通信协议，得到了第二个版本 telegraf-mi-aqara-v2.py，它与第一版的区别是，第一版是主动向网关读取信息，而这一版则是监听组播包，等待网关发消息。这个脚本负责把读取到的组播信息发送到 MQTT ，再让 telegraf 从 MQTT 里解析 JSON 消息，写入数据库。Telegraf 配置如下：
[[inputs.mqtt_consumer]] servers = [&amp;#34;tcp://127.0.0.1:1883&amp;#34;] qos = 0 connection_timeout = &amp;#34;30s&amp;#34; topics = [ &amp;#34;/telegraf-mi-aqara&amp;#34; ] persistent_session = true client_id = &amp;#34;Telegraf&amp;#34; data_format = &amp;#34;json&amp;#34; json_string_fields = [&amp;#34;model&amp;#34;, &amp;#34;sid&amp;#34;, &amp;#34;status&amp;#34;] tag_keys = [&amp;#34;model&amp;#34;, &amp;#34;sid&amp;#34;, &amp;#34;short_id&amp;#34;] 由于设备不全，有些字段可能不完整。如果大家自己要用的话，可能需要自行修改一下。</description>
    </item>
    
    <item>
      <title>Grafana 可视化实践：清华大学 2018 年度人物评选</title>
      <link>https://jia.je/software/2018/12/07/grafana-visualize-vote18/</link>
      <pubDate>Fri, 07 Dec 2018 23:03:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/12/07/grafana-visualize-vote18/</guid>
      <description>最近这段时间，清华内部正在投票选出今年的年度人物，想到最近刚好在学习使用 Grafana+InfluxDB+Telegraf 全家桶，于是想着能不能写个爬虫把数据都拿下来，然后用 Grafana 画出来，就可以得到一个投票随时间变化的趋势。爬虫很简单，就是登录，获取页面信息，然后按照 InfluxDB 的输入格式进行输出即可。代码放在了 jiegec/student-tsinghua-vote18 下。
接着就是用 Grafana 进行可视化，大概得到了这样一个曲线：
为保护隐私，把名字隐去了。实际上的投票时间是从 12-3 号开始到 12-7号结束，但由于宿舍停电的原因所以采样的点在半夜的时候都没有，所以看起来有点奇怪，但还是能够反应总体的趋势的。比如可以看到前两名很早就一马当先，而后一直遥遥领先，下面的选手则排名变动很大，特别是截止前最后一段时间，大家都在拼命拉票，可见大家都是 DDL 选手啊。如果对上面这个图求个导，看看变化率的话：
这显现出了很有意思的一个趋势，就是每天十二点左右都有一个高峰期，然后在零点前大概熄灯附近的时间也是一个高峰期，另外就是截止前最后的抢票阶段，大家都在疯狂拉票，从中午拉到最后时刻。由于停电的原因，在零点附近的数据都比较的鬼畜，不过影响不大，趋势一目了然。
Grafana 真香！期望可以学到更多高端的查询语法和可视化的骚操作，现在有很多东西不知道该怎么可视化，比较苦恼，不知道大家有没有什么经验可以分享。</description>
    </item>
    
    <item>
      <title>编写 010 Editor 的 FLV Template</title>
      <link>https://jia.je/software/2018/12/06/010-editor-flv-parsing/</link>
      <pubDate>Thu, 06 Dec 2018 20:33:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/12/06/010-editor-flv-parsing/</guid>
      <description>最近在做 FLV 和 H264 方面的研究，研究了很多标准和文档，然后用 010 Editor 对着文件进行分析。这个软件真的很好用，对研究二进制结构用处特别大。不过它自带的 FLV.bt 功能不是很好，我对它加上了 H264(AVC) 的部分支持，放在了 myFLV.bt 里。我也写了 H264 的解析，不过效率不高，大文件要卡好一会。
除此之外，很多格式，010 editor 都有支持，特别好用，它的解析器语法也很好写。</description>
    </item>
    
    <item>
      <title>配置 Grafana&#43;InfluxDB&#43;Telegraf 并添加 MIIO 数据来源</title>
      <link>https://jia.je/software/2018/11/27/grafana-influxdb-telegraf-miio/</link>
      <pubDate>Tue, 27 Nov 2018 20:33:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/11/27/grafana-influxdb-telegraf-miio/</guid>
      <description>之前一直想配一个监控系统，现在有机会了，就简单配了一下。发现真的特别简单，用 Homebrew 安装这三个软件并且都跑起来，然后稍微动一下配置，就可以得到可观的效果了。
然后想利用 miio 配置一下，把宿舍的空气净化器各项参数拿到，以 Telegraf 的插件形式定时上报，然后通过 Grafana 进行可视化。插件放在了 jiegec/tools 下，就是一个简单的 Python 脚本。配置方法如下：
编辑 /usr/local/etc/telegraf.d/miio.conf：
[[inputs.exec]] commands = [&amp;#34;/usr/local/bin/python3 /Volumes/Data/tools/telegraf/miio.py MIID_HERE&amp;#34;] timeout = &amp;#34;5s&amp;#34; data_format = &amp;#34;influx&amp;#34; 默认了 miio 路径为 /usr/local/bin/miio 。</description>
    </item>
    
    <item>
      <title>强制启用 Google Chrome 原生的 Dark Mode</title>
      <link>https://jia.je/software/2018/11/27/enable-dark-mode-google-chrome/</link>
      <pubDate>Tue, 27 Nov 2018 00:17:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/11/27/enable-dark-mode-google-chrome/</guid>
      <description>Mojave 的 Dark Mode 真香，但是 Google Chrome 并不会随着系统的 Dark Mode 设置变化，所以 NightOwl 只能让部分软件按照时间变更 Dark/Light Mode 。一番搜索，发现其实 Google Chrome 其实已经支持了 Dark Mode，但只能设置，不能按照系统的状态自动切换，命令如下：
$ open -a Google\ Chrome --args --force-dark-mode 然后就可以看到 Google Chrome 已经是 Dark Mode 了。但可惜并不能自动切换。</description>
    </item>
    
    <item>
      <title>Mac 上安装 Arch Linux ， ZFS 真香</title>
      <link>https://jia.je/software/2018/11/26/zfs-on-macos-and-linux/</link>
      <pubDate>Mon, 26 Nov 2018 20:51:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/11/26/zfs-on-macos-and-linux/</guid>
      <description>最近在 Mac 上装了 Arch Linux ，按照 Mac - Arch Linux Wiki 一路一路走，创建单独的一个 EFI 分区给 Arch Linux 放 GRUB 和内核，一个 ext4 作为根分区。由于 Arch ISO 不支持 Broadcom 的无线网卡，于是先拿 Apple Ethernet Adapter 连到路由器上装机。然后把一些需要的驱动装上了，桌面用的 KDE Plasma ，Trackpad 用的 xf86-input-mtrack-git ， HiDPI 设置为 2x Scale ，各种体验都还可以，就是 Wi-Fi 的 802.1X 没配置好，然后 kwalletd5 老是崩没找到原因。常见的应用除了微信基本都有，也终于可以体验 Steam Play ，利用 Proton 在 Linux 上跑一些只支持 Windows 的游戏，不过我已经很少玩游戏了。
然后我就想，怎么做 macOS 和 Linux 之间的文件共享。典型的操作可能是 exFAT ，但是作为数据盘的话，这还是不大适合。或者就直接用 ext4 ，配合 extFS For Mac by Paragon 使用，也可以，最后我选择了 ZFS 。</description>
    </item>
    
    <item>
      <title>USB/IP 实践</title>
      <link>https://jia.je/software/2018/11/20/usb-ip/</link>
      <pubDate>Tue, 20 Nov 2018 18:50:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/11/20/usb-ip/</guid>
      <description>之前一直想玩 USB/IP ，但是一直没有找俩 Linux 设备然后共享，今天终于尝试了一下，没有什么大问题。这次采用的设备是 Raspberri Pi 3 和 SaltedFish Pi 。一开始尝试从后者向前者共享，但总是出现这个错误：
libusbip: error: udev_device_get_sysattr_value failed usbip: error: open vhci_driver 然后我反过来做就好了，比较神奇。
主要过程如下：
pacman -S usbip 安装用户态软件 systemctl enable --now usbipd 启动 USB/IP 的端口监听 daemon usbip list -l 查看本地有哪些 USB 设备可以共享 usbip bind -b [BUS_ID] 把指定的 USB 设备共享出去，其中 BUS_ID 从上个命令中查看 usbip list -r [IP] 在另一个设备上查看这个设备共享的 USB 设备，可以看到许多信息 usbip attach -r [IP] -b [BUS_ID] 把对方共享的 USB 设备 attach 到本地 效果：把一个 U 盘成功映射到了本地：</description>
    </item>
    
    <item>
      <title>使用 HomeBridge 把小米空气净化器加入到 HomeKit 中</title>
      <link>https://jia.je/software/2018/11/04/mi-air-purifier-homekit/</link>
      <pubDate>Sun, 04 Nov 2018 10:47:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/11/04/mi-air-purifier-homekit/</guid>
      <description>受 @NSBlink 安利，自己部署了一下 HomeBridge ，然后在 iOS 的家庭上就可以看到它。然后，通过 homebrdige-mi-airpurifier 和 miio 按照教程进行配置。然后就可以在家庭里看到小米空气净化器，包括空气质量，湿度，睡眠模式，温度，打开状态。然后我就可以做一些配置，如离开宿舍的时候自动关闭空气净化器，回来的时候自动打开。不过由于自己没有一个一直放在宿舍的 iPad、Apple TV 或者 HomePod ，失去了中枢，这个功能可能会打折扣。
后续想买一些智能的灯啊，然后就可以用 Siri 进行打开 / 关闭了。
此外，我又试了下，可以用 homebridge-camera-ffmpeg 把摄像头配置到 HomeKit 中。这样，就可以远程查看视频流了。</description>
    </item>
    
    <item>
      <title>部署 adminMongo 的 Docker 镜像</title>
      <link>https://jia.je/software/2018/10/23/admin-mongo-docker/</link>
      <pubDate>Tue, 23 Oct 2018 20:08:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/10/23/admin-mongo-docker/</guid>
      <description>之前在软工的平台上部署了一个 MongoDB ，但是自然是仅内网访问，想要浏览内容只能通过网页上的 Console 进去看，体验特别不好。所以想着能不能找一个在线的 MongoDB 浏览器。由于软工平台只能部署 Docker 镜像，所以我找到了mongo-express和adicom/admin-mongo。但软工平台现在还没实现环境变量的配置，所以我选了后者。
首先本地创建一个 app.json ，让它监听 0.0.0.0:80 ，通过 deployer 传到平台上的配置，然后再把配置 mount 到 /app/config 路径上。现在就可以成功地在网页上浏览 MongoDB 了。</description>
    </item>
    
    <item>
      <title>软工平台踩坑记</title>
      <link>https://jia.je/software/2018/10/12/secoder-platform-sucks/</link>
      <pubDate>Fri, 12 Oct 2018 00:09:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/10/12/secoder-platform-sucks/</guid>
      <description>老师要求我们搞 CI/CD ，CI 自然是很快就搞好了，不过 CD 还得配一下。今天研究了一下它的 Deployer 架构，发现了若干易用性问题：
缺乏文档 只有样例配置没有讲解 已有的文档 语焉不详 官方对此回复：功能太多，还没忙过来写文档 于是只好经常戳助教然后尝试理解这个东西。。然后遇到了很多的 BUG ：
容器没有重启功能。。。 容器死了还是活着看一个图的颜色。。。毫无说明 容器虽然有 Console ，但是输入过长后直接回到行首没有换行。。。 容器对外的域名里有下划线。。。 Django 上来就一句 Invalid HTTP_HOST header: &#39;xxxx_xxx.app.secoder.net&#39;. The domain name provided is not valid according to RFC 1034/1035. Express 直接就 Invalid Host header 放弃治疗。。。 助教对上一条的回复是，等我忙完 DDL 有空再做吧。。。也就是说现在要做只能自己再开一个 Nginx 容器然后自己在 proxy_set_header 上做手脚。。。 </description>
    </item>
    
    <item>
      <title>绕过 GPGMail 的激活检测</title>
      <link>https://jia.je/software/2018/10/04/bypass-gpgmail-activation/</link>
      <pubDate>Thu, 04 Oct 2018 11:47:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/10/04/bypass-gpgmail-activation/</guid>
      <description>前段时间 GPGMail 宣布不再免费，在三十天的试用期后就不给用了。唉，可能是官方实在没钱维护了，也可能是官方想赚钱了。不过，既然 GPGMail 采用的是自由的许可证，意味着我们可以自己对代码进行更改。和许可证验证相关的代码如下：
- (BOOL)hasActiveContract { NSDictionary *contractInformation = [self contractInformation]; return [contractInformation[@&amp;#34;Active&amp;#34;] boolValue]; } 我们只要改成 return TRUE ，在自己的电脑上手动编译、并复制到 /Library/Application Support/GPGTools/GPGMail 下即可。
另：还有一个直接对二进制打 patch 的方法（仍然符合许可证），利用了最近打 CTF 学到的一些知识。找到以上这个函数，然后把返回值修改成非零即可。这里就不提供方法了。最后的更改：
$ radiff2 -D --- 0x0000282f 410fbec7 - movsx eax, r15b +++ 0x0000282f 4c89e090 + mov rax, r12 + nop 当然了，还需要额外 codesign --remove-signature 一下。
谨慎对非自由软件采用这个方法。可能有法律风险。</description>
    </item>
    
    <item>
      <title>在 Ubuntu 上跨版本迁移 MongoDB</title>
      <link>https://jia.je/software/2018/09/13/migrate-mongodb-on-ubuntu/</link>
      <pubDate>Thu, 13 Sep 2018 14:27:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/09/13/migrate-mongodb-on-ubuntu/</guid>
      <description>由于 MongoDB 只支持当前版本和上一个版本的数据库格式，然后刚刚滚系统升级的时候升级到了 3.6.x ，而数据库格式仍然是 3.2.x 的，于是需要先安装回 3.4.x 版本的 MongoDB，输入命令把数据库升级到 3.4.x 版本后，再用 3.6.x 的数据库进行升级。
以 从 Ubuntu 14.04 LTS 升级到 Ubuntu 18.04.1 LTS 为例，方法如下：
$ wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu1604-3.4.17.tgz $ tar xvf mongodb-linux-x86_64-ubuntu1604-3.4.17.tgz $ cd mongodb-linux-x86_64-ubuntu1604-3.4.17/bin/ $ sudo ./mongod --config /etc/mongodb.conf &amp;amp; $ mongo &amp;gt; db.adminCommand( { setFeatureCompatibilityVersion: &amp;#39;3.4&amp;#39; } ) { &amp;#34;ok&amp;#34; : 1 } $ fg ^C $ sudo chown -R mongodb:mongodb /var/lib/mongodb $ sudo systemctl start mongodb $ mongo &amp;gt; db.</description>
    </item>
    
    <item>
      <title>在 Xcode 9 上启用 Vim 模拟（XVim 2）</title>
      <link>https://jia.je/software/2018/09/08/enable-vim-mode-in-xcode-9/</link>
      <pubDate>Sat, 08 Sep 2018 02:01:00 +0800</pubDate>
      
      <guid>https://jia.je/software/2018/09/08/enable-vim-mode-in-xcode-9/</guid>
      <description>作为一个不用 vim 编辑会死星人，用 Xcode 总是止不住自己想 Escape 的心。于是找到了 XVimProject/XVim2 进行配置。
大致方法如下：
按照 Signing Xcode 对 Xcode 进行重签名。套路和对 GDB 进行签名一样。不过这次，签名完成的时间可长多了，毕竟 Xcode 这么大。 接着按照项目的 README ，首先 git clone 然后 make ，第一次打开 Xcode 的时候选择 Load Bundle 即可。 终于可以满足我 Escape Xcode 的欲望了。</description>
    </item>
    
  </channel>
</rss>
